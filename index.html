<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Intro to R &quot;Big Data&quot; Bootcamp</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <link href="assets/bootstrap/css/bootstrap.css" rel="stylesheet">
    <link href="assets/custom/custom.css" rel="stylesheet">
    <!-- font-awesome -->
    <link href="assets/font-awesome/css/font-awesome.min.css" rel="stylesheet">

    <!-- prism -->
    <link href="assets/prism/prism.css" rel="stylesheet">
    <link href="assets/prism/prism.r.css" rel="stylesheet">
    <script type='text/javascript' src='assets/prism/prism.js'></script>
    <script type='text/javascript' src='assets/prism/prism.r.js'></script>
    
    
    
    <script type="text/javascript" src="assets/MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
   MathJax.Hub.Config({    
     extensions: ["tex2jax.js"],    
     "HTML-CSS": { scale: 100}    
   });
   </script>
    
    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="js/html5shiv.js"></script>
    <![endif]-->
    
    <link href='http://fonts.googleapis.com/css?family=Lato' rel='stylesheet' type='text/css'>
    <!-- <link href='http://fonts.googleapis.com/css?family=Lustria' rel='stylesheet' type='text/css'> -->
    <link href='http://fonts.googleapis.com/css?family=Bitter' rel='stylesheet' type='text/css'>
    

    <!-- Fav and touch icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="ico/apple-touch-icon-114-precomposed.png">
      <link rel="apple-touch-icon-precomposed" sizes="72x72" href="ico/apple-touch-icon-72-precomposed.png">
                    <link rel="apple-touch-icon-precomposed" href="ico/apple-touch-icon-57-precomposed.png">
                                   <!-- <link rel="shortcut icon" href="ico/favicon.png"> -->
  </head>

  <body>

    <div class="container-narrow">

      <div class="masthead">
        <ul class="nav nav-pills pull-right">
           
        </ul>
        <p class="myHeader">Intro to R &quot;Big Data&quot; Bootcamp</p>
      </div>

      <hr>

<div class="container-fluid">
   <div class="row-fluid">
   
   <div class="col-md-3 well">
   <ul class = "nav nav-list" id="toc">
   <li class='nav-header unselectable' data-edit-href='Activity_1.2.Rmd'>Activity 1: Introduction to R</li>
      
      <li class='active'>
         <a target='_self' class='nav-not-header' href='#activity-12-getting-started'>Activity 1.2: Getting Started</a>
      </li>


      <li class='active'>
         <a target='_self' class='nav-not-header' href='#activity-13-data-structures'>Activity 1.3: Data Structures</a>
      </li>


      <li class='active'>
         <a target='_self' class='nav-not-header' href='#activity-13-solutions'>Activity 1.3 Solutions</a>
      </li>


      <li class='active'>
         <a target='_self' class='nav-not-header' href='#activity-14-readingwriting-to-disc-packages-functions'>Activity 1.4: Reading/writing to disc, packages, functions</a>
      </li>


      <li class='active'>
         <a target='_self' class='nav-not-header' href='#activity-14-solutions'>Activity 1.4 Solutions</a>
      </li>


      <li class='active'>
         <a target='_self' class='nav-not-header' href='#activity-15-statistical-and-graphical-analyses'>Activity 1.5: Statistical and graphical analyses</a>
      </li>


      <li class='active'>
         <a target='_self' class='nav-not-header' href='#activity-15-solutions'>Activity 1.5 Solutions</a>
      </li>


<li class='nav-header unselectable' data-edit-href='Activity_2.1.Rmd'>Activity 2: Demonstration of Tessera Tools with Data</li>
      
      <li class='active'>
         <a target='_self' class='nav-not-header' href='#activity-21-datadr-and-trelliscope-example-with-census-data'>Activity 2.1: DataDR and Trelliscope example with Census Data</a>
      </li>


      <li class='active'>
         <a target='_self' class='nav-not-header' href='#activity-22-using-tessera-with-hadoop-to-analyze-large-data'>Activity 2.2: Using Tessera with Hadoop to Analyze Large Data</a>
      </li>


      <li class='active'>
         <a target='_self' class='nav-not-header' href='#activity-23-using-trelliscope-to-explore-large-complex-data'>Activity 2.3: Using Trelliscope to Explore Large, Complex Data</a>
      </li>


<li class='nav-header unselectable' data-edit-href='Appendix.Rmd'>Appendix</li>
      
      <li class='active'>
         <a target='_self' class='nav-not-header' href='#r-code'>R Code</a>
      </li>

   </ul>
   </div>

<div class="col-md-9 tab-content" id="main-content">

<div class='tab-pane active' id='activity-12-getting-started'>
<h3>Activity 1.2: Getting Started</h3>

<h1></h1>

<h4>Activity 1.2.1: Help commands</h4>

<p>When you don&#39;t know exactly what you&#39;re looking for,
search for a topic.  There are two ways to do this:</p>

<pre><code class="r">help.search(&quot;graphics&quot;)
??graphics
</code></pre>

<p>When you know the name of the R function, e.g. the function
 print(), there are two ways to do this:</p>

<pre><code class="r">help(print)
?print
</code></pre>

<p>Sometimes you just need a reminder about the arguments (the inputs) of a function.  The args() function can help in
this situation.  Here are the arguments for the rnorm()
function, which generates normal random variates</p>

<pre><code class="r">args(rnorm)
</code></pre>

<pre><code>function (n, mean = 0, sd = 1) 
NULL
</code></pre>

<p>Examples are often included in the documentation of functions at the bottom of the documentation.  Look at:</p>

<pre><code class="r">?seq
</code></pre>

<p>You can execute the example code for a function all at once
 using the example() function:</p>

<pre><code class="r">example(seq)
</code></pre>

<pre><code>
seq&gt; seq(0, 1, length.out = 11)
 [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0

seq&gt; seq(stats::rnorm(20)) # effectively &#39;along&#39;
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20

seq&gt; seq(1, 9, by = 2)     # matches &#39;end&#39;
[1] 1 3 5 7 9

seq&gt; seq(1, 9, by = pi)    # stays below &#39;end&#39;
[1] 1.000 4.142 7.283

seq&gt; seq(1, 6, by = 3)
[1] 1 4

seq&gt; seq(1.575, 5.125, by = 0.05)
 [1] 1.575 1.625 1.675 1.725 1.775 1.825 1.875 1.925 1.975 2.025 2.075
[12] 2.125 2.175 2.225 2.275 2.325 2.375 2.425 2.475 2.525 2.575 2.625
[23] 2.675 2.725 2.775 2.825 2.875 2.925 2.975 3.025 3.075 3.125 3.175
[34] 3.225 3.275 3.325 3.375 3.425 3.475 3.525 3.575 3.625 3.675 3.725
[45] 3.775 3.825 3.875 3.925 3.975 4.025 4.075 4.125 4.175 4.225 4.275
[56] 4.325 4.375 4.425 4.475 4.525 4.575 4.625 4.675 4.725 4.775 4.825
[67] 4.875 4.925 4.975 5.025 5.075 5.125

seq&gt; seq(17) # same as 1:17, or even better seq_len(17)
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17
</code></pre>

<h4>Activity 1.2.2:Demos</h4>

<p>Some R packages include demonstrations you can run to learn
 about their capability.  Be sure to hit &quot;Enter&quot; to
 cycle through the components of each demo</p>

<p>Here&#39;s one from the &#39;graphics&#39; package, which gives a nice
 demonstration of the breadth of graphical capability in R</p>

<pre><code class="r">demo(&quot;graphics&quot;)
</code></pre>

<pre><code>

    demo(graphics)
    ---- ~~~~~~~~

&gt; #  Copyright (C) 1997-2009 The R Core Team
&gt; 
&gt; require(datasets)

&gt; require(grDevices); require(graphics)

&gt; ## Here is some code which illustrates some of the differences between
&gt; ## R and S graphics capabilities.  Note that colors are generally specified
&gt; ## by a character string name (taken from the X11 rgb.txt file) and that line
&gt; ## textures are given similarly.  The parameter &quot;bg&quot; sets the background
&gt; ## parameter for the plot and there is also an &quot;fg&quot; parameter which sets
&gt; ## the foreground color.
&gt; 
&gt; 
&gt; x &lt;- stats::rnorm(50)

&gt; opar &lt;- par(bg = &quot;white&quot;)

&gt; plot(x, ann = FALSE, type = &quot;n&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-61.png" alt="plot of chunk unnamed-chunk-6"> </p>

<pre><code>
&gt; abline(h = 0, col = gray(.90))

&gt; lines(x, col = &quot;green4&quot;, lty = &quot;dotted&quot;)

&gt; points(x, bg = &quot;limegreen&quot;, pch = 21)

&gt; title(main = &quot;Simple Use of Color In a Plot&quot;,
+       xlab = &quot;Just a Whisper of a Label&quot;,
+       col.main = &quot;blue&quot;, col.lab = gray(.8),
+       cex.main = 1.2, cex.lab = 1.0, font.main = 4, font.lab = 3)

&gt; ## A little color wheel.   This code just plots equally spaced hues in
&gt; ## a pie chart.   If you have a cheap SVGA monitor (like me) you will
&gt; ## probably find that numerically equispaced does not mean visually
&gt; ## equispaced.  On my display at home, these colors tend to cluster at
&gt; ## the RGB primaries.  On the other hand on the SGI Indy at work the
&gt; ## effect is near perfect.
&gt; 
&gt; par(bg = &quot;gray&quot;)

&gt; pie(rep(1,24), col = rainbow(24), radius = 0.9)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-62.png" alt="plot of chunk unnamed-chunk-6"> </p>

<pre><code>
&gt; title(main = &quot;A Sample Color Wheel&quot;, cex.main = 1.4, font.main = 3)

&gt; title(xlab = &quot;(Use this as a test of monitor linearity)&quot;,
+       cex.lab = 0.8, font.lab = 3)

&gt; ## We have already confessed to having these.  This is just showing off X11
&gt; ## color names (and the example (from the postscript manual) is pretty &quot;cute&quot;.
&gt; 
&gt; pie.sales &lt;- c(0.12, 0.3, 0.26, 0.16, 0.04, 0.12)

&gt; names(pie.sales) &lt;- c(&quot;Blueberry&quot;, &quot;Cherry&quot;,
+             &quot;Apple&quot;, &quot;Boston Cream&quot;, &quot;Other&quot;, &quot;Vanilla Cream&quot;)

&gt; pie(pie.sales,
+     col = c(&quot;purple&quot;,&quot;violetred1&quot;,&quot;green3&quot;,&quot;cornsilk&quot;,&quot;cyan&quot;,&quot;white&quot;))
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-63.png" alt="plot of chunk unnamed-chunk-6"> </p>

<pre><code>
&gt; title(main = &quot;January Pie Sales&quot;, cex.main = 1.8, font.main = 1)

&gt; title(xlab = &quot;(Don&#39;t try this at home kids)&quot;, cex.lab = 0.8, font.lab = 3)

&gt; ## Boxplots:  I couldn&#39;t resist the capability for filling the &quot;box&quot;.
&gt; ## The use of color seems like a useful addition, it focuses attention
&gt; ## on the central bulk of the data.
&gt; 
&gt; par(bg=&quot;cornsilk&quot;)

&gt; n &lt;- 10

&gt; g &lt;- gl(n, 100, n*100)

&gt; x &lt;- rnorm(n*100) + sqrt(as.numeric(g))

&gt; boxplot(split(x,g), col=&quot;lavender&quot;, notch=TRUE)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-64.png" alt="plot of chunk unnamed-chunk-6"> </p>

<pre><code>
&gt; title(main=&quot;Notched Boxplots&quot;, xlab=&quot;Group&quot;, font.main=4, font.lab=1)

&gt; ## An example showing how to fill between curves.
&gt; 
&gt; par(bg=&quot;white&quot;)

&gt; n &lt;- 100

&gt; x &lt;- c(0,cumsum(rnorm(n)))

&gt; y &lt;- c(0,cumsum(rnorm(n)))

&gt; xx &lt;- c(0:n, n:0)

&gt; yy &lt;- c(x, rev(y))

&gt; plot(xx, yy, type=&quot;n&quot;, xlab=&quot;Time&quot;, ylab=&quot;Distance&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-65.png" alt="plot of chunk unnamed-chunk-6"> </p>

<pre><code>
&gt; polygon(xx, yy, col=&quot;gray&quot;)

&gt; title(&quot;Distance Between Brownian Motions&quot;)

&gt; ## Colored plot margins, axis labels and titles.   You do need to be
&gt; ## careful with these kinds of effects.   It&#39;s easy to go completely
&gt; ## over the top and you can end up with your lunch all over the keyboard.
&gt; ## On the other hand, my market research clients love it.
&gt; 
&gt; x &lt;- c(0.00, 0.40, 0.86, 0.85, 0.69, 0.48, 0.54, 1.09, 1.11, 1.73, 2.05, 2.02)

&gt; par(bg=&quot;lightgray&quot;)

&gt; plot(x, type=&quot;n&quot;, axes=FALSE, ann=FALSE)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-66.png" alt="plot of chunk unnamed-chunk-6"> </p>

<pre><code>
&gt; usr &lt;- par(&quot;usr&quot;)

&gt; rect(usr[1], usr[3], usr[2], usr[4], col=&quot;cornsilk&quot;, border=&quot;black&quot;)

&gt; lines(x, col=&quot;blue&quot;)

&gt; points(x, pch=21, bg=&quot;lightcyan&quot;, cex=1.25)

&gt; axis(2, col.axis=&quot;blue&quot;, las=1)

&gt; axis(1, at=1:12, lab=month.abb, col.axis=&quot;blue&quot;)

&gt; box()

&gt; title(main= &quot;The Level of Interest in R&quot;, font.main=4, col.main=&quot;red&quot;)

&gt; title(xlab= &quot;1996&quot;, col.lab=&quot;red&quot;)

&gt; ## A filled histogram, showing how to change the font used for the
&gt; ## main title without changing the other annotation.
&gt; 
&gt; par(bg=&quot;cornsilk&quot;)

&gt; x &lt;- rnorm(1000)

&gt; hist(x, xlim=range(-4, 4, x), col=&quot;lavender&quot;, main=&quot;&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-67.png" alt="plot of chunk unnamed-chunk-6"> </p>

<pre><code>
&gt; title(main=&quot;1000 Normal Random Variates&quot;, font.main=3)

&gt; ## A scatterplot matrix
&gt; ## The good old Iris data (yet again)
&gt; 
&gt; pairs(iris[1:4], main=&quot;Edgar Anderson&#39;s Iris Data&quot;, font.main=4, pch=19)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-68.png" alt="plot of chunk unnamed-chunk-6"> </p>

<pre><code>
&gt; pairs(iris[1:4], main=&quot;Edgar Anderson&#39;s Iris Data&quot;, pch=21,
+       bg = c(&quot;red&quot;, &quot;green3&quot;, &quot;blue&quot;)[unclass(iris$Species)])
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-69.png" alt="plot of chunk unnamed-chunk-6"> </p>

<pre><code>
&gt; ## Contour plotting
&gt; ## This produces a topographic map of one of Auckland&#39;s many volcanic &quot;peaks&quot;.
&gt; 
&gt; x &lt;- 10*1:nrow(volcano)

&gt; y &lt;- 10*1:ncol(volcano)

&gt; lev &lt;- pretty(range(volcano), 10)

&gt; par(bg = &quot;lightcyan&quot;)

&gt; pin &lt;- par(&quot;pin&quot;)

&gt; xdelta &lt;- diff(range(x))

&gt; ydelta &lt;- diff(range(y))

&gt; xscale &lt;- pin[1]/xdelta

&gt; yscale &lt;- pin[2]/ydelta

&gt; scale &lt;- min(xscale, yscale)

&gt; xadd &lt;- 0.5*(pin[1]/scale - xdelta)

&gt; yadd &lt;- 0.5*(pin[2]/scale - ydelta)

&gt; plot(numeric(0), numeric(0),
+      xlim = range(x)+c(-1,1)*xadd, ylim = range(y)+c(-1,1)*yadd,
+      type = &quot;n&quot;, ann = FALSE)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-610.png" alt="plot of chunk unnamed-chunk-6"> </p>

<pre><code>
&gt; usr &lt;- par(&quot;usr&quot;)

&gt; rect(usr[1], usr[3], usr[2], usr[4], col=&quot;green3&quot;)

&gt; contour(x, y, volcano, levels = lev, col=&quot;yellow&quot;, lty=&quot;solid&quot;, add=TRUE)

&gt; box()

&gt; title(&quot;A Topographic Map of Maunga Whau&quot;, font= 4)

&gt; title(xlab = &quot;Meters North&quot;, ylab = &quot;Meters West&quot;, font= 3)

&gt; mtext(&quot;10 Meter Contour Spacing&quot;, side=3, line=0.35, outer=FALSE,
+       at = mean(par(&quot;usr&quot;)[1:2]), cex=0.7, font=3)

&gt; ## Conditioning plots
&gt; 
&gt; par(bg=&quot;cornsilk&quot;)

&gt; coplot(lat ~ long | depth, data = quakes, pch = 21, bg = &quot;green3&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-611.png" alt="plot of chunk unnamed-chunk-6"> </p>

<pre><code>
&gt; par(opar)
</code></pre>

<p>And here&#39;s one about generalized linear models (glm)</p>

<pre><code class="r">demo(lm.glm)
</code></pre>

<pre><code>

    demo(lm.glm)
    ---- ~~~~~~

&gt; ### Examples from: &quot;An Introduction to Statistical Modelling&quot;
&gt; ###           By Annette Dobson
&gt; ###
&gt; ### == with some additions ==
&gt; 
&gt; #  Copyright (C) 1997-2008 The R Core Team
&gt; 
&gt; require(stats); require(graphics)

&gt; ## Plant Weight Data (Page 9)
&gt; ctl &lt;- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)

&gt; trt &lt;- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)

&gt; group &lt;- gl(2,10, labels=c(&quot;Ctl&quot;,&quot;Trt&quot;))

&gt; weight &lt;- c(ctl,trt)

&gt; anova  (lm(weight~group))
Analysis of Variance Table

Response: weight
          Df Sum Sq Mean Sq F value Pr(&gt;F)
group      1   0.69   0.688    1.42   0.25
Residuals 18   8.73   0.485               

&gt; summary(lm(weight~group -1))

Call:
lm(formula = weight ~ group - 1)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.0710 -0.4937  0.0685  0.2462  1.3690 

Coefficients:
         Estimate Std. Error t value Pr(&gt;|t|)    
groupCtl     5.03       0.22    22.9  9.5e-15 ***
groupTrt     4.66       0.22    21.2  3.6e-14 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.696 on 18 degrees of freedom
Multiple R-squared:  0.982, Adjusted R-squared:  0.98 
F-statistic:  485 on 2 and 18 DF,  p-value: &lt;2e-16


&gt; ## Birth Weight Data (Page 14)
&gt; age &lt;- c(40, 38, 40, 35, 36, 37, 41, 40, 37, 38, 40, 38,
+    40, 36, 40, 38, 42, 39, 40, 37, 36, 38, 39, 40)

&gt; birthw &lt;- c(2968, 2795, 3163, 2925, 2625, 2847, 3292, 3473, 2628, 3176,
+       3421, 2975, 3317, 2729, 2935, 2754, 3210, 2817, 3126, 2539,
+       2412, 2991, 2875, 3231)

&gt; sex &lt;- gl(2,12, labels=c(&quot;M&quot;,&quot;F&quot;))

&gt; plot(age, birthw, col=as.numeric(sex), pch=3*as.numeric(sex),
+      main=&quot;Dobson&#39;s Birth Weight Data&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-71.png" alt="plot of chunk unnamed-chunk-7"> </p>

<pre><code>
&gt; lines(lowess(age[sex==&#39;M&#39;], birthw[sex==&#39;M&#39;]), col=1)

&gt; lines(lowess(age[sex==&#39;F&#39;], birthw[sex==&#39;F&#39;]), col=2)

&gt; legend(&quot;topleft&quot;, levels(sex), col=1:2, pch=3*(1:2), lty=1, bty=&quot;n&quot;)

&gt; summary(l1 &lt;- lm(birthw ~ sex + age),    correlation=TRUE)

Call:
lm(formula = birthw ~ sex + age)

Residuals:
   Min     1Q Median     3Q    Max 
-257.5 -125.3  -58.4  169.0  304.0 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  -1610.3      786.1   -2.05    0.053 .  
sexF          -163.0       72.8   -2.24    0.036 *  
age            120.9       20.5    5.91  7.3e-06 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 177 on 21 degrees of freedom
Multiple R-squared:  0.64,  Adjusted R-squared:  0.606 
F-statistic: 18.7 on 2 and 21 DF,  p-value: 2.19e-05

Correlation of Coefficients:
     (Intercept) sexF 
sexF  0.07            
age  -1.00       -0.12


&gt; summary(l0 &lt;- lm(birthw ~ sex + age -1), correlation=TRUE)

Call:
lm(formula = birthw ~ sex + age - 1)

Residuals:
   Min     1Q Median     3Q    Max 
-257.5 -125.3  -58.4  169.0  304.0 

Coefficients:
     Estimate Std. Error t value Pr(&gt;|t|)    
sexM  -1610.3      786.1   -2.05    0.053 .  
sexF  -1773.3      794.6   -2.23    0.037 *  
age     120.9       20.5    5.91  7.3e-06 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 177 on 21 degrees of freedom
Multiple R-squared:  0.997, Adjusted R-squared:  0.996 
F-statistic: 2.26e+03 on 3 and 21 DF,  p-value: &lt;2e-16

Correlation of Coefficients:
     sexM  sexF 
sexF  1.00      
age  -1.00 -1.00


&gt; anova(l1,l0)
Analysis of Variance Table

Model 1: birthw ~ sex + age
Model 2: birthw ~ sex + age - 1
  Res.Df    RSS Df Sum of Sq F Pr(&gt;F)
1     21 658771                      
2     21 658771  0 -4.19e-09         

&gt; summary(li &lt;- lm(birthw ~ sex + sex:age -1), correlation=TRUE)

Call:
lm(formula = birthw ~ sex + sex:age - 1)

Residuals:
   Min     1Q Median     3Q    Max 
-246.7 -138.1  -39.1  176.6  274.3 

Coefficients:
         Estimate Std. Error t value Pr(&gt;|t|)    
sexM        -1269       1115   -1.14  0.26849    
sexF        -2142       1164   -1.84  0.08057 .  
sexM:age      112         29    3.86  0.00099 ***
sexF:age      130         30    4.35  0.00031 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 181 on 20 degrees of freedom
Multiple R-squared:  0.997, Adjusted R-squared:  0.996 
F-statistic: 1.63e+03 on 4 and 20 DF,  p-value: &lt;2e-16

Correlation of Coefficients:
         sexM  sexF  sexM:age
sexF      0.00               
sexM:age -1.00  0.00         
sexF:age  0.00 -1.00  0.00   


&gt; anova(li,l0)
Analysis of Variance Table

Model 1: birthw ~ sex + sex:age - 1
Model 2: birthw ~ sex + age - 1
  Res.Df    RSS Df Sum of Sq    F Pr(&gt;F)
1     20 652425                         
2     21 658771 -1     -6346 0.19   0.66

&gt; summary(zi &lt;- glm(birthw ~ sex + age, family=gaussian()))

Call:
glm(formula = birthw ~ sex + age, family = gaussian())

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-257.5  -125.3   -58.4   169.0   304.0  

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  -1610.3      786.1   -2.05    0.053 .  
sexF          -163.0       72.8   -2.24    0.036 *  
age            120.9       20.5    5.91  7.3e-06 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for gaussian family taken to be 31370)

    Null deviance: 1829873  on 23  degrees of freedom
Residual deviance:  658771  on 21  degrees of freedom
AIC: 321.4

Number of Fisher Scoring iterations: 2


&gt; summary(z0 &lt;- glm(birthw ~ sex + age - 1, family=gaussian()))

Call:
glm(formula = birthw ~ sex + age - 1, family = gaussian())

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-257.5  -125.3   -58.4   169.0   304.0  

Coefficients:
     Estimate Std. Error t value Pr(&gt;|t|)    
sexM  -1610.3      786.1   -2.05    0.053 .  
sexF  -1773.3      794.6   -2.23    0.037 *  
age     120.9       20.5    5.91  7.3e-06 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for gaussian family taken to be 31370)

    Null deviance: 213198964  on 24  degrees of freedom
Residual deviance:    658771  on 21  degrees of freedom
AIC: 321.4

Number of Fisher Scoring iterations: 2


&gt; anova(zi, z0)
Analysis of Deviance Table

Model 1: birthw ~ sex + age
Model 2: birthw ~ sex + age - 1
  Resid. Df Resid. Dev Df Deviance
1        21     658771            
2        21     658771  0 5.82e-10

&gt; summary(z.o4 &lt;- update(z0, subset = -4))

Call:
glm(formula = birthw ~ sex + age - 1, family = gaussian(), subset = -4)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-253.9  -129.5   -53.5   165.0   251.1  

Coefficients:
     Estimate Std. Error t value Pr(&gt;|t|)    
sexM  -2318.0      801.6   -2.89   0.0090 ** 
sexF  -2455.4      803.8   -3.05   0.0063 ** 
age     138.5       20.7    6.69  1.6e-06 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for gaussian family taken to be 26925)

    Null deviance: 204643339  on 23  degrees of freedom
Residual deviance:    538508  on 20  degrees of freedom
AIC: 304.7

Number of Fisher Scoring iterations: 2


&gt; summary(zz &lt;- update(z0, birthw ~ sex+age-1 + sex:age))

Call:
glm(formula = birthw ~ sex + age + sex:age - 1, family = gaussian())

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-246.7  -138.1   -39.1   176.6   274.3  

Coefficients:
         Estimate Std. Error t value Pr(&gt;|t|)    
sexM      -1268.7     1114.6   -1.14  0.26849    
sexF      -2141.7     1163.6   -1.84  0.08057 .  
age         112.0       29.0    3.86  0.00099 ***
sexF:age     18.4       41.8    0.44  0.66389    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for gaussian family taken to be 32621)

    Null deviance: 213198964  on 24  degrees of freedom
Residual deviance:    652425  on 20  degrees of freedom
AIC: 323.2

Number of Fisher Scoring iterations: 2


&gt; anova(z0,zz)
Analysis of Deviance Table

Model 1: birthw ~ sex + age - 1
Model 2: birthw ~ sex + age + sex:age - 1
  Resid. Df Resid. Dev Df Deviance
1        21     658771            
2        20     652425  1     6346

&gt; ## Poisson Regression Data (Page 42)
&gt; x &lt;- c(-1,-1,0,0,0,0,1,1,1)

&gt; y &lt;- c(2,3,6,7,8,9,10,12,15)

&gt; summary(glm(y~x, family=poisson(link=&quot;identity&quot;)))

Call:
glm(formula = y ~ x, family = poisson(link = &quot;identity&quot;))

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-0.702  -0.338  -0.111   0.296   0.718  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)    7.452      0.884    8.43  &lt; 2e-16 ***
x              4.935      1.089    4.53  5.9e-06 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 18.4206  on 8  degrees of freedom
Residual deviance:  1.8947  on 7  degrees of freedom
AIC: 40.01

Number of Fisher Scoring iterations: 3


&gt; ## Calorie Data (Page 45)
&gt; calorie &lt;- data.frame(
+     carb = c(33,40,37,27,30,43,34,48,30,38,
+        50,51,30,36,41,42,46,24,35,37),
+     age    = c(33,47,49,35,46,52,62,23,32,42,
+        31,61,63,40,50,64,56,61,48,28),
+     wgt    = c(100, 92,135,144,140,101, 95,101, 98,105,
+        108, 85,130,127,109,107,117,100,118,102),
+     prot = c(14,15,18,12,15,15,14,17,15,14,
+        17,19,19,20,15,16,18,13,18,14))

&gt; summary(lmcal &lt;- lm(carb~age+wgt+prot, data= calorie))

Call:
lm(formula = carb ~ age + wgt + prot, data = calorie)

Residuals:
   Min     1Q Median     3Q    Max 
-10.34  -4.82   0.99   3.85   7.91 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)  36.9601    13.0713    2.83   0.0121 * 
age          -0.1137     0.1093   -1.04   0.3139   
wgt          -0.2280     0.0833   -2.74   0.0146 * 
prot          1.9577     0.6349    3.08   0.0071 **
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 5.96 on 16 degrees of freedom
Multiple R-squared:  0.481, Adjusted R-squared:  0.383 
F-statistic: 4.93 on 3 and 16 DF,  p-value: 0.013


&gt; ## Extended Plant Data (Page 59)
&gt; ctl &lt;-    c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)

&gt; trtA &lt;- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)

&gt; trtB &lt;- c(6.31,5.12,5.54,5.50,5.37,5.29,4.92,6.15,5.80,5.26)

&gt; group &lt;- gl(3, length(ctl), labels=c(&quot;Ctl&quot;,&quot;A&quot;,&quot;B&quot;))

&gt; weight &lt;- c(ctl,trtA,trtB)

&gt; anova(lmwg &lt;- lm(weight~group))
Analysis of Variance Table

Response: weight
          Df Sum Sq Mean Sq F value Pr(&gt;F)  
group      2   3.77   1.883    4.85  0.016 *
Residuals 27  10.49   0.389                 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

&gt; summary(lmwg)

Call:
lm(formula = weight ~ group)

Residuals:
   Min     1Q Median     3Q    Max 
-1.071 -0.418 -0.006  0.263  1.369 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)    5.032      0.197   25.53   &lt;2e-16 ***
groupA        -0.371      0.279   -1.33    0.194    
groupB         0.494      0.279    1.77    0.088 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.623 on 27 degrees of freedom
Multiple R-squared:  0.264, Adjusted R-squared:  0.21 
F-statistic: 4.85 on 2 and 27 DF,  p-value: 0.0159


&gt; coef(lmwg)
(Intercept)      groupA      groupB 
      5.032      -0.371       0.494 

&gt; coef(summary(lmwg))#- incl.  std.err,  t- and P- values.
            Estimate Std. Error t value  Pr(&gt;|t|)
(Intercept)    5.032     0.1971  25.527 1.937e-20
groupA        -0.371     0.2788  -1.331 1.944e-01
groupB         0.494     0.2788   1.772 8.768e-02

&gt; ## Fictitious Anova Data (Page 64)
&gt; y &lt;- c(6.8,6.6,5.3,6.1,7.5,7.4,7.2,6.5,7.8,9.1,8.8,9.1)

&gt; a &lt;- gl(3,4)

&gt; b &lt;- gl(2,2, length(a))

&gt; anova(z &lt;- lm(y~a*b))
Analysis of Variance Table

Response: y
          Df Sum Sq Mean Sq F value Pr(&gt;F)   
a          2  12.74    6.37   25.82 0.0011 **
b          1   0.40    0.40    1.64 0.2482   
a:b        2   1.21    0.60    2.45 0.1672   
Residuals  6   1.48    0.25                  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

&gt; ## Achievement Scores (Page 70)
&gt; y &lt;- c(6,4,5,3,4,3,6, 8,9,7,9,8,5,7, 6,7,7,7,8,5,7)

&gt; x &lt;- c(3,1,3,1,2,1,4, 4,5,5,4,3,1,2, 3,2,2,3,4,1,4)

&gt; m &lt;- gl(3,7)

&gt; anova(z &lt;- lm(y~x+m))
Analysis of Variance Table

Response: y
          Df Sum Sq Mean Sq F value  Pr(&gt;F)    
x          1   36.6    36.6    60.4 5.4e-07 ***
m          2   16.9     8.5    14.0 0.00026 ***
Residuals 17   10.3     0.6                    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

&gt; ## Beetle Data (Page 78)
&gt; dose &lt;- c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.861, 1.8839)

&gt; x &lt;- c( 6, 13, 18, 28, 52, 53, 61, 60)

&gt; n &lt;- c(59, 60, 62, 56, 63, 59, 62, 60)

&gt; dead &lt;- cbind(x, n-x)

&gt; summary(     glm(dead ~ dose, family=binomial(link=logit)))

Call:
glm(formula = dead ~ dose, family = binomial(link = logit))

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-1.594  -0.394   0.833   1.259   1.594  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -60.72       5.18   -11.7   &lt;2e-16 ***
dose           34.27       2.91    11.8   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 284.202  on 7  degrees of freedom
Residual deviance:  11.232  on 6  degrees of freedom
AIC: 41.43

Number of Fisher Scoring iterations: 4


&gt; summary(     glm(dead ~ dose, family=binomial(link=probit)))

Call:
glm(formula = dead ~ dose, family = binomial(link = probit))

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
 -1.57   -0.47    0.75    1.06    1.34  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -34.94       2.65   -13.2   &lt;2e-16 ***
dose           19.73       1.49    13.3   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 284.20  on 7  degrees of freedom
Residual deviance:  10.12  on 6  degrees of freedom
AIC: 40.32

Number of Fisher Scoring iterations: 4


&gt; summary(z &lt;- glm(dead ~ dose, family=binomial(link=cloglog)))

Call:
glm(formula = dead ~ dose, family = binomial(link = cloglog))

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.8033  -0.5513   0.0309   0.3832   1.2888  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -39.57       3.24   -12.2   &lt;2e-16 ***
dose           22.04       1.80    12.2   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 284.2024  on 7  degrees of freedom
Residual deviance:   3.4464  on 6  degrees of freedom
AIC: 33.64

Number of Fisher Scoring iterations: 4


&gt; anova(z, update(z, dead ~ dose -1))
Analysis of Deviance Table

Model 1: dead ~ dose
Model 2: dead ~ dose - 1
  Resid. Df Resid. Dev Df Deviance
1         6        3.4            
2         7      285.2 -1     -282

&gt; ## Anther Data (Page 84)
&gt; ## Note that the proportions below are not exactly
&gt; ## in accord with the sample sizes quoted below.
&gt; ## In particular, the value 0.555 does not seem sensible.
&gt; ##    [MM: huh?  round(round(n*p)/n, 3) looks almost exactly like &quot;p&quot; !]
&gt; n &lt;- c(102,  99,   108,    76,   81,   90)

&gt; p &lt;- c(0.539,0.525,0.528,0.724,0.617,0.555)

&gt; x &lt;- round(n*p)

&gt; ## x &lt;- n*p
&gt; y &lt;- cbind(x,n-x)

&gt; f &lt;- rep(c(40,150,350),2)

&gt; (g &lt;- gl(2,3))
[1] 1 1 1 2 2 2
Levels: 1 2

&gt; summary(glm(y ~ g*f, family=binomial(link=&quot;logit&quot;)))

Call:
glm(formula = y ~ g * f, family = binomial(link = &quot;logit&quot;))

Deviance Residuals: 
      1        2        3        4        5        6  
 0.0827  -0.1300   0.0441   0.4232  -0.6008   0.1952  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)  0.145672   0.197545    0.74    0.461  
g2           0.796314   0.312505    2.55    0.011 *
f           -0.000123   0.000878   -0.14    0.889  
g2:f        -0.002049   0.001348   -1.52    0.129  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 10.45197  on 5  degrees of freedom
Residual deviance:  0.60387  on 2  degrees of freedom
AIC: 38.17

Number of Fisher Scoring iterations: 3


&gt; summary(glm(y ~ g + f, family=binomial(link=&quot;logit&quot;)))

Call:
glm(formula = y ~ g + f, family = binomial(link = &quot;logit&quot;))

Deviance Residuals: 
     1       2       3       4       5       6  
-0.551  -0.278   0.797   1.156  -0.369  -0.658  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)  0.306643   0.167629    1.83    0.067 .
g2           0.405554   0.174560    2.32    0.020 *
f           -0.000997   0.000665   -1.50    0.134  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 10.4520  on 5  degrees of freedom
Residual deviance:  2.9218  on 3  degrees of freedom
AIC: 38.49

Number of Fisher Scoring iterations: 3


&gt; ## The &quot;final model&quot;
&gt; summary(glm.p84 &lt;- glm(y~g,  family=binomial(link=&quot;logit&quot;)))

Call:
glm(formula = y ~ g, family = binomial(link = &quot;logit&quot;))

Deviance Residuals: 
      1        2        3        4        5        6  
 0.1715  -0.1095  -0.0618   1.7721  -0.1904  -1.3969  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)    0.123      0.114    1.08    0.280  
g2             0.399      0.174    2.29    0.022 *
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 10.452  on 5  degrees of freedom
Residual deviance:  5.173  on 4  degrees of freedom
AIC: 38.74

Number of Fisher Scoring iterations: 3


&gt; op &lt;- par(mfrow = c(2,2), oma = c(0,0,1,0))

&gt; plot(glm.p84) # well ?
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-72.png" alt="plot of chunk unnamed-chunk-7"> </p>

<pre><code>
&gt; par(op)

&gt; ## Tumour Data (Page 92)
&gt; counts &lt;- c(22,2,10,16,54,115,19,33,73,11,17,28)

&gt; type &lt;- gl(4,3,12,labels=c(&quot;freckle&quot;,&quot;superficial&quot;,&quot;nodular&quot;,&quot;indeterminate&quot;))

&gt; site &lt;- gl(3,1,12,labels=c(&quot;head/neck&quot;,&quot;trunk&quot;,&quot;extremities&quot;))

&gt; data.frame(counts,type,site)
   counts          type        site
1      22       freckle   head/neck
2       2       freckle       trunk
3      10       freckle extremities
4      16   superficial   head/neck
5      54   superficial       trunk
6     115   superficial extremities
7      19       nodular   head/neck
8      33       nodular       trunk
9      73       nodular extremities
10     11 indeterminate   head/neck
11     17 indeterminate       trunk
12     28 indeterminate extremities

&gt; summary(z &lt;- glm(counts ~ type + site, family=poisson()))

Call:
glm(formula = counts ~ type + site, family = poisson())

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-3.045  -1.074   0.130   0.586   5.135  

Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)          1.754      0.204    8.60  &lt; 2e-16 ***
typesuperficial      1.694      0.187    9.08  &lt; 2e-16 ***
typenodular          1.302      0.193    6.73  1.7e-11 ***
typeindeterminate    0.499      0.217    2.30   0.0217 *  
sitetrunk            0.444      0.155    2.86   0.0043 ** 
siteextremities      1.201      0.138    8.68  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 295.203  on 11  degrees of freedom
Residual deviance:  51.795  on  6  degrees of freedom
AIC: 122.9

Number of Fisher Scoring iterations: 5


&gt; ## Randomized Controlled Trial (Page 93)
&gt; counts &lt;- c(18,17,15, 20,10,20, 25,13,12)

&gt; outcome   &lt;- gl(3, 1, length(counts))

&gt; treatment &lt;- gl(3, 3)

&gt; summary(z &lt;- glm(counts ~ outcome + treatment, family=poisson()))

Call:
glm(formula = counts ~ outcome + treatment, family = poisson())

Deviance Residuals: 
      1        2        3        4        5        6        7        8  
-0.6712   0.9627  -0.1696  -0.2200  -0.9555   1.0494   0.8472  -0.0917  
      9  
-0.9666  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  3.04e+00   1.71e-01   17.81   &lt;2e-16 ***
outcome2    -4.54e-01   2.02e-01   -2.25    0.025 *  
outcome3    -2.93e-01   1.93e-01   -1.52    0.128    
treatment2   1.34e-15   2.00e-01    0.00    1.000    
treatment3   1.42e-15   2.00e-01    0.00    1.000    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 10.5814  on 8  degrees of freedom
Residual deviance:  5.1291  on 4  degrees of freedom
AIC: 56.76

Number of Fisher Scoring iterations: 4


&gt; ## Peptic Ulcers and Blood Groups
&gt; counts &lt;- c(579, 4219, 911, 4578, 246, 3775, 361, 4532, 291, 5261, 396, 6598)

&gt; group &lt;- gl(2, 1, 12, labels=c(&quot;cases&quot;,&quot;controls&quot;))

&gt; blood &lt;- gl(2, 2, 12, labels=c(&quot;A&quot;,&quot;O&quot;))

&gt; city  &lt;- gl(3, 4, 12, labels=c(&quot;London&quot;,&quot;Manchester&quot;,&quot;Newcastle&quot;))

&gt; cbind(group, blood, city, counts) # gives internal codes for the factors
      group blood city counts
 [1,]     1     1    1    579
 [2,]     2     1    1   4219
 [3,]     1     2    1    911
 [4,]     2     2    1   4578
 [5,]     1     1    2    246
 [6,]     2     1    2   3775
 [7,]     1     2    2    361
 [8,]     2     2    2   4532
 [9,]     1     1    3    291
[10,]     2     1    3   5261
[11,]     1     2    3    396
[12,]     2     2    3   6598

&gt; summary(z1 &lt;- glm(counts ~ group*(city + blood), family=poisson()))

Call:
glm(formula = counts ~ group * (city + blood), family = poisson())

Deviance Residuals: 
     1       2       3       4       5       6       7       8       9  
-0.752   3.018   0.610  -2.814   0.171  -0.434  -0.141   0.398   0.932  
    10      11      12  
-2.269  -0.774   2.065  

Coefficients:
                             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)                    6.3924     0.0348  183.92  &lt; 2e-16 ***
groupcontrols                  1.9081     0.0369   51.69  &lt; 2e-16 ***
cityManchester                -0.8980     0.0482  -18.65  &lt; 2e-16 ***
cityNewcastle                 -0.7742     0.0461  -16.79  &lt; 2e-16 ***
bloodO                         0.4019     0.0387   10.39  &lt; 2e-16 ***
groupcontrols:cityManchester   0.8407     0.0505   16.64  &lt; 2e-16 ***
groupcontrols:cityNewcastle    1.0729     0.0482   22.25  &lt; 2e-16 ***
groupcontrols:bloodO          -0.2321     0.0404   -5.74  9.5e-09 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 26717.157  on 11  degrees of freedom
Residual deviance:    29.241  on  4  degrees of freedom
AIC: 154.3

Number of Fisher Scoring iterations: 3


&gt; summary(z2 &lt;- glm(counts ~ group*city + blood, family=poisson()),
+         correlation = TRUE)

Call:
glm(formula = counts ~ group * city + blood, family = poisson())

Deviance Residuals: 
     1       2       3       4       5       6       7       8       9  
-3.769   3.717   3.281  -3.442  -1.767   0.239   1.557  -0.217  -1.146  
    10      11      12  
-1.469   1.022   1.328  

Coefficients:
                             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)                    6.5139     0.0266   244.6   &lt;2e-16 ***
groupcontrols                  1.7756     0.0280    63.4   &lt;2e-16 ***
cityManchester                -0.8980     0.0482   -18.6   &lt;2e-16 ***
cityNewcastle                 -0.7742     0.0461   -16.8   &lt;2e-16 ***
bloodO                         0.1899     0.0113    16.8   &lt;2e-16 ***
groupcontrols:cityManchester   0.8407     0.0505    16.6   &lt;2e-16 ***
groupcontrols:cityNewcastle    1.0729     0.0482    22.2   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 26717.157  on 11  degrees of freedom
Residual deviance:    62.558  on  5  degrees of freedom
AIC: 185.6

Number of Fisher Scoring iterations: 4

Correlation of Coefficients:
                             (Intercept) groupcontrols cityManchester
groupcontrols                -0.90                                   
cityManchester               -0.52        0.50                       
cityNewcastle                -0.55        0.52          0.30         
bloodO                       -0.23        0.00          0.00         
groupcontrols:cityManchester  0.50       -0.55         -0.95         
groupcontrols:cityNewcastle   0.52       -0.58         -0.29         
                             cityNewcastle bloodO
groupcontrols                                    
cityManchester                                   
cityNewcastle                                    
bloodO                        0.00               
groupcontrols:cityManchester -0.29          0.00 
groupcontrols:cityNewcastle  -0.96          0.00 
                             groupcontrols:cityManchester
groupcontrols                                            
cityManchester                                           
cityNewcastle                                            
bloodO                                                   
groupcontrols:cityManchester                             
groupcontrols:cityNewcastle   0.32                       


&gt; anova(z2, z1, test = &quot;Chisq&quot;)
Analysis of Deviance Table

Model 1: counts ~ group * city + blood
Model 2: counts ~ group * (city + blood)
  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)    
1         5       62.6                         
2         4       29.2  1     33.3  7.8e-09 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
</code></pre>

<h4>Activity 1.2.3: R as a calculator</h4>

<p>Addition</p>

<pre><code class="r">7 + 3
</code></pre>

<pre><code>[1] 10
</code></pre>

<p>Subtraction</p>

<pre><code class="r">7 - 3
</code></pre>

<pre><code>[1] 4
</code></pre>

<p>Multiplication</p>

<pre><code class="r">7 * 3
</code></pre>

<pre><code>[1] 21
</code></pre>

<p>Division</p>

<pre><code class="r">7 / 3
</code></pre>

<pre><code>[1] 2.333
</code></pre>

<p>Integer division</p>

<pre><code class="r">7 %/% 3
</code></pre>

<pre><code>[1] 2
</code></pre>

<p>Division remainder (the modulo)</p>

<pre><code class="r">7 %% 3
</code></pre>

<pre><code>[1] 1
</code></pre>

<p>exponentiation</p>

<pre><code class="r">exp(7)
</code></pre>

<pre><code>[1] 1097
</code></pre>

<p>Natural logarithm</p>

<pre><code class="r">log(7)
</code></pre>

<pre><code>[1] 1.946
</code></pre>

<p>Base 10 log</p>

<pre><code class="r">log10(1000)
</code></pre>

<pre><code>[1] 3
</code></pre>

<p>Examples of common mathematical functions and constants</p>

<pre><code class="r">sqrt(16)
</code></pre>

<pre><code>[1] 4
</code></pre>

<pre><code class="r">cos(pi)
</code></pre>

<pre><code>[1] -1
</code></pre>

<p>Powers:  2 to the 5th</p>

<pre><code class="r">2^5
</code></pre>

<pre><code>[1] 32
</code></pre>

<p>Large and small numbers</p>

<pre><code class="r">1.7e+05
</code></pre>

<pre><code>[1] 170000
</code></pre>

<pre><code class="r">1.7e-03
</code></pre>

<pre><code>[1] 0.0017
</code></pre>

<p>And there are numerous statistical functions.  For example:
The probability a standard normal random variable takes
a value of 1.96 or lower:</p>

<pre><code class="r">pnorm(1.96)
</code></pre>

<pre><code>[1] 0.975
</code></pre>

<p>And the probability of 4 heads in 12 fair coin flips</p>

<pre><code class="r">dbinom(4, 12, 0.5)
</code></pre>

<pre><code>[1] 0.1208
</code></pre>

<p>And, best of all, it handles division by 0 gracefully :)</p>

<pre><code class="r">1 / 0
</code></pre>

<pre><code>[1] Inf
</code></pre>

</div>


<div class='tab-pane' id='activity-13-data-structures'>
<h3>Activity 1.3: Data Structures</h3>

<h1></h1>

<h4>Activity 1.3.1:  Numeric vectors</h4>

<p>Numeric vectors are the fundamental building blocks of R. Most of the techniques shown in this activity apply to any type of vector, be it a numeric, character, or logical vector.</p>

<p>Suppose you wish to create an object &#39;x&#39; and assign it a value of 5.  There are two ways to do this:</p>

<pre><code class="r">x = 5
x &lt;- 5
</code></pre>

<p>Display the object:</p>

<pre><code class="r">x
</code></pre>

<pre><code>[1] 5
</code></pre>

<p>Note that R is CaSe SenSiTivE!</p>

<pre><code class="r">w &lt;- 10
W &lt;- 12
</code></pre>

<p>The <code>cat()</code> function prints text to the screen, which is useful for writing. messages</p>

<pre><code class="r">cat(&quot;Little w =&quot;, w, &quot;is different than big W =&quot;, W, &quot;\n&quot;)
</code></pre>

<pre><code>Little w = 10 is different than big W = 12 
</code></pre>

<p>You can create a numeric vector from 1 to 6 in three different ways.</p>

<pre><code class="r">x0 &lt;- c(1, 2, 3, 4, 5, 6)
x1 &lt;- seq(1, 6, by = 1)
x2 &lt;- 1:6
</code></pre>

<p>View these three objects:</p>

<pre><code class="r">x0
</code></pre>

<pre><code>[1] 1 2 3 4 5 6
</code></pre>

<pre><code class="r">x1
</code></pre>

<pre><code>[1] 1 2 3 4 5 6
</code></pre>

<pre><code class="r">x2
</code></pre>

<pre><code>[1] 1 2 3 4 5 6
</code></pre>

<p>Here&#39;s a sequence from 1 to 22 stepping by 3.</p>

<pre><code class="r">x &lt;- seq(1, 22, by = 3)
x
</code></pre>

<pre><code>[1]  1  4  7 10 13 16 19 22
</code></pre>

<p>This operation will square the elements of x. This is a &#39;vectorized&#39; calculation. This means it squares each element indvidually and so there is no need to loop over each element.</p>

<pre><code class="r">y &lt;- x^2
y
</code></pre>

<pre><code>[1]   1  16  49 100 169 256 361 484
</code></pre>

<p>Assign a value to m:</p>

<pre><code class="r">m = 0.5
</code></pre>

<p>Another vectorized calculation:  multiple each element of <code>y</code> by <code>m</code>:</p>

<pre><code class="r">y * m
</code></pre>

<pre><code>[1]   0.5   8.0  24.5  50.0  84.5 128.0 180.5 242.0
</code></pre>

<p>Take the natural logarithm of each element of <code>y</code>:</p>

<pre><code class="r">log(y)
</code></pre>

<pre><code>[1] 0.000 2.773 3.892 4.605 5.130 5.545 5.889 6.182
</code></pre>

<p>Add two sequences together, elementwise:</p>

<pre><code class="r">1:3 + 2:4
</code></pre>

<pre><code>[1] 3 5 7
</code></pre>

<p>Suppose a vector is so long that we don&#39;t want to display all of it. Let&#39;s create a vector of 500 random numbers from a normal distribution with mean of 3 and standard deviation of 2.</p>

<pre><code class="r">x &lt;- rnorm(500, mean = 3, sd = 2)
</code></pre>

<p>The <code>str()</code> (structure) function tells us what type of object <code>x</code> is and provides some examples of the first few values.</p>

<pre><code class="r">str(x)
</code></pre>

<pre><code> num [1:500] 2.91 6.65 3.89 3.78 3.5 ...
</code></pre>

<p>The <code>length()</code> function returns the number of elements in <code>ÃŸx</code>.</p>

<pre><code class="r">length(x)
</code></pre>

<pre><code>[1] 500
</code></pre>

<p>We can calculate the sum, mean, max, min, and standard deviation.</p>

<pre><code class="r">sum(x)
</code></pre>

<pre><code>[1] 1537
</code></pre>

<pre><code class="r">mean(x)
</code></pre>

<pre><code>[1] 3.073
</code></pre>

<pre><code class="r">max(x)
</code></pre>

<pre><code>[1] 8.285
</code></pre>

<pre><code class="r">min(x)
</code></pre>

<pre><code>[1] -3.555
</code></pre>

<pre><code class="r">sd(x)
</code></pre>

<pre><code>[1] 2.001
</code></pre>

<p>The <code>summary()</code> function provides summary statistics.</p>

<pre><code class="r">summary(x)
</code></pre>

<pre><code>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  -3.56    1.95    3.14    3.07    4.44    8.28 
</code></pre>

<p>The <code>head()</code> and <code>tail()</code> functions shows the first or last 6 elements, respectively.</p>

<pre><code class="r">head(x)
</code></pre>

<pre><code>[1] 2.912 6.651 3.893 3.777 3.500 1.876
</code></pre>

<pre><code class="r">tail(x)
</code></pre>

<pre><code>[1] 3.589 6.466 2.226 0.181 2.955 2.131
</code></pre>

<p>We can easily extract elements of vectors.  For example, let&#39;s grab the 7th element of <code>y</code>:</p>

<pre><code class="r">y &lt;- 1:10
y[7]
</code></pre>

<pre><code>[1] 7
</code></pre>

<p>Or let&#39;s select the 1st, 3rd, and 5th elements of <code>y</code>:</p>

<pre><code class="r">y[c(1,3,5)]
</code></pre>

<pre><code>[1] 1 3 5
</code></pre>

<p>Or the 6th through 8th elements:</p>

<pre><code class="r">y[6:8]
</code></pre>

<pre><code>[1] 6 7 8
</code></pre>

<p>To select elements that are less than 4, we first make an indicator, which 
is a vector of TRUE and FALSE elements indicating whether the elements are 
less than 4.</p>

<pre><code class="r">indicator &lt;- y &lt; 4
indicator
</code></pre>

<pre><code> [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
</code></pre>

<p>And now we select elements that are less than 4 from y:</p>

<pre><code class="r">y[indicator]
</code></pre>

<pre><code>[1] 1 2 3
</code></pre>

<p>Another useful tool for generating vectors is the <code>rep()</code> function.  A 
vector of seven 1&#39;s:</p>

<pre><code class="r">z &lt;- rep(1, 7)
z
</code></pre>

<pre><code>[1] 1 1 1 1 1 1 1
</code></pre>

<p>A sequence of 1 to 5, repeated twice</p>

<pre><code class="r">rep(1:5, 2)
</code></pre>

<pre><code> [1] 1 2 3 4 5 1 2 3 4 5
</code></pre>

<p>Another style of repeating, elementwise</p>

<pre><code class="r">rep(1:5, each = 2)
</code></pre>

<pre><code> [1] 1 1 2 2 3 3 4 4 5 5
</code></pre>

<h4>Exercise 1.3.1:  Numeric Vectors</h4>

<p>1) Create a vector from 3 to 11, in steps of 2</p>

<p>2) Create another vector from 12 to 4 in steps of -2</p>

<p>3) Display the last 2 elements of the second vector</p>

<p>4) Calculate the mean of the element-wise product of these
two vectors</p>

<h4>Activity 1.3.2:  Character vectors</h4>

<p>Character vectors allow you to store non-numeric data.  They are used in R all the time.</p>

<p>We refer to vectors of characters as strings. To create a character vector, we do the following:</p>

<pre><code class="r">x = c(&quot;this&quot;, &quot;that&quot;, &quot;those&quot;)
x
</code></pre>

<pre><code>[1] &quot;this&quot;  &quot;that&quot;  &quot;those&quot;
</code></pre>

<p>Extracting characters is the same as extracting elements.</p>

<pre><code class="r">x[2:3]
</code></pre>

<pre><code>[1] &quot;that&quot;  &quot;those&quot;
</code></pre>

<p>There are numerous functions for parsing, searching, and connecting text.  For example:</p>

<pre><code class="r">y &lt;- c(&quot;cat&quot;, &quot;dog&quot;, &quot;fish&quot;)
paste(x, y)
</code></pre>

<pre><code>[1] &quot;this cat&quot;   &quot;that dog&quot;   &quot;those fish&quot;
</code></pre>

<p>Or we can extract parts of the strings, known as substrings. In this case, we extract the first 3 letters of each element, beginning at position 1, ending at position 3.</p>

<pre><code class="r">substr(x, 1, 3)
</code></pre>

<pre><code>[1] &quot;thi&quot; &quot;tha&quot; &quot;tho&quot;
</code></pre>

<p>Count the number of characters in each element:</p>

<pre><code class="r">nchar(x)
</code></pre>

<pre><code>[1] 4 4 5
</code></pre>

<p>Search for the string &quot;s&quot; in each element of <code>x</code> and return a logical vector.</p>

<pre><code class="r">sIndicator &lt;- grepl(&quot;s&quot;, x)
sIndicator
</code></pre>

<pre><code>[1]  TRUE FALSE  TRUE
</code></pre>

<p>Select only those words that have &quot;s&quot;</p>

<pre><code class="r">x[sIndicator]
</code></pre>

<pre><code>[1] &quot;this&quot;  &quot;those&quot;
</code></pre>

<p>We can test if a value is in the string using <code>%in%</code>. Here, we use an indicator
variable to subset the original vector.</p>

<pre><code class="r">mammalIndicator &lt;- y %in% c(&quot;cat&quot;, &quot;dog&quot;)
mammalIndicator
</code></pre>

<pre><code>[1]  TRUE  TRUE FALSE
</code></pre>

<p>Now select the mammals from y:</p>

<pre><code class="r">y[mammalIndicator]
</code></pre>

<pre><code>[1] &quot;cat&quot; &quot;dog&quot;
</code></pre>

<p>Regarding quotes:  R will accept double or single quotes for all character 
strings.  Use both in the same statement if you need to nest them.</p>

<pre><code class="r">x &lt;- &quot;A string with &#39;inner quotes&#39;&quot;
x
</code></pre>

<pre><code>[1] &quot;A string with &#39;inner quotes&#39;&quot;
</code></pre>

<pre><code class="r">cat(x, &quot;\n&quot;)
</code></pre>

<pre><code>A string with &#39;inner quotes&#39; 
</code></pre>

<h4>Exercise 1.3.2:  Character vectors</h4>

<p>1) Create a character vector consisting of nouns (of the
length of your choosing)</p>

<p>2) Create a second character vector of same length with verbs</p>

<p>3) Paste the two vectors together</p>

<p>4) Count the total number of characters in the entire noun
vector.  Hint, use the <code>sum</code> function</p>

<h4>Activity 1.3.3:  Logical vectors</h4>

<p>Logical, or boolean, vectors are used to select subsets of data and define 
logical expressions in R programming.</p>

<p>To create a logical vector:</p>

<pre><code class="r">z &lt;- c(TRUE, FALSE, TRUE, TRUE)
z
</code></pre>

<pre><code>[1]  TRUE FALSE  TRUE  TRUE
</code></pre>

<p>Or, equivalently:</p>

<pre><code class="r">z &lt;- c(T, F, T, T)
z
</code></pre>

<pre><code>[1]  TRUE FALSE  TRUE  TRUE
</code></pre>

<p>We can select elements like any other vector.</p>

<pre><code class="r">z[c(2,4)]
</code></pre>

<pre><code>[1] FALSE  TRUE
</code></pre>

<p>The which() function returns the indexes of a logical vector that are TRUE.</p>

<pre><code class="r">which(z)
</code></pre>

<pre><code>[1] 1 3 4
</code></pre>

<p>And we can summarize over each element in the vector.  For example, the 
<code>any()</code> function returns TRUE if any elements are TRUE.</p>

<pre><code class="r">any(z)
</code></pre>

<pre><code>[1] TRUE
</code></pre>

<p>And the <code>all()</code> function returns TRUE if all elments are TRUE.</p>

<pre><code class="r">all(z)
</code></pre>

<pre><code>[1] FALSE
</code></pre>

<p>We can also count the number of true values in a logical vector using the 
<code>sum()</code> function.</p>

<pre><code class="r">sum(z)
</code></pre>

<pre><code>[1] 3
</code></pre>

<p>And we can negate a logical vector:</p>

<pre><code class="r">!z
</code></pre>

<pre><code>[1] FALSE  TRUE FALSE FALSE
</code></pre>

<p>Let&#39;s create another logical vector, which will be TRUE for the elements of 
1,2,3,4 that are &lt;= 2.</p>

<pre><code class="r">y &lt;- 1:4 &lt;= 2
y
</code></pre>

<pre><code>[1]  TRUE  TRUE FALSE FALSE
</code></pre>

<p>We can perform &#39;and&#39; comparisons betwen two logical vectors, elementwise:</p>

<pre><code class="r">z &amp; y
</code></pre>

<pre><code>[1]  TRUE FALSE FALSE FALSE
</code></pre>

<p>As well as &#39;or&#39; comparisons, elementwise:</p>

<pre><code class="r">z | y
</code></pre>

<pre><code>[1] TRUE TRUE TRUE TRUE
</code></pre>

<h4>Exercise 1.3.3:  Logical vectors</h4>

<p>1) Create random numeric vector of length 1000 with values
uniformly chosen between 0 and 1.  Hint: use the &#39;runif&#39;
function</p>

<p>2) Count the number of elements in the vector that
fall in the interval [0.2, 0.8].  On average, it should
be 600</p>

<h4>Activity 1.3.4:  Integer and complex vectors</h4>

<p>For most applications in R, it will likely not make a difference if you 
represent integer values as &#39;numeric&#39;. The difference between the &#39;integer&#39; 
and &#39;numeric&#39; classes is that objects of class &#39;integer&#39; are coded
as type &#39;int&#39; in the primitive C or Fortran code that is running underneath 
the R interpeter, and objects of class &#39;numeric&#39; are usually typed as 
&#39;double&#39;.  But it might be important to you in some cases.</p>

<p>Notice this results in an integer:</p>

<pre><code class="r">x &lt;- 1:3
str(x)
</code></pre>

<pre><code> int [1:3] 1 2 3
</code></pre>

<pre><code class="r">is.integer(x)
</code></pre>

<pre><code>[1] TRUE
</code></pre>

<p>Whereas these end up being numeric:</p>

<pre><code class="r">str(c(1, 2, 3))
</code></pre>

<pre><code> num [1:3] 1 2 3
</code></pre>

<pre><code class="r">str(seq(1, 3, 1))
</code></pre>

<pre><code> num [1:3] 1 2 3
</code></pre>

<p>There are two fullproof ways to create integer vectors. Here are two identical approaches:</p>

<pre><code class="r">x1 &lt;- as.integer(c(1, 5, -2))
x2 &lt;- c(1L, 5L, -2L)
x1
</code></pre>

<pre><code>[1]  1  5 -2
</code></pre>

<pre><code class="r">x2
</code></pre>

<pre><code>[1]  1  5 -2
</code></pre>

<p>Note how they are identical (not juse in value, but also in type).</p>

<pre><code class="r">identical(x1, x2)
</code></pre>

<pre><code>[1] TRUE
</code></pre>

<p>Whereas if we create a numeric vector, they are not identical because x1 is 
of class &#39;integer&#39; and x3 is of class &#39;numeric&#39;.</p>

<pre><code class="r">x3 &lt;- c(1, 2, 3)
identical(x1, x3)
</code></pre>

<pre><code>[1] FALSE
</code></pre>

<p>R can also store and perform mathematical operations with complex values 
<code>(a + bi)</code>.  Here&#39;s a complex vector:</p>

<pre><code class="r">v1 &lt;- complex(real = 1:3, imaginary = 4:6)
v1
</code></pre>

<pre><code>[1] 1+4i 2+5i 3+6i
</code></pre>

<pre><code class="r">str(v1)
</code></pre>

<pre><code> cplx [1:3] 1+4i 2+5i 3+6i
</code></pre>

<p>And here are some operations on the complex vector, the sum, and extracting 
the real and imaginary portions of the vector:</p>

<pre><code class="r">sum(v1)
</code></pre>

<pre><code>[1] 6+15i
</code></pre>

<pre><code class="r">Re(v1)
</code></pre>

<pre><code>[1] 1 2 3
</code></pre>

<pre><code class="r">Im(v1)
</code></pre>

<pre><code>[1] 4 5 6
</code></pre>

<p>Type <code>?complex</code> in R for more details.</p>

<h4>Activity 1.3.5:  Named vectors</h4>

<p>The elements of vectors in R can be named for convenience.
Here&#39;s how to create a named vector.</p>

<pre><code class="r">aNamedVec &lt;- c(type = 1, count = 7, max = 10)
aNamedVec
</code></pre>

<pre><code> type count   max 
    1     7    10 
</code></pre>

<p>You can also assign names using quoted strings, which can include spaces 
or special characters:</p>

<pre><code class="r">bNamedVec &lt;- c(&quot;a type&quot; = 1, &quot;b%type&quot; = 7)
bNamedVec
</code></pre>

<pre><code>a type b%type 
     1      7 
</code></pre>

<p>And you can extract elements of a named vector by the names. Notice how the 
name is displayed, along with the value of the vector.</p>

<pre><code class="r">aNamedVec[&quot;type&quot;]
</code></pre>

<pre><code>type 
   1 
</code></pre>

<p>Suppose you would like extract the element without the name. You can do this 
using the &#39;double brace&#39; syntax:</p>

<pre><code class="r">aNamedVec[[&quot;type&quot;]]
</code></pre>

<pre><code>[1] 1
</code></pre>

<p>And you can extract more than one element:</p>

<pre><code class="r">aNamedVec[c(&quot;type&quot;, &quot;max&quot;)]
</code></pre>

<pre><code>type  max 
   1   10 
</code></pre>

<p>But attempting to strip the names when you extract more than one element doesn&#39;t work:</p>

<pre><code class="r">try(aNamedVec[[c(&quot;type&quot;, &quot;max&quot;)]])
</code></pre>

<p>Speaking of removing names, here&#39;s how you can do that:</p>

<pre><code class="r">names(aNamedVec) &lt;- NULL
aNamedVec
</code></pre>

<pre><code>[1]  1  7 10
</code></pre>

<p>And you can use <code>names()</code> to put the names back in again, or to change the names.</p>

<pre><code class="r">names(aNamedVec) &lt;- c(&quot;type1&quot;, &quot;count1&quot;, &quot;max1&quot;)
aNamedVec
</code></pre>

<pre><code> type1 count1   max1 
     1      7     10 
</code></pre>

<p>And you can extract the names as well.</p>

<pre><code class="r">names(aNamedVec)
</code></pre>

<pre><code>[1] &quot;type1&quot;  &quot;count1&quot; &quot;max1&quot;  
</code></pre>

<p>These naming principles apply to any type of vector: integer, numeric, 
character, logical, or complex.</p>

<h4>Exercise 1.3.5: Named vectors</h4>

<p>1) Create a named character vector of length 3</p>

<p>2) Create a second named logical vector of length 3</p>

<p>3) Switch the names of the 2 vectors</p>

<h4>Activity 1.3.6:  Data frames</h4>

<p>Data frames consist of rows and columns (like a spreadsheet). They are the most
common way to store data in R.  Columns can be of any type:  numeric, 
character, logical, complex, or factors. (We haven&#39;t learned about 
factors--that&#39;s a more advanced topic).</p>

<p>Here&#39;s how we could manually create a simple data frame.</p>

<pre><code class="r">df &lt;- data.frame(a = 1:6, b = letters[1:6],
                 c = rep(c(TRUE, FALSE), each = 3))
df
</code></pre>

<pre><code>  a b     c
1 1 a  TRUE
2 2 b  TRUE
3 3 c  TRUE
4 4 d FALSE
5 5 e FALSE
6 6 f FALSE
</code></pre>

<p>And here&#39;s a more interesting data frame with the specs of various automobiles 
that is included in the datasets package that comes with R:</p>

<pre><code class="r">mtcars
</code></pre>

<pre><code>                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb
Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1
Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4
Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4
Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3
Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3
Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3
Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4
Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4
Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4
Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1
Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1
Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2
AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2
Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4
Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2
Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1
Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2
Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2
Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4
Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6
Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8
Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2
</code></pre>

<p>There are a number of tools to extract info from data frames and create subsets.</p>

<p>The <code>str()</code> function tells the names and types of variables in the data frame.</p>

<pre><code class="r">str(mtcars)
</code></pre>

<pre><code>&#39;data.frame&#39;:   32 obs. of  11 variables:
 $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
 $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...
 $ disp: num  160 160 108 258 360 ...
 $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...
 $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...
 $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...
 $ qsec: num  16.5 17 18.6 19.4 17 ...
 $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...
 $ am  : num  1 1 1 0 0 0 0 0 0 0 ...
 $ gear: num  4 4 4 3 3 3 3 4 4 4 ...
 $ carb: num  4 4 1 1 2 1 4 2 2 4 ...
</code></pre>

<p>Use <code>head()</code> to look at the first 6 rows of the data frame.</p>

<pre><code class="r">head(mtcars)
</code></pre>

<pre><code>                   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
</code></pre>

<p>We can display the number of rows:</p>

<pre><code class="r">nrow(mtcars)
</code></pre>

<pre><code>[1] 32
</code></pre>

<p>We can display the number of columns:</p>

<pre><code class="r">ncol(mtcars)
</code></pre>

<pre><code>[1] 11
</code></pre>

<p>We can extract the row names as a character vector:</p>

<pre><code class="r">rownames(mtcars)
</code></pre>

<pre><code> [1] &quot;Mazda RX4&quot;           &quot;Mazda RX4 Wag&quot;       &quot;Datsun 710&quot;         
 [4] &quot;Hornet 4 Drive&quot;      &quot;Hornet Sportabout&quot;   &quot;Valiant&quot;            
 [7] &quot;Duster 360&quot;          &quot;Merc 240D&quot;           &quot;Merc 230&quot;           
[10] &quot;Merc 280&quot;            &quot;Merc 280C&quot;           &quot;Merc 450SE&quot;         
[13] &quot;Merc 450SL&quot;          &quot;Merc 450SLC&quot;         &quot;Cadillac Fleetwood&quot; 
[16] &quot;Lincoln Continental&quot; &quot;Chrysler Imperial&quot;   &quot;Fiat 128&quot;           
[19] &quot;Honda Civic&quot;         &quot;Toyota Corolla&quot;      &quot;Toyota Corona&quot;      
[22] &quot;Dodge Challenger&quot;    &quot;AMC Javelin&quot;         &quot;Camaro Z28&quot;         
[25] &quot;Pontiac Firebird&quot;    &quot;Fiat X1-9&quot;           &quot;Porsche 914-2&quot;      
[28] &quot;Lotus Europa&quot;        &quot;Ford Pantera L&quot;      &quot;Ferrari Dino&quot;       
[31] &quot;Maserati Bora&quot;       &quot;Volvo 142E&quot;         
</code></pre>

<p>We can extract the colum names as a character vector:</p>

<pre><code class="r">colnames(mtcars)
</code></pre>

<pre><code> [1] &quot;mpg&quot;  &quot;cyl&quot;  &quot;disp&quot; &quot;hp&quot;   &quot;drat&quot; &quot;wt&quot;   &quot;qsec&quot; &quot;vs&quot;   &quot;am&quot;   &quot;gear&quot;
[11] &quot;carb&quot;
</code></pre>

<p>And we can see summaries of each column:</p>

<pre><code class="r">summary(mtcars)
</code></pre>

<pre><code>      mpg            cyl            disp             hp       
 Min.   :10.4   Min.   :4.00   Min.   : 71.1   Min.   : 52.0  
 1st Qu.:15.4   1st Qu.:4.00   1st Qu.:120.8   1st Qu.: 96.5  
 Median :19.2   Median :6.00   Median :196.3   Median :123.0  
 Mean   :20.1   Mean   :6.19   Mean   :230.7   Mean   :146.7  
 3rd Qu.:22.8   3rd Qu.:8.00   3rd Qu.:326.0   3rd Qu.:180.0  
 Max.   :33.9   Max.   :8.00   Max.   :472.0   Max.   :335.0  
      drat            wt            qsec            vs       
 Min.   :2.76   Min.   :1.51   Min.   :14.5   Min.   :0.000  
 1st Qu.:3.08   1st Qu.:2.58   1st Qu.:16.9   1st Qu.:0.000  
 Median :3.69   Median :3.33   Median :17.7   Median :0.000  
 Mean   :3.60   Mean   :3.22   Mean   :17.8   Mean   :0.438  
 3rd Qu.:3.92   3rd Qu.:3.61   3rd Qu.:18.9   3rd Qu.:1.000  
 Max.   :4.93   Max.   :5.42   Max.   :22.9   Max.   :1.000  
       am             gear           carb     
 Min.   :0.000   Min.   :3.00   Min.   :1.00  
 1st Qu.:0.000   1st Qu.:3.00   1st Qu.:2.00  
 Median :0.000   Median :4.00   Median :2.00  
 Mean   :0.406   Mean   :3.69   Mean   :2.81  
 3rd Qu.:1.000   3rd Qu.:4.00   3rd Qu.:4.00  
 Max.   :1.000   Max.   :5.00   Max.   :8.00  
</code></pre>

<p>We can subset a data frame similar to the way we extracted elements from 
vectors.  For example, let&#39;s extract the 3rd row and 4th column of mtcars</p>

<pre><code class="r">mtcars[3, 4]
</code></pre>

<pre><code>[1] 93
</code></pre>

<p>Equivalently, we could have used the row and column name to extract the data:</p>

<pre><code class="r">mtcars[&quot;Datsun 710&quot;, &quot;hp&quot;]
</code></pre>

<pre><code>[1] 93
</code></pre>

<p>In general, using the row and column name is a better programming practice 
than using just the row or column numbers because it makes code easier to 
read and there&#39;s no mistaking which rows or columns were selected.</p>

<p>These two statements give the same result. </p>

<pre><code class="r">mtcars[3:5, ]
</code></pre>

<pre><code>                   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
</code></pre>

<pre><code class="r">mtcars[c(&quot;Datsun 710&quot;, &quot;Hornet 4 Drive&quot;, &quot;Hornet Sportabout&quot;),]
</code></pre>

<pre><code>                   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
</code></pre>

<p>Or extract multiple rows and columns simultaneously.
These are equivalent:</p>

<pre><code class="r">mtcars[c(1,30), c(1, 5:7)]
</code></pre>

<pre><code>              mpg drat   wt  qsec
Mazda RX4    21.0 3.90 2.62 16.46
Ferrari Dino 19.7 3.62 2.77 15.50
</code></pre>

<pre><code class="r">mtcars[c(&quot;Mazda RX4&quot;, &quot;Ferrari Dino&quot;), c(&quot;mpg&quot;, &quot;drat&quot;,
                                         &quot;wt&quot;, &quot;qsec&quot;)]
</code></pre>

<pre><code>              mpg drat   wt  qsec
Mazda RX4    21.0 3.90 2.62 16.46
Ferrari Dino 19.7 3.62 2.77 15.50
</code></pre>

<p>Suppose we wish to look at the vehicles that have high power but still good gas mileage: e.g. cars with <code>horsepower &gt; 150</code> and <code>mpg &gt; 15</code>.</p>

<pre><code class="r">indicator &lt;- (mtcars[,&quot;hp&quot;] &gt; 150) &amp; (mtcars[,&quot;mpg&quot;] &gt; 15)
mtcars[indicator, c(&quot;hp&quot;, &quot;mpg&quot;)]
</code></pre>

<pre><code>                   hp  mpg
Hornet Sportabout 175 18.7
Merc 450SE        180 16.4
Merc 450SL        180 17.3
Merc 450SLC       180 15.2
Pontiac Firebird  175 19.2
Ford Pantera L    264 15.8
Ferrari Dino      175 19.7
</code></pre>

<p>Suppose we wish to exclude Japanese-made cars from the data:</p>

<pre><code class="r">japanese &lt;- c(&quot;Mazda RX4&quot;, &quot;Mazda RX4 Wag&quot;, &quot;Datsun 710&quot;,
              &quot;Honda Civic&quot;, &quot;Toyota Corolla&quot;, &quot;Toyota Corona&quot;)
japaneseInd &lt;- rownames(mtcars) %in% japanese
nonJapan &lt;- mtcars[!japaneseInd,]
</code></pre>

<p>Did we get them all?  If so, these two numbers should be the same:</p>

<pre><code class="r">nrow(mtcars) - nrow(nonJapan)
</code></pre>

<pre><code>[1] 6
</code></pre>

<pre><code class="r">length(japanese)
</code></pre>

<pre><code>[1] 6
</code></pre>

<p>And as if there weren&#39;t enough options, a single column can be extracted 
from a data frame using the $.
For example, let&#39;s get the number of gears.</p>

<pre><code class="r">gears &lt;- mtcars$gear
</code></pre>

<p>Notice it&#39;s a numeric vector.</p>

<pre><code class="r">str(gears)
</code></pre>

<pre><code> num [1:32] 4 4 4 3 3 3 3 4 4 4 ...
</code></pre>

<p>And we can tabulate the number of vehicles with 3, 4, or 5 gears:</p>

<pre><code class="r">table(gears)
</code></pre>

<pre><code>gears
 3  4  5 
15 12  5 
</code></pre>

<p>Last of all, for variables that are discrete (with relatively few values, 
we might want to do a cross tabluation.  Here&#39;s an example comparing the 
number of gears to the number of cylinders.</p>

<pre><code class="r">table(mtcars[,c(&quot;cyl&quot;, &quot;gear&quot;)])
</code></pre>

<pre><code>   gear
cyl  3  4  5
  4  1  8  2
  6  2  4  1
  8 12  0  2
</code></pre>

<h4>Exercise 1.3.6: Data frames</h4>

<p>1) Create a data frame with at least 7 rows with the
following columns:
    1. A character vector consisting of some repetition of
       the letters &#39;a&#39;, &#39;b&#39; and &#39;c&#39;
    2. A numeric vector of randomly generated numbers between
       0 and 1.  Hint:  use runif()
    3. A second numeric vector of randomly generated numbers
       between 2 and 7.  Hint: use runif() again</p>

<p>2) Display the number of rows of the data frame</p>

<p>3) Assign rownames consisting of capital letters, &#39;A&#39;, &#39;B&#39;,
    &#39;C&#39;, etc.  Hint, use the <code>LETTERS</code> object that is part of
    R</p>

<p>4) Display the second column of the fourth and fifth rows
    using the row and column names of the data frame</p>

<p>5) Create a subset of the data by selecting those observations
    meet all of the following criteria:
    a.  The character vector has a value of &#39;b&#39; or &#39;c&#39;
    b.  The value of the first numeric vector is greater than
        0.1
    c.  The value of the second numeric vector is less than
        6.</p>

<h4>Activity 1.3.7: Matrices</h4>

<p>Matrices in R are similar to data frames, with one key
difference:  all elements in a data frame must be the same
type: either integer, numeric, character, logical, or complex.</p>

<p>Here is a simple matrix of integers.  Notice how R loads
the matrix columnwise by default.</p>

<pre><code class="r">m1 &lt;- matrix(1:15, nrow = 5, ncol = 3)
m1
</code></pre>

<pre><code>     [,1] [,2] [,3]
[1,]    1    6   11
[2,]    2    7   12
[3,]    3    8   13
[4,]    4    9   14
[5,]    5   10   15
</code></pre>

<pre><code class="r">str(m1)
</code></pre>

<pre><code> int [1:5, 1:3] 1 2 3 4 5 6 7 8 9 10 ...
</code></pre>

<p>We could also load the matrix rowwise:</p>

<pre><code class="r">m1 &lt;- matrix(1:15, nrow = 5, ncol = 3, byrow = TRUE)
m1
</code></pre>

<pre><code>     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    4    5    6
[3,]    7    8    9
[4,]   10   11   12
[5,]   13   14   15
</code></pre>

<p>We can add column names and rownames:</p>

<pre><code class="r">rownames(m1) &lt;- paste(&quot;Row&quot;, 1:5, sep = &quot;&quot;)
colnames(m1) &lt;- paste(&quot;Col&quot;, 1:3, sep = &quot;&quot;)
m1
</code></pre>

<pre><code>     Col1 Col2 Col3
Row1    1    2    3
Row2    4    5    6
Row3    7    8    9
Row4   10   11   12
Row5   13   14   15
</code></pre>

<p>Alternatively, we can add in the row and column names from
the start when we build the matrix using the <code>dimnames</code> argument.</p>

<pre><code class="r">m1 &lt;- matrix(1:15, nrow = 5, ncol = 3,
             dimnames = list(paste(&quot;Row&quot;, 1:5, sep = &quot;&quot;),
                             paste(&quot;Col&quot;, 1:3, sep = &quot;&quot;)))
m1
</code></pre>

<pre><code>     Col1 Col2 Col3
Row1    1    6   11
Row2    2    7   12
Row3    3    8   13
Row4    4    9   14
Row5    5   10   15
</code></pre>

<p>We can also use rownames() and colnames() to extract names from the matrix.</p>

<pre><code class="r">rownames(m1)
</code></pre>

<pre><code>[1] &quot;Row1&quot; &quot;Row2&quot; &quot;Row3&quot; &quot;Row4&quot; &quot;Row5&quot;
</code></pre>

<pre><code class="r">colnames(m1)
</code></pre>

<pre><code>[1] &quot;Col1&quot; &quot;Col2&quot; &quot;Col3&quot;
</code></pre>

<p>We can get summary information about the matrix, like the total number of 
elements, using <code>length()</code>.</p>

<pre><code class="r">length(m1)
</code></pre>

<pre><code>[1] 15
</code></pre>

<p>The number of columns:</p>

<pre><code class="r">ncol(m1)
</code></pre>

<pre><code>[1] 3
</code></pre>

<p>And the number of rows:</p>

<pre><code class="r">nrow(m1)
</code></pre>

<pre><code>[1] 5
</code></pre>

<p>As with data frames, we can extract elements using row and column names:</p>

<pre><code class="r">m1[c(&quot;Row1&quot;, &quot;Row3&quot;), c(&quot;Col1&quot;, &quot;Col2&quot;)]
</code></pre>

<pre><code>     Col1 Col2
Row1    1    6
Row3    3    8
</code></pre>

<p>Or we can extract using row/column indexes:</p>

<pre><code class="r">m1[c(1, 3), 1:2]
</code></pre>

<pre><code>     Col1 Col2
Row1    1    6
Row3    3    8
</code></pre>

<p>Likewise, we can create a matrix of of other types.  Let&#39;s  create a matrix 
of boolean values (logicals).  In this case, we&#39;ll start with a random vector 
of length 9 that consists of TRUEs and FALSEs using the sample() function.</p>

<pre><code class="r">x &lt;- sample(c(TRUE, FALSE), 9, replace = TRUE)
</code></pre>

<p>To build the matrix, notice that we only need to specify the number of rows, 
or the number of columns, but not both.
This is because the length of <code>x</code>, combined the row or column number is 
sufficient to define the matrix.</p>

<pre><code class="r">m2 &lt;- matrix(x, ncol = 3)
m2
</code></pre>

<pre><code>      [,1]  [,2]  [,3]
[1,] FALSE FALSE  TRUE
[2,] FALSE FALSE FALSE
[3,]  TRUE FALSE  TRUE
</code></pre>

<pre><code class="r">str(m2)
</code></pre>

<pre><code> logi [1:3, 1:3] FALSE FALSE TRUE FALSE FALSE FALSE ...
</code></pre>

<p>And you can melt a matrix back into a vector using <code>as.vector()</code>.</p>

<pre><code class="r">x1 &lt;- as.vector(m2)
x1
</code></pre>

<pre><code>[1] FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE  TRUE
</code></pre>

<pre><code class="r">identical(x, x1)
</code></pre>

<pre><code>[1] TRUE
</code></pre>

<p>You can also create a matrix of empty values.</p>

<pre><code class="r">matrix(NA,  ncol = 2, nrow = 2)
</code></pre>

<pre><code>     [,1] [,2]
[1,]   NA   NA
[2,]   NA   NA
</code></pre>

<p>Or a matrix of repeated values.</p>

<pre><code class="r">matrix(1,   ncol = 2, nrow = 2)
</code></pre>

<pre><code>     [,1] [,2]
[1,]    1    1
[2,]    1    1
</code></pre>

<pre><code class="r">matrix(1:2, ncol = 2, nrow = 2)
</code></pre>

<pre><code>     [,1] [,2]
[1,]    1    1
[2,]    2    2
</code></pre>

<p>But if the vector you provide doesn&#39;t divide evenly into the number of matrix elements, you get warned:</p>

<pre><code class="r">matrix(1:3, ncol = 2, nrow = 2)
</code></pre>

<pre><code>Warning: data length [3] is not a sub-multiple or multiple of the number
of rows [2]
</code></pre>

<pre><code>     [,1] [,2]
[1,]    1    3
[2,]    2    1
</code></pre>

<p>All the standard matrix operations are available in R. Let&#39;s create a set of conformable column vectors and matrices to illustrate:</p>

<pre><code class="r">v1 &lt;- 1:3
v2 &lt;- 4:6
m1 &lt;- matrix(c(3, 11, 16, 1, 4, 1, 4, 14, 19), nrow = 3)
m2 &lt;- matrix(1:9, ncol = 3)
</code></pre>

<p>Transpose the column vector to create a row vector.</p>

<pre><code class="r">t(v1)
</code></pre>

<pre><code>     [,1] [,2] [,3]
[1,]    1    2    3
</code></pre>

<p>Transpose the matrix.</p>

<pre><code class="r">t(m1)
</code></pre>

<pre><code>     [,1] [,2] [,3]
[1,]    3   11   16
[2,]    1    4    1
[3,]    4   14   19
</code></pre>

<p>Inner product of two vectors.  Notice it returns a 1 x 1 matrix.</p>

<pre><code class="r">t(v1) %*% v2
</code></pre>

<pre><code>     [,1]
[1,]   32
</code></pre>

<p>If you want to just have a simple vector (non-matrix) object returned after 
calculating the inner product:</p>

<pre><code class="r">as.vector(t(v1) %*% v2)
</code></pre>

<pre><code>[1] 32
</code></pre>

<p>Outer product of two vectors:</p>

<pre><code class="r">v1 %*% t(v2)
</code></pre>

<pre><code>     [,1] [,2] [,3]
[1,]    4    5    6
[2,]    8   10   12
[3,]   12   15   18
</code></pre>

<p>Matrix multiplication:</p>

<pre><code class="r">m1 %*% m2
</code></pre>

<pre><code>     [,1] [,2] [,3]
[1,]   17   41   65
[2,]   61  148  235
[3,]   75  183  291
</code></pre>

<p>Matrix inversion:</p>

<pre><code class="r">solve(m1)
</code></pre>

<pre><code>       [,1]    [,2]     [,3]
[1,] -5.636  1.3636  0.18182
[2,] -1.364  0.6364 -0.18182
[3,]  4.818 -1.1818 -0.09091
</code></pre>

<p>Calculate eigenvectors and eigenvalues:</p>

<pre><code class="r">eigen(m2)
</code></pre>

<pre><code>$values
[1]  1.612e+01 -1.117e+00 -5.701e-16

$vectors
        [,1]    [,2]    [,3]
[1,] -0.4645 -0.8829  0.4082
[2,] -0.5708 -0.2395 -0.8165
[3,] -0.6770  0.4039  0.4082
</code></pre>

<p>Calculate the determinant:</p>

<pre><code class="r">det(m1)
</code></pre>

<pre><code>[1] -11
</code></pre>

<p>Extract the diagonal elements:</p>

<pre><code class="r">diag(m2)
</code></pre>

<pre><code>[1] 1 5 9
</code></pre>

<p>Stack matrices on top of each other using &quot;row bind&quot;:</p>

<pre><code class="r">rbind(m1, m2)
</code></pre>

<pre><code>     [,1] [,2] [,3]
[1,]    3    1    4
[2,]   11    4   14
[3,]   16    1   19
[4,]    1    4    7
[5,]    2    5    8
[6,]    3    6    9
</code></pre>

<p>Join matrices side by side using &quot;column bind&quot;:</p>

<pre><code class="r">cbind(m1, m2)
</code></pre>

<pre><code>     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    3    1    4    1    4    7
[2,]   11    4   14    2    5    8
[3,]   16    1   19    3    6    9
</code></pre>

<p>By the way, <code>rbind()</code> and <code>cbind()</code> work the same way for data frames too, so 
long as the variable types and the dimensions of the data frames are conformable.</p>

<p>Elementwise arithmetic operations</p>

<pre><code class="r">m1 + m2
</code></pre>

<pre><code>     [,1] [,2] [,3]
[1,]    4    5   11
[2,]   13    9   22
[3,]   19    7   28
</code></pre>

<pre><code class="r">m1 - m2
</code></pre>

<pre><code>     [,1] [,2] [,3]
[1,]    2   -3   -3
[2,]    9   -1    6
[3,]   13   -5   10
</code></pre>

<pre><code class="r">m1 * m2
</code></pre>

<pre><code>     [,1] [,2] [,3]
[1,]    3    4   28
[2,]   22   20  112
[3,]   48    6  171
</code></pre>

<pre><code class="r">m1 / m2
</code></pre>

<pre><code>      [,1]   [,2]   [,3]
[1,] 3.000 0.2500 0.5714
[2,] 5.500 0.8000 1.7500
[3,] 5.333 0.1667 2.1111
</code></pre>

<p>Add all the elements in the matrix:</p>

<pre><code class="r">sum(m1)
</code></pre>

<pre><code>[1] 73
</code></pre>

<p>Take the product of all the elments in the matrix:</p>

<pre><code class="r">prod(m1)
</code></pre>

<pre><code>[1] 2247168
</code></pre>

<p>Calculate the sums of the rows, of the columns:</p>

<pre><code class="r">rowSums(m1)
</code></pre>

<pre><code>[1]  8 29 36
</code></pre>

<pre><code class="r">colSums(m1)
</code></pre>

<pre><code>[1] 30  6 37
</code></pre>

<p>Calculate the means of the rows, of the columns:</p>

<pre><code class="r">rowMeans(m1)
</code></pre>

<pre><code>[1]  2.667  9.667 12.000
</code></pre>

<pre><code class="r">colMeans(m1)
</code></pre>

<pre><code>[1] 10.00  2.00 12.33
</code></pre>

<p>Use the sums to get the same results as the rowMeans:</p>

<pre><code class="r">colSums(m1) / nrow(m1)
</code></pre>

<pre><code>[1] 10.00  2.00 12.33
</code></pre>

<p>Create a 5 x 5 identity matrix:</p>

<pre><code class="r">diag(5)
</code></pre>

<pre><code>     [,1] [,2] [,3] [,4] [,5]
[1,]    1    0    0    0    0
[2,]    0    1    0    0    0
[3,]    0    0    1    0    0
[4,]    0    0    0    1    0
[5,]    0    0    0    0    1
</code></pre>

<h4>Exercise 1.3.7: Matrices</h4>

<p>1) Create a 2 x 2 matrix with the following elements:
    (2, 4, 7, 1), loaded rowwise.</p>

<p>2) Calculate the trace (the sum of the diagonal elements)
    of the matrix.  Hint: use the <code>sum()</code> function</p>

<p>3) Create a column vector of length 2 with the elements
    (3, 5)</p>

<p>4) Using matrix multiplication, and your results from (1)
    and (3), find the product of the transpose of the column
    vector, the matrix, and the column vector.  Display the
    result should as a single number (not a 1 x 1 matrix).</p>

<h4>Activity 1.3.8: Lists</h4>

<p>Lists are one of the most flexible objects in R.  A list is
 a collection of R objects--and these objects do not have to
 be of any particular type or size.  These objects can even
 be other lists.</p>

<p>Let&#39;s build a simple list.  Notice how the elements are quite
 heterogenous (different data types, different lengths)</p>

<pre><code class="r">aList &lt;- list(a = 1:5, b = rep(TRUE, 2), c = letters[1:3])
aList
</code></pre>

<pre><code>$a
[1] 1 2 3 4 5

$b
[1] TRUE TRUE

$c
[1] &quot;a&quot; &quot;b&quot; &quot;c&quot;
</code></pre>

<pre><code class="r">str(aList)
</code></pre>

<pre><code>List of 3
 $ a: int [1:5] 1 2 3 4 5
 $ b: logi [1:2] TRUE TRUE
 $ c: chr [1:3] &quot;a&quot; &quot;b&quot; &quot;c&quot;
</code></pre>

<p>We can extract the names:</p>

<pre><code class="r">names(aList)
</code></pre>

<pre><code>[1] &quot;a&quot; &quot;b&quot; &quot;c&quot;
</code></pre>

<p>And we can assign new names:</p>

<pre><code class="r">names(aList) &lt;- c(&quot;a.new&quot;, &quot;b.new&quot;, &quot;c.new&quot;)
aList
</code></pre>

<pre><code>$a.new
[1] 1 2 3 4 5

$b.new
[1] TRUE TRUE

$c.new
[1] &quot;a&quot; &quot;b&quot; &quot;c&quot;
</code></pre>

<p>We can extract elements of the list using indexes, where
the double-brace [[]] notation removes the name.</p>

<pre><code class="r">aList[1]
</code></pre>

<pre><code>$a.new
[1] 1 2 3 4 5
</code></pre>

<pre><code class="r">aList[[1]]
</code></pre>

<pre><code>[1] 1 2 3 4 5
</code></pre>

<p>We can also extract elements by names:</p>

<pre><code class="r">aList[&quot;b.new&quot;]
</code></pre>

<pre><code>$b.new
[1] TRUE TRUE
</code></pre>

<pre><code class="r">aList[[&quot;b.new&quot;]]
</code></pre>

<pre><code>[1] TRUE TRUE
</code></pre>

<p>Like dataframes, we can also extract single elements from
a list using the &#39;$&#39;, just like we can with data frames.</p>

<pre><code class="r">aList$b.new
</code></pre>

<pre><code>[1] TRUE TRUE
</code></pre>

<p>And we can extract multiple elements as well.</p>

<pre><code class="r">aList[c(&quot;c.new&quot;, &quot;b.new&quot;)]
</code></pre>

<pre><code>$c.new
[1] &quot;a&quot; &quot;b&quot; &quot;c&quot;

$b.new
[1] TRUE TRUE
</code></pre>

<p>But if we use the double bracket with more than one element,
we end up with trouble.</p>

<pre><code class="r">try(aList[[c(&quot;c.new&quot;, &quot;b.new&quot;)]])
</code></pre>

<p>The length() function returns the number of elements.</p>

<pre><code class="r">length(aList)
</code></pre>

<pre><code>[1] 3
</code></pre>

<p>Let&#39;s create a new list:
aNewList</p>

<pre><code class="r">aNewList &lt;- list(d = &quot;nice&quot;, e = 12.7,
                 f = complex(real = 1, imaginary = 7))
</code></pre>

<p>And append the new list to the first list using <code>c()</code>.</p>

<pre><code class="r">bList &lt;- c(aList, aNewList)
bList
</code></pre>

<pre><code>$a.new
[1] 1 2 3 4 5

$b.new
[1] TRUE TRUE

$c.new
[1] &quot;a&quot; &quot;b&quot; &quot;c&quot;

$d
[1] &quot;nice&quot;

$e
[1] 12.7

$f
[1] 1+7i
</code></pre>

<p>We can individually operate on each element in the list
as well, using <code>lapply()</code>.  For example, suppose we wanted
to know the length of each element in the list:</p>

<pre><code class="r">lapply(bList, length)
</code></pre>

<pre><code>$a.new
[1] 5

$b.new
[1] 2

$c.new
[1] 3

$d
[1] 1

$e
[1] 1

$f
[1] 1
</code></pre>

<p>Or suppose we wish to test whether each element is of type
&quot;character&quot;, which we can do using the <code>is.character()</code> function.</p>

<pre><code class="r">lapply(bList, is.character)
</code></pre>

<pre><code>$a.new
[1] FALSE

$b.new
[1] FALSE

$c.new
[1] TRUE

$d
[1] TRUE

$e
[1] FALSE

$f
[1] FALSE
</code></pre>

<p>Or perhaps we wish to convert every element into a character
vector, using as.character().</p>

<pre><code class="r">str(lapply(bList, as.character))
</code></pre>

<pre><code>List of 6
 $ a.new: chr [1:5] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
 $ b.new: chr [1:2] &quot;TRUE&quot; &quot;TRUE&quot;
 $ c.new: chr [1:3] &quot;a&quot; &quot;b&quot; &quot;c&quot;
 $ d    : chr &quot;nice&quot;
 $ e    : chr &quot;12.7&quot;
 $ f    : chr &quot;1+7i&quot;
</code></pre>

<p>If we want to deconstruct the list into a single vector,
we can use <code>unlist()</code>, which will create chose the type of
the resulting vector.</p>

<pre><code class="r">unlist(aList)
</code></pre>

<pre><code>a.new1 a.new2 a.new3 a.new4 a.new5 b.new1 b.new2 c.new1 c.new2 c.new3 
   &quot;1&quot;    &quot;2&quot;    &quot;3&quot;    &quot;4&quot;    &quot;5&quot; &quot;TRUE&quot; &quot;TRUE&quot;    &quot;a&quot;    &quot;b&quot;    &quot;c&quot; 
</code></pre>

<p>Here&#39;s another example of <code>unlist</code> with numeric vectors:</p>

<pre><code class="r">cList &lt;- list(a = 1:3, b = 4:10)
cList
</code></pre>

<pre><code>$a
[1] 1 2 3

$b
[1]  4  5  6  7  8  9 10
</code></pre>

<pre><code class="r">unlist(cList)
</code></pre>

<pre><code>a1 a2 a3 b1 b2 b3 b4 b5 b6 b7 
 1  2  3  4  5  6  7  8  9 10 
</code></pre>

<p>We could remove the names from &quot;aList&quot;:</p>

<pre><code class="r">names(aList) &lt;- NULL
aList
</code></pre>

<pre><code>[[1]]
[1] 1 2 3 4 5

[[2]]
[1] TRUE TRUE

[[3]]
[1] &quot;a&quot; &quot;b&quot; &quot;c&quot;
</code></pre>

<p>But without names, you can only access the elements with.
index numbers.</p>

<pre><code class="r">aList[2:3]
</code></pre>

<pre><code>[[1]]
[1] TRUE TRUE

[[2]]
[1] &quot;a&quot; &quot;b&quot; &quot;c&quot;
</code></pre>

<p>However, you can still use <code>lapply()</code> with a list that
doesn&#39;t have names.  Here we&#39;re applying the <code>names()</code> function
to each element of the list. The resulting NULL output
for each element confirms the names are indeed gone.</p>

<pre><code class="r">lapply(aList, names)
</code></pre>

<pre><code>[[1]]
NULL

[[2]]
NULL

[[3]]
NULL
</code></pre>

<p>Notice how adding unlist() collapes the output into a vector.</p>

<pre><code class="r">unlist(lapply(aList, is.numeric))
</code></pre>

<pre><code>[1]  TRUE FALSE FALSE
</code></pre>

<p>And you can create a list without names from the start.</p>

<pre><code class="r">dList &lt;- list(1:10, rep(TRUE, 2), rnorm(3), diag(2))
dList
</code></pre>

<pre><code>[[1]]
 [1]  1  2  3  4  5  6  7  8  9 10

[[2]]
[1] TRUE TRUE

[[3]]
[1]  0.1886 -1.2698  0.1002

[[4]]
     [,1] [,2]
[1,]    1    0
[2,]    0    1
</code></pre>

<p>Last of all, there is an important connection between
lists and data frames.  Data frames are special cases of
lists!  A data frame is a list of vectors of potentially
different types that all have the same length.</p>

<h4>Exercise 1.3.8: Lists</h4>

<p>1) Create a named list with 3 elements:  a character vector,
    a numeric vector, and a 2 x 2 matrix</p>

<p>2) Extract the third and first elements of the list,
    in that order</p>

<p>3) Extract the 2nd element without the elment name</p>

<p>4) Calculate the length of each element of the list and
    return the result as a vector</p>

</div>


<div class='tab-pane' id='activity-13-solutions'>
<h3>Activity 1.3 Solutions</h3>

<p>Solutions to the exercises in Activity 1.3.</p>

<h4>Exercise 1.3.1: Numeric Vectors</h4>

<p>1) Create a vector from 3 to 11, in steps of 2</p>

<p>2) Create another vector from 12 to 4 in steps of -2</p>

<p>3) Display the last 2 elements of the second vector</p>

<p>4) Calculate the mean of the element-wise product of these
two vectors</p>

<h5>Solutions</h5>

<p>First vector:</p>

<pre><code class="r">x &lt;- seq(3, 11, by = 2)
</code></pre>

<p>Second vector:</p>

<pre><code class="r">y &lt;- seq(12, 4, by = -2)
y
</code></pre>

<pre><code>[1] 12 10  8  6  4
</code></pre>

<p>Determine the length of the vector:</p>

<pre><code class="r">n &lt;- length(y)
</code></pre>

<p>Select the last two elements:</p>

<pre><code class="r">y[c(n - 1, n)]
</code></pre>

<pre><code>[1] 6 4
</code></pre>

<p>Calculate the mean of the element-wise product of x and y:</p>

<pre><code class="r">mean(x * y)
</code></pre>

<pre><code>[1] 48
</code></pre>

<h4>Exercise 1.3.2: Character vectors</h4>

<p>1) Create a character vector consisting of nouns (of the
length of your choosing)</p>

<p>2) Create a second character vector of same length with verbs</p>

<p>3) Paste the two vectors together</p>

<p>4) Count the total number of characters in the entire noun
vector.  Hint, use the &#39;sum&#39; function</p>

<h5>Solutions</h5>

<p>Create the noun vector:</p>

<pre><code class="r">nouns &lt;- c(&quot;cats&quot;, &quot;dogs&quot;, &quot;elephants&quot;)
</code></pre>

<p>Create the verb vector:</p>

<pre><code class="r">verbs &lt;- c(&quot;bark&quot;, &quot;climb&quot;, &quot;jump&quot;)
</code></pre>

<p>Join them together:</p>

<pre><code class="r">paste(nouns, verbs)
</code></pre>

<pre><code>[1] &quot;cats bark&quot;      &quot;dogs climb&quot;     &quot;elephants jump&quot;
</code></pre>

<p>Count the number of characters:</p>

<pre><code class="r">sum(nchar(nouns))
</code></pre>

<pre><code>[1] 17
</code></pre>

<h4>Exercise 1.3.3: Logical vectors</h4>

<p>1) Create random numeric vector of length 1000 with values
uniformly chosen between 0 and 1.  Hint: use the <code>runif</code>
function</p>

<p>2) Count the number of elements in the vector that
fall in the interval <code>[0.2, 0.8]</code>.  On average, it should
be 600</p>

<h5>Solutions</h5>

<p>Generate 1000 random uniform draws in the interval <code>[0, 1]</code>.</p>

<pre><code class="r">x &lt;- runif(1000)
</code></pre>

<p>Create the indicator for &gt;= 0.2.</p>

<pre><code class="r">above_2 &lt;- x &gt;= 0.2
</code></pre>

<p>Create the indicator for &lt;= 0.8.</p>

<pre><code class="r">below_8 &lt;- x &lt;= 0.8
</code></pre>

<p>Count the number of &#39;TRUE&#39;s that satisfy both conditions.</p>

<pre><code class="r">sum(above_2 &amp; below_8)
</code></pre>

<pre><code>[1] 601
</code></pre>

<h4>Exercise 1.3.5: Named vectors</h4>

<p>1) Create a named character vector of length 3</p>

<p>2) Create a second named logical vector of length 3</p>

<p>3) Switch the names of the 2 vectors</p>

<h5>Solutions</h5>

<p>A named character vector:</p>

<pre><code class="r">xChar &lt;- c(this = &quot;one&quot;, that = &quot;too&quot;, these = &quot;many&quot;)
xChar
</code></pre>

<pre><code>  this   that  these 
 &quot;one&quot;  &quot;too&quot; &quot;many&quot; 
</code></pre>

<p>A named logical vector:</p>

<pre><code class="r">xLogical &lt;- c(happy = TRUE, sad = FALSE, angry = TRUE)
xLogical
</code></pre>

<pre><code>happy   sad angry 
 TRUE FALSE  TRUE 
</code></pre>

<p>Switch the names.  Begin by storing the names of <code>xChar</code> in a character vector.</p>

<pre><code class="r">xCharNames &lt;- names(xChar)
</code></pre>

<p>Assign the names of <code>xLogical</code> to <code>xChar</code>.</p>

<pre><code class="r">names(xChar) &lt;- names(xLogical)
</code></pre>

<p>Assign the names of <code>xChar</code> to <code>xLogical</code>.</p>

<pre><code class="r">names(xLogical) &lt;- xCharNames
</code></pre>

<p>Look at the results</p>

<pre><code class="r">xChar
</code></pre>

<pre><code> happy    sad  angry 
 &quot;one&quot;  &quot;too&quot; &quot;many&quot; 
</code></pre>

<pre><code class="r">xLogical
</code></pre>

<pre><code> this  that these 
 TRUE FALSE  TRUE 
</code></pre>

<h4>Exercise 1.3.6: Data frames</h4>

<p>1) Create a data frame with at least 7 rows with the
following columns:
    1. A character vector consisting of some repetition of
       the letters &#39;a&#39;, &#39;b&#39; and &#39;c&#39;
    2. A numeric vector of randomly generated numbers between
       0 and 1.  Hint:  use runif()
    3. A second numeric vector of randomly generated numbers
       between 2 and 7.  Hint: use runif() again</p>

<p>2) Display the number of rows of the data frame</p>

<p>3) Assign rownames consisting of capital letters, &#39;A&#39;, &#39;B&#39;,
    &#39;C&#39;, etc.  Hint, use the <code>LETTERS</code> object that is part of
    R</p>

<p>4) Display the second column of the fourth and fifth rows
    using the row and column names of the data frame</p>

<p>5) Create a subset of the data by selecting those observations
    meet all of the following criteria:
    a.  The character vector has a value of &#39;b&#39; or &#39;c&#39;
    b.  The value of the first numeric vector is greater than
        0.1
    c.  The value of the second numeric vector is less than
        6.</p>

<h5>Solutions</h5>

<p>Create the data frame.  I&#39;m using vectors of length 9.</p>

<pre><code class="r">X &lt;- data.frame(char = rep(letters[1:3], 3),
                num1 = runif(9),
                num2 = runif(9, min = 2, max = 7))
</code></pre>

<p>Get the number of rows of the data frame.</p>

<pre><code class="r">n &lt;- nrow(X)
n
</code></pre>

<pre><code>[1] 9
</code></pre>

<p>Assign rownames:</p>

<pre><code class="r">rownames(X) &lt;- LETTERS[1:n]
</code></pre>

<p>Display the data frame.</p>

<pre><code class="r">X
</code></pre>

<pre><code>  char    num1  num2
A    a 0.24712 5.898
B    b 0.50582 5.998
C    c 0.71732 5.527
D    a 0.99964 4.471
E    b 0.09157 4.178
F    c 0.95430 3.431
G    a 0.17525 4.985
H    b 0.31092 6.463
I    c 0.45487 3.991
</code></pre>

<p>Display 2nd column, 4th and 5th rows using names.</p>

<pre><code class="r">X[c(&quot;D&quot;, &quot;E&quot;), &quot;num1&quot;]
</code></pre>

<pre><code>[1] 0.99964 0.09157
</code></pre>

<p>Create a subset of the data to satisfy the criteria.</p>

<pre><code class="r">criteria1 &lt;- X$char %in% c(&quot;b&quot;, &quot;c&quot;)
criteria2 &lt;- X$num1 &gt; 0.1
criteria3 &lt;- X$num2 &lt; 6
allCrit &lt;- criteria1 &amp; criteria2 &amp; criteria3
</code></pre>

<p>How many rows satisfy the criteria?</p>

<pre><code class="r">sum(allCrit)
</code></pre>

<pre><code>[1] 4
</code></pre>

<p>Display the subset:</p>

<pre><code class="r">X[allCrit,]
</code></pre>

<pre><code>  char   num1  num2
B    b 0.5058 5.998
C    c 0.7173 5.527
F    c 0.9543 3.431
I    c 0.4549 3.991
</code></pre>

<p>What happens if all values of <code>allCrit</code> are false? We get back a data frame with no rows</p>

<pre><code class="r">allCrit &lt;- rep(FALSE, n)
X[allCrit,]
</code></pre>

<pre><code>[1] char num1 num2
&lt;0 rows&gt; (or 0-length row.names)
</code></pre>

<h4>Exercise 1.3.7: Matrices</h4>

<p>1) Create a 2 x 2 matrix with the following elements:
    (2, 4, 7, 1), loaded rowwise.</p>

<p>2) Calculate the trace (the sum of the diagonal elements)
    of the matrix.  Hint: use the sum() function</p>

<p>3) Create a column vector of length 2 with the elements
    (3, 5)</p>

<p>4) Using matrix multiplication, and your results from (1)
    and (3), find the product of the transpose of the column
    vector, the matrix, and the column vector.  Display the
    result should as a single number (not a 1 x 1 matrix).</p>

<h5>Solutions</h5>

<p>Create the matrix:</p>

<pre><code class="r">m &lt;- matrix(c(2, 4, 7, 1), nrow = 2, byrow = TRUE)
m
</code></pre>

<pre><code>     [,1] [,2]
[1,]    2    4
[2,]    7    1
</code></pre>

<p>Calculate the trace:</p>

<pre><code class="r">sum(diag(m))
</code></pre>

<pre><code>[1] 3
</code></pre>

<p>Create the column vector:</p>

<pre><code class="r">v &lt;- c(3, 5)
v
</code></pre>

<pre><code>[1] 3 5
</code></pre>

<p>Calcuate the product, display as a vector:</p>

<pre><code class="r">as.vector(t(v) %*% m %*% v)
</code></pre>

<pre><code>[1] 208
</code></pre>

<h4>Exercise 1.3.8:  Lists</h4>

<p>1) Create a named list with 3 elements:  a character vector,
    a numeric vector, and a 2 x 2 matrix</p>

<p>2) Extract the third and first elements of the list,
    in that order</p>

<p>3) Extract the 2nd element without the elment name</p>

<p>4) Calculate the length of each element of the list and
    return the result as a vector</p>

<h5>Solutions</h5>

<p>Create a list with three named elements</p>

<pre><code class="r">myList &lt;- list(charVec = c(&quot;this&quot;, &quot;that&quot;),
               numVec = rnorm(7),
               mat = matrix(1:4, nrow = 2))
myList
</code></pre>

<pre><code>$charVec
[1] &quot;this&quot; &quot;that&quot;

$numVec
[1]  0.27018 -0.66637 -1.46425 -1.34848  0.05008 -0.75593 -0.11173

$mat
     [,1] [,2]
[1,]    1    3
[2,]    2    4
</code></pre>

<p>Extract the third and first elements. There are two ways to do this:</p>

<pre><code class="r">myList[c(&quot;mat&quot;, &quot;charVec&quot;)]
</code></pre>

<pre><code>$mat
     [,1] [,2]
[1,]    1    3
[2,]    2    4

$charVec
[1] &quot;this&quot; &quot;that&quot;
</code></pre>

<pre><code class="r">myList[c(3, 1)]
</code></pre>

<pre><code>$mat
     [,1] [,2]
[1,]    1    3
[2,]    2    4

$charVec
[1] &quot;this&quot; &quot;that&quot;
</code></pre>

<p>Extract the 2nd element. Therea re two ways to do this:</p>

<pre><code class="r">myList[[&quot;numVec&quot;]]
</code></pre>

<pre><code>[1]  0.27018 -0.66637 -1.46425 -1.34848  0.05008 -0.75593 -0.11173
</code></pre>

<pre><code class="r">myList$numVec
</code></pre>

<pre><code>[1]  0.27018 -0.66637 -1.46425 -1.34848  0.05008 -0.75593 -0.11173
</code></pre>

<p>Calculate the length of each element, returned as a vector.</p>

<pre><code class="r">unlist(lapply(myList, length))
</code></pre>

<pre><code>charVec  numVec     mat 
      2       7       4 
</code></pre>

</div>


<div class='tab-pane' id='activity-14-readingwriting-to-disc-packages-functions'>
<h3>Activity 1.4: Reading/writing to disc, packages, functions</h3>

<h1></h1>

<h4>Activity 1.4.1: Working directory and sourcing files</h4>

<p>The code samples above assume the data files are located in
the R working directory, which can be found with the
function <code>getwd()</code>.</p>

<pre><code class="r">getwd()
</code></pre>

<pre><code>[1] &quot;C:/Users/bunn131/Documents&quot;
</code></pre>

<p>All files visible from R should be accessed relative to the
working directory.
Let&#39;s create a new directory and then set it as the
working directory.</p>

<pre><code class="r">dir.create(&quot;working_tmp&quot;)
</code></pre>

<pre><code>Warning: &#39;working_tmp&#39; already exists
</code></pre>

<pre><code class="r">setwd(&quot;working_tmp&quot;)
getwd()
</code></pre>

<pre><code>[1] &quot;C:/Users/bunn131/Documents/working_tmp&quot;
</code></pre>

<p>Write a one-line text file: (&#39;\n&#39; means new line).</p>

<pre><code class="r">cat(&quot;This is one-line file\n&quot;, file = &quot;tmpFile.txt&quot;)
</code></pre>

<p>Now look at the contents of the directory.</p>

<pre><code class="r">dir()
</code></pre>

<pre><code> [1] &quot;activity2.html&quot;                     
 [2] &quot;activity2.md&quot;                       
 [3] &quot;activity2.Rmd&quot;                      
 [4] &quot;Activity4.html&quot;                     
 [5] &quot;Activity4.md&quot;                       
 [6] &quot;Activity4.Rmd&quot;                      
 [7] &quot;Activity4solutions.html&quot;            
 [8] &quot;Activity4solutions.md&quot;              
 [9] &quot;Activity4solutions.Rmd&quot;             
[10] &quot;Activity5.html&quot;                     
[11] &quot;Activity5.md&quot;                       
[12] &quot;Activity5.Rmd&quot;                      
[13] &quot;Activity5solutions.html&quot;            
[14] &quot;Activity5solutions.md&quot;              
[15] &quot;Activity5solutions.Rmd&quot;             
[16] &quot;Divide_Target_500reals.R&quot;           
[17] &quot;Divide_Target_FOI_Design_500reals.R&quot;
[18] &quot;figure&quot;                             
[19] &quot;more_fake_data.csv&quot;                 
[20] &quot;My Music&quot;                           
[21] &quot;My Pictures&quot;                        
[22] &quot;My Videos&quot;                          
[23] &quot;NDVIDataFrame.csv&quot;                  
[24] &quot;new&quot;                                
[25] &quot;nf-week2-sample.csv&quot;                
[26] &quot;Precipitation&quot;                      
[27] &quot;R&quot;                                  
[28] &quot;Rlibs&quot;                              
[29] &quot;RMD Files&quot;                          
[30] &quot;rstudio-export (1).zip&quot;             
[31] &quot;some_fake_data.csv&quot;                 
[32] &quot;tmpFile.txt&quot;                        
[33] &quot;TrelliscopeViews&quot;                   
[34] &quot;vdb&quot;                                
[35] &quot;working_tmp&quot;                        
[36] &quot;x.pptx&quot;
</code></pre>

<p>Delete the file.</p>

<pre><code class="r">unlink(&quot;tmpFile.txt&quot;)
</code></pre>

<p>Go back to the original working directory.  The &quot;../&quot; is the
Unix/Linux notation for moving up one directory.  This
syntax will work in Windows too.</p>

<pre><code class="r">setwd(&quot;../&quot;)
</code></pre>

<p>Note that the forward slash should be used as the path
separator even on Windows, for example:
setwd(&quot;C:/Users/Me/Documents&quot;)</p>

<p>When you have a large amount of code in a separate file that
you&#39;d like to run all at once, use the <code>source()</code> function.
Let&#39;s illustrate by writing some R code to a text file using
<code>cat()</code>. The &#39;\n&#39; are newline characters.</p>

<pre><code class="r">cat(&quot;x &lt;- 10\n&quot;,
    &quot;y &lt;- 20\n&quot;,
    &quot;x + y&quot;,
    sep = &quot;&quot;,
    file = &quot;tmp1_code.R&quot;)
</code></pre>

<p>Now &quot;tmp1_code.R&quot; should be in your working directory.  We
can verify using <code>dir()</code>.</p>

<pre><code class="r">dir(pattern = &quot;tmp1_&quot;)
</code></pre>

<pre><code>[1] &quot;tmp1_code.R&quot;
</code></pre>

<p>Now we can source (i.e. run) the code in the file.  The
<code>echo</code> argument displays each line as it runs.</p>

<pre><code class="r">source(&quot;tmp1_code.R&quot;, echo = TRUE)
</code></pre>

<pre><code>&gt; x &lt;- 10

&gt; y &lt;- 20

&gt; x + y
[1] 30
</code></pre>

<p>Having sourced the file, let&#39;s remove it.</p>

<pre><code class="r">unlink(&quot;tmp1_code.R&quot;)
</code></pre>

<h4>Activity 1.4.2:  Read and write data to/from disc</h4>

<p>There are lots of ways to read data into R.  One of the
easiest is to write your data (perhaps from Excel) to a csv
(Comma Separated Values) file and then read it into R.</p>

<p>Read in 20 rows of NetFlow data from local disk
into local a data frame object that we&#39;ll call <code>nfHead</code>.</p>

<pre><code class="r">nfHead &lt;- read.csv(&quot;nf-week2-sample.csv&quot;, nrows = 20)
</code></pre>

<p>Look at the structure of <code>nfHead</code>.  Notice that by default,
R converts all character variables to factors, because the
data can be stored more efficiently that way.</p>

<pre><code class="r">str(nfHead)
</code></pre>

<pre><code>&#39;data.frame&#39;:   20 obs. of  19 variables:
 $ TimeSeconds              : Factor w/ 20 levels &quot;1365582756.3809049&quot;,..: 20 19 18 17 16 15 14 13 12 11 ...
 $ parsedDate               : Factor w/ 1 level &quot;2013-04-10 08:32:36&quot;: 1 1 1 1 1 1 1 1 1 1 ...
 $ dateTimeStr              : Factor w/ 20 levels &quot;20130410083236.380905&quot;,..: 20 19 18 17 16 15 14 13 12 11 ...
 $ ipLayerProtocol          : int  17 17 17 17 17 17 17 17 17 17 ...
 $ ipLayerProtocolCode      : Factor w/ 1 level &quot;UDP&quot;: 1 1 1 1 1 1 1 1 1 1 ...
 $ firstSeenSrcIp           : Factor w/ 20 levels &quot;172.20.2.10&quot;,..: 9 8 7 6 5 4 3 2 1 15 ...
 $ firstSeenDestIp          : Factor w/ 1 level &quot;239.255.255.250&quot;: 1 1 1 1 1 1 1 1 1 1 ...
 $ firstSeenSrcPort         : int  29987 29986 29985 29984 29983 29982 29981 29980 29979 29978 ...
 $ firstSeenDestPort        : int  1900 1900 1900 1900 1900 1900 1900 1900 1900 1900 ...
 $ moreFragments            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ contFragments            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ durationSeconds          : int  0 0 0 0 0 0 0 0 0 0 ...
 $ firstSeenSrcPayloadBytes : int  133 133 133 133 133 133 133 133 133 133 ...
 $ firstSeenDestPayloadBytes: int  0 0 0 0 0 0 0 0 0 0 ...
 $ firstSeenSrcTotalBytes   : int  175 175 175 175 175 175 175 175 175 175 ...
 $ firstSeenDestTotalBytes  : int  0 0 0 0 0 0 0 0 0 0 ...
 $ firstSeenSrcPacketCount  : int  1 1 1 1 1 1 1 1 1 1 ...
 $ firstSeenDestPacketCount : int  0 0 0 0 0 0 0 0 0 0 ...
 $ recordForceOut           : int  0 0 0 0 0 0 0 0 0 0 ...
</code></pre>

<p>We can surpress this behavior by using the
<code>stringsAsFactors = FALSE</code> argument in <code>read.csv()</code>.</p>

<pre><code class="r">nfHead &lt;- read.csv(&quot;nf-week2-sample.csv&quot;, nrows = 20,
                   stringsAsFactors = FALSE)
</code></pre>

<p>Notice that the factor variables are now character.</p>

<pre><code class="r">str(nfHead)
</code></pre>

<pre><code>&#39;data.frame&#39;:   20 obs. of  19 variables:
 $ TimeSeconds              : chr  &quot;1365582756.3842709&quot; &quot;1365582756.384094&quot; &quot;1365582756.383898&quot; &quot;1365582756.3837221&quot; ...
 $ parsedDate               : chr  &quot;2013-04-10 08:32:36&quot; &quot;2013-04-10 08:32:36&quot; &quot;2013-04-10 08:32:36&quot; &quot;2013-04-10 08:32:36&quot; ...
 $ dateTimeStr              : chr  &quot;20130410083236.384271&quot; &quot;20130410083236.384094&quot; &quot;20130410083236.383898&quot; &quot;20130410083236.383722&quot; ...
 $ ipLayerProtocol          : int  17 17 17 17 17 17 17 17 17 17 ...
 $ ipLayerProtocolCode      : chr  &quot;UDP&quot; &quot;UDP&quot; &quot;UDP&quot; &quot;UDP&quot; ...
 $ firstSeenSrcIp           : chr  &quot;172.20.2.19&quot; &quot;172.20.2.18&quot; &quot;172.20.2.17&quot; &quot;172.20.2.16&quot; ...
 $ firstSeenDestIp          : chr  &quot;239.255.255.250&quot; &quot;239.255.255.250&quot; &quot;239.255.255.250&quot; &quot;239.255.255.250&quot; ...
 $ firstSeenSrcPort         : int  29987 29986 29985 29984 29983 29982 29981 29980 29979 29978 ...
 $ firstSeenDestPort        : int  1900 1900 1900 1900 1900 1900 1900 1900 1900 1900 ...
 $ moreFragments            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ contFragments            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ durationSeconds          : int  0 0 0 0 0 0 0 0 0 0 ...
 $ firstSeenSrcPayloadBytes : int  133 133 133 133 133 133 133 133 133 133 ...
 $ firstSeenDestPayloadBytes: int  0 0 0 0 0 0 0 0 0 0 ...
 $ firstSeenSrcTotalBytes   : int  175 175 175 175 175 175 175 175 175 175 ...
 $ firstSeenDestTotalBytes  : int  0 0 0 0 0 0 0 0 0 0 ...
 $ firstSeenSrcPacketCount  : int  1 1 1 1 1 1 1 1 1 1 ...
 $ firstSeenDestPacketCount : int  0 0 0 0 0 0 0 0 0 0 ...
 $ recordForceOut           : int  0 0 0 0 0 0 0 0 0 0 ...
</code></pre>

<p>Let&#39;t create a new subset of the data and write the results
back to disk.</p>

<pre><code class="r">nfSub &lt;- nfHead[1:5, c(&quot;parsedDate&quot;, &quot;firstSeenSrcIp&quot;,
                       &quot;firstSeenSrcTotalBytes&quot;)]
nfSub
</code></pre>

<pre><code>           parsedDate firstSeenSrcIp firstSeenSrcTotalBytes
1 2013-04-10 08:32:36    172.20.2.19                    175
2 2013-04-10 08:32:36    172.20.2.18                    175
3 2013-04-10 08:32:36    172.20.2.17                    175
4 2013-04-10 08:32:36    172.20.2.16                    175
5 2013-04-10 08:32:36    172.20.2.14                    175
</code></pre>

<p>Now write the file to disk.</p>

<pre><code class="r">write.csv(nfSub, file = &quot;a_temporary_subset.csv&quot;,
          row.names = FALSE)
</code></pre>

<p>If we call the <code>dir()</code> function, you should see the new
csv file listed in the working directory.  If you are
using a Windows machine, you could open this file in Excel.</p>

<pre><code class="r">dir(pattern = &quot;csv&quot;)
</code></pre>

<pre><code>[1] &quot;a_temporary_subset.csv&quot; &quot;more_fake_data.csv&quot;    
[3] &quot;NDVIDataFrame.csv&quot;      &quot;nf-week2-sample.csv&quot;   
[5] &quot;some_fake_data.csv&quot;
</code></pre>

<p>Now we can delete the file (from R).</p>

<pre><code class="r">unlink(&quot;a_temporary_subset.csv&quot;)
</code></pre>

<p>We can also save nfSub as an R data object, this will only
be readable by R. (But it will be readable by R on any
operating system:  Windows, Mac, or Linux).</p>

<pre><code class="r">save(nfSub, file = &quot;a_temporary_subset.Rdata&quot;)
dir(pattern = &quot;Rdata&quot;)
</code></pre>

<pre><code>[1] &quot;a_temporary_subset.Rdata&quot;
</code></pre>

<p>And since we&#39;ve saved it, we can remove the data frame from
R&#39;s memory.</p>

<pre><code class="r">rm(nfSub)
</code></pre>

<p>If we want to load some existing data that are stored in
the Rdata format, we do the following:</p>

<pre><code class="r">objectName &lt;- load(&quot;a_temporary_subset.Rdata&quot;)
</code></pre>

<p>Note that &#39;objectName&#39; is a character vector that indicates
the name(s) of the R object(s) that were read from the Rdata
file.</p>

<pre><code class="r">objectName
</code></pre>

<pre><code>[1] &quot;nfSub&quot;
</code></pre>

<p>And a call to ls() shows us the &#39;nfSub&#39; object exists in R&#39;s
memory.</p>

<pre><code class="r">&quot;nfSub&quot; %in% ls()
</code></pre>

<pre><code>[1] TRUE
</code></pre>

<p>And if you need more convicing it&#39;s really there:
head() lets us look at the first 6 lines of an object.</p>

<pre><code class="r">head(nfSub)
</code></pre>

<pre><code>           parsedDate firstSeenSrcIp firstSeenSrcTotalBytes
1 2013-04-10 08:32:36    172.20.2.19                    175
2 2013-04-10 08:32:36    172.20.2.18                    175
3 2013-04-10 08:32:36    172.20.2.17                    175
4 2013-04-10 08:32:36    172.20.2.16                    175
5 2013-04-10 08:32:36    172.20.2.14                    175
</code></pre>

<p>And now we delete the Rdata file on disk.</p>

<pre><code class="r">unlink(&quot;a_temporary_subset.Rdata&quot;)
</code></pre>

<h4>Exercise 1.4.2: Read and write data to/from disc</h4>

<p>1) Verify that the file &quot;some_fake_data.csv&quot; is in your
  working directory using <code>dir()</code></p>

<p>2) Read the file &quot;some_fake_data.csv&quot; to a data frame</p>

<p>3) Create a subset of the data by selecting the
    first and last columns whenever the second column is
    less than 7.  Try to use the column names when
    accessing the data frame, as it&#39;s generally a better
    programming practice</p>

<p>4) Write the resulting data frame to a new csv file, called
    &quot;more_fake_data.csv&quot;.  Use the <code>write.csv()</code> function</p>

<h4>Activity 1.4.3: Installing other packages</h4>

<p>Often times, you&#39;ll want to use methods or functions in
R that are available only through contributed packages that
don&#39;t come pre-installed with R.  The <code>xtable</code> package is an
example of a widely used package that converts data frames
and matrices into LaTeX or html tables.</p>

<p>Prior to installation, let&#39;s create a directory where R
will install the package. This step is not usually required
if you are installing a package on your own computer.</p>

<pre><code class="r">dir.create(&quot;Rlibs&quot;)
</code></pre>

<p>To install <code>xtable</code>, we use the <code>install.packages()</code> function.
The <code>libs</code> argument tells R where to install the package on
your computer.  Once again, if you own the computer, this
the <code>lib</code> argument is not usually necessary. The <code>repos</code>
argument allows you to specify a CRAN mirror.  For this
example, we&#39;ll use the CRAN mirro at Case Western University.
If you omit the <code>repos</code> argument, R will prompt you with a
pop-up window to select a CRAN mirror. Typically, you want
to choose a mirror that is geographically close to you.</p>

<pre><code class="r">install.packages(&quot;xtable&quot;, lib = &quot;Rlibs&quot;,
                 repos = &quot;http://cran.case.edu&quot;)
</code></pre>

<pre><code>package &#39;xtable&#39; successfully unpacked and MD5 sums checked

The downloaded binary packages are in
    C:\Users\bunn131\AppData\Local\Temp\RtmpSaYL8m\downloaded_packages
</code></pre>

<p>Once we have installed the <code>xtable</code> package, we need
to load it with <code>library()</code> in order to use it.  Again,
we need to tell R where to look for the library, since
we installed it to the <code>Rlibs</code> directory.  For your
own computer, the <code>lib.loc</code> argument is not usually
necessary.</p>

<pre><code class="r">library(xtable, lib.loc = &quot;Rlibs&quot;)
</code></pre>

<p>We can get a listing of the functions contained in the
<code>xtable</code> package using:</p>

<pre><code class="r">help(package = xtable)
</code></pre>

<pre><code>
</code></pre>

<p>All good packages have documentation for their functions.
Let&#39;s look at the help for the <code>xtable()</code> function</p>

<pre><code class="r">?xtable
</code></pre>

<pre><code>starting httpd help server ... done
</code></pre>

<p>Suppose we wanted to create an html table for
a portion of the mtcars data with the vehicles that have
high power and relatively good gas mileage:</p>

<pre><code class="r">indicator &lt;- (mtcars[,&quot;hp&quot;] &gt; 150) &amp; (mtcars[,&quot;mpg&quot;] &gt; 15)
mtSub &lt;- mtcars[indicator, c(&quot;hp&quot;, &quot;mpg&quot;)]
</code></pre>

<p>Now create the html table that we can copy and paste to
an html editor using xtable() from the <code>xtable</code> package</p>

<pre><code class="r">mtSub.xtable &lt;- xtable(mtSub)
print(mtSub.xtable, type = &quot;html&quot;)
</code></pre>

<pre><code>&lt;!-- html table generated in R 3.1.0 by xtable 1.7-3 package --&gt;
&lt;!-- Thu Jul 03 12:38:21 2014 --&gt;
&lt;TABLE border=1&gt;
&lt;TR&gt; &lt;TH&gt;  &lt;/TH&gt; &lt;TH&gt; hp &lt;/TH&gt; &lt;TH&gt; mpg &lt;/TH&gt;  &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; Hornet Sportabout &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 175.00 &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 18.70 &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; Merc 450SE &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 180.00 &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 16.40 &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; Merc 450SL &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 180.00 &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 17.30 &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; Merc 450SLC &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 180.00 &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 15.20 &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; Pontiac Firebird &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 175.00 &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 19.20 &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; Ford Pantera L &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 264.00 &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 15.80 &lt;/TD&gt; &lt;/TR&gt;
  &lt;TR&gt; &lt;TD align=&quot;right&quot;&gt; Ferrari Dino &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 175.00 &lt;/TD&gt; &lt;TD align=&quot;right&quot;&gt; 19.70 &lt;/TD&gt; &lt;/TR&gt;
   &lt;/TABLE&gt;
</code></pre>

<p>We can also render the table for use in a LaTeX document:</p>

<pre><code class="r">print(mtSub.xtable)
</code></pre>

<pre><code>% latex table generated in R 3.1.0 by xtable 1.7-3 package
% Thu Jul 03 12:38:22 2014
\begin{table}[ht]
\centering
\begin{tabular}{rrr}
  \hline
 &amp; hp &amp; mpg \\ 
  \hline
Hornet Sportabout &amp; 175.00 &amp; 18.70 \\ 
  Merc 450SE &amp; 180.00 &amp; 16.40 \\ 
  Merc 450SL &amp; 180.00 &amp; 17.30 \\ 
  Merc 450SLC &amp; 180.00 &amp; 15.20 \\ 
  Pontiac Firebird &amp; 175.00 &amp; 19.20 \\ 
  Ford Pantera L &amp; 264.00 &amp; 15.80 \\ 
  Ferrari Dino &amp; 175.00 &amp; 19.70 \\ 
   \hline
\end{tabular}
\end{table}
</code></pre>

<h4>Activity 1.4.4: Making your own functions</h4>

<p>Functions are the core computational unit of R.  To the
extent possble, good R coders divide their work into modular,
generalizable, and reusable pieces of code that are
often writen as functions.</p>

<p>All functions in R have inputs (arguments) and outputs
(values).  Let&#39;s define a function called <code>simple()</code> that
adds two numbers together and subtracts 7.</p>

<pre><code class="r">simple &lt;- function(x, y) {
  return(x + y - 7)
}
</code></pre>

<p>To display the function, simply type it&#39;s name:</p>

<pre><code class="r">simple
</code></pre>

<pre><code>function(x, y) {
  return(x + y - 7)
}
</code></pre>

<p>To call the function, add in parameter values for <code>x</code> and <code>y</code>:</p>

<pre><code class="r">simple(4, 7)
</code></pre>

<pre><code>[1] 4
</code></pre>

<p>Note how we can put vectors in the arguments.</p>

<pre><code class="r">simple(1:3, 5:7)
</code></pre>

<pre><code>[1] -1  1  3
</code></pre>

<p>Here&#39;s function with both unnamed and named arguments and
some if/else statements.  Notice the indentation! This is
a standard coding practice for readability.  Here, <code>x</code> is an
unnamed argument, and <code>method</code> is a named argument with
a default value.</p>

<pre><code class="r">simp1 &lt;- function(x, method = &quot;sum&quot;) {

  if (method == &quot;sum&quot;) {
    out &lt;- sum(x)
  }
  else if (method == &quot;prod&quot;) {
    out &lt;- prod(x)
  }
  else {
    stop(&quot;&#39;method&#39; must be &#39;sum&#39; or &#39;prod&#39;&quot;)
  }

  return(out)

}
</code></pre>

<p>Let&#39;s try it using the default for the <code>method</code> argument.
Note that the unnamed argument, <code>x</code>, must be supplied in
order for the function to be called, whereas the named
argument, <code>method</code>, will use the default value if nothing
is supplied for it.</p>

<pre><code class="r">simp1(1:7)
</code></pre>

<pre><code>[1] 28
</code></pre>

<p>Equivalenty we could have called:</p>

<pre><code class="r">simp1(1:7, method = &quot;sum&quot;)
</code></pre>

<pre><code>[1] 28
</code></pre>

<p>And now for the product, assigning the result to <code>x</code>:</p>

<pre><code class="r">x &lt;- simp1(1:7, method = &quot;prod&quot;)
x
</code></pre>

<pre><code>[1] 5040
</code></pre>

<p>And this will throw the error. We&#39;ll wrap it in
the try() function which will keep the error from crashing
this script when it is sourced (i.e. run all at once).</p>

<pre><code class="r">try(simp1(1:7, method = &quot;granny&quot;))
</code></pre>

<p>Here&#39;s a function with a &#39;for&#39; loop that returns nothing.
But it does print the iterations of the loop.  Notice the
commenting inside the function.  Commenting is essential for
readability! With liberal use of comments, you (at the
very least) will know what you were doing if you revisit
the code in the future.</p>

<pre><code class="r">simp2 &lt;- function(begin, long = TRUE) {

  # Determine the value of &#39;end&#39; depending on the value of
  # &#39;long&#39;
  if (long) {
    end &lt;- begin + 10
  }
  else {
    end &lt;- begin + 5
  }

  # A for loop from begin to end that prints each value in the
  # loop
  for (i in begin:end) {
    cat(&quot;Iteration&quot;, i, &quot;\n&quot;)
  }

}
</code></pre>

<p>Call it without specifying the <code>long</code> parameter, it will use the
default parameter value. </p>

<pre><code class="r">simp2(3)
</code></pre>

<pre><code>Iteration 3 
Iteration 4 
Iteration 5 
Iteration 6 
Iteration 7 
Iteration 8 
Iteration 9 
Iteration 10 
Iteration 11 
Iteration 12 
Iteration 13
</code></pre>

<p>Call the function again, setting <code>long</code> to FALSE.</p>

<pre><code class="r">simp2(3, long = FALSE)
</code></pre>

<pre><code>Iteration 3 
Iteration 4 
Iteration 5 
Iteration 6 
Iteration 7 
Iteration 8
</code></pre>

<p>In some cases, you need to return more than one object from
your function.  The standard way to do this in R is to
return a list.  (MANY of the base and contributed
functions in R return lists).  Here&#39;s how:</p>

<pre><code class="r">simp3 &lt;- function(x, y) {

  return(list(sum = x + y,
              product = x * y,
              quotient = x / y))

}
</code></pre>

<p>Upon calling the function, notice it how the named list is
returned.</p>

<pre><code class="r">simp3(3, 7)
</code></pre>

<pre><code>$sum
[1] 10

$product
[1] 21

$quotient
[1] 0.4286
</code></pre>

<p>We can call it and extract the <code>sum</code> from the list.</p>

<pre><code class="r">simp3(3, 7)$sum
</code></pre>

<pre><code>[1] 10
</code></pre>

<p>Or you can extract using brackets:</p>

<pre><code class="r">simp3(3, 7)[&quot;sum&quot;]
</code></pre>

<pre><code>$sum
[1] 10
</code></pre>

<pre><code class="r">simp3(3, 7)[1]
</code></pre>

<pre><code>$sum
[1] 10
</code></pre>

<p>And recall, if you want to strip the label name, use the
double brackets [[]]:</p>

<pre><code class="r">simp3(3, 7)[[&quot;sum&quot;]]
</code></pre>

<pre><code>[1] 10
</code></pre>

<pre><code class="r">simp3(3, 7)[[1]]
</code></pre>

<pre><code>[1] 10
</code></pre>

<p>Or call the function, assign the output to an object, and then extract
the last two elements</p>

<pre><code class="r">y &lt;- simp3(3, 7)
y[2:3]
</code></pre>

<pre><code>$product
[1] 21

$quotient
[1] 0.4286
</code></pre>

<p>Many R coders do not use the <code>return()</code> function at the end
of their function definitions. Some prefer to use <code>return()</code> for
readability and clarity of the code but, technically, it is
redundant.  The last object that is stated at the end of the
function is automatically returned, as illustrated here:</p>

<pre><code class="r">simp4 &lt;- function(x, y) {

    z1 &lt;- x + 7
    z2 &lt;- z1 * y

    # z2 is returned
    z2

}
</code></pre>

<p>Call the function:</p>

<pre><code class="r">simp4(3, -2)
</code></pre>

<pre><code>[1] -20
</code></pre>

<p>What if the output you return from a function is so large
you would never want to have it displayed on the screen?  R
has a nice trick for this:  the <code>invisible()</code> function.</p>

<pre><code class="r">simp5 &lt;- function(n) {

  # Make a vector
  x &lt;- 1:n

  # Write a message that tells you the mean of the vector
  cat(&quot;The mean of the numbers from 1 to&quot;, n, &quot;is&quot;, mean(x),
      &quot;\n&quot;)

  # Invisibly return the vector
  invisible(x)

}
</code></pre>

<p>Now, if we call the function without assigning it to an
object, the value <code>x</code> is not returned.  Only the <code>cat()</code>
statement is printed.</p>

<pre><code class="r">simp5(100)
</code></pre>

<pre><code>The mean of the numbers from 1 to 100 is 50.5
</code></pre>

<p>But if I assign it to an object, the vector is returned
and assigned to the object.</p>

<pre><code class="r">y &lt;- simp5(100)
</code></pre>

<pre><code>The mean of the numbers from 1 to 100 is 50.5
</code></pre>

<pre><code class="r">head(y)
</code></pre>

<pre><code>[1] 1 2 3 4 5 6
</code></pre>

<pre><code class="r">tail(y)
</code></pre>

<pre><code>[1]  95  96  97  98  99 100
</code></pre>

<p>Functions can also be defined without arguments.  A common
reason to do this might be to wrap a large script into a
single unit of code.  This can be especially helpful
if you need to write code with control statements (e.g.,
if/then/else statements, for/while loops, etc.).  Control
statements behave better in R if they are encapsulated
within a function.</p>

<pre><code class="r">simp6 &lt;- function() {

  # Take 1 random draw from a poisson distribution with mean 20
  aRandomPoissonNumber &lt;- rpois(1, lambda = 20)

  # Create some text to return
  textToReturn &lt;- paste(&quot;A random Poisson variate:&quot;,
                        aRandomPoissonNumber)

  # Return the text string
  return(textToReturn)

}
</code></pre>

<p>Call it:</p>

<pre><code class="r">simp6()
</code></pre>

<pre><code>[1] &quot;A random Poisson variate: 23&quot;
</code></pre>

<pre><code class="r">simp6()
</code></pre>

<pre><code>[1] &quot;A random Poisson variate: 18&quot;
</code></pre>

<h4>Exercise 1.4.4: Making your own functions</h4>

<p>1) Create a function that takes two numerical, unnamed
   arguments, (say, <code>x</code> and <code>y</code>) and a single named argument
   that will determine whether your function multiplies
   (the default) or divides your two numeric arguments,
   <code>x</code> and <code>y</code></p>

<p>2) Call the function using scalar inputs for <code>x</code> and <code>y</code>
   such that <code>x</code> is multiplied by <code>y</code></p>

<p>3) Call the function using vector inputs for <code>x</code> and <code>y</code>
   such that <code>x</code> is divided by <code>y</code></p>

</div>


<div class='tab-pane' id='activity-14-solutions'>
<h3>Activity 1.4 Solutions</h3>

<p>Solutions to the exercises in Activity 1.4.</p>

<h4>Exercise 1.4.2: Read and write data to/from disc</h4>

<p>1) Verify that the file &quot;some_fake_data.csv&quot; is in your
  working directory using <code>dir()</code></p>

<p>2) Read the file &quot;some_fake_data.csv&quot; to a data frame</p>

<p>3) Create a subset of the data by selecting the
    first and last columns whenever the second column is
    less than 7.  Try to use the column names when
    accessing the data frame, as it&#39;s generally a better
    programming practice</p>

<p>4) Write the resulting data frame to a new csv file, called
    &quot;more_fake_data.csv&quot;.  Use the <code>write.csv()</code> function</p>

<h5>Solution</h5>

<p>Check for the presence of the data.</p>

<pre><code class="r">dir(pattern = &quot;some_fake&quot;)
</code></pre>

<pre><code>[1] &quot;some_fake_data.csv&quot;
</code></pre>

<p>Read data:</p>

<pre><code class="r">d &lt;- read.csv(&quot;some_fake_data.csv&quot;)
</code></pre>

<p>Look at the structure, notice the column names.</p>

<pre><code class="r">str(d)
</code></pre>

<pre><code>&#39;data.frame&#39;:   10 obs. of  3 variables:
 $ alpha: Factor w/ 10 levels &quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;,..: 1 2 3 4 5 6 7 8 9 10
 $ beta : int  1 2 3 4 5 6 7 8 9 10
 $ gamma: num  -0.637 -0.459 0.897 -0.358 -0.577 ...
</code></pre>

<p>Create an indicator for when the 2nd column is less than 7.</p>

<pre><code class="r">selIndicator &lt;- d[,&quot;beta&quot;] &lt; 7
</code></pre>

<p>Create the requested subset.</p>

<pre><code class="r">dSubset &lt;- d[selIndicator, c(&quot;alpha&quot;, &quot;gamma&quot;)]
</code></pre>

<p>Write the output.</p>

<pre><code class="r">write.csv(dSubset, file = &quot;more_fake_data.csv&quot;,
          row.names = FALSE)
</code></pre>

<h4>Exercise 1.4.4: Making your own functions</h4>

<p>1) Create a function that takes two numerical, unnamed
   arguments (say, <code>x</code> and <code>y</code>) and a single named argument
   that will determine whether your function multiplies
   (the default) or divides your two numeric arguments,
   <code>x</code> and <code>y</code></p>

<p>2) Call the function using scalar inputs for <code>x</code> and <code>y</code>
   such that <code>x</code> is multiplied by <code>y</code></p>

<p>3) Call the function using vector inputs for <code>x</code> and <code>y</code>
   such that <code>x</code> is divided by <code>y</code></p>

<h5>Solution</h5>

<p>Define the function:</p>

<pre><code class="r">f &lt;- function(x, y, type = &quot;multiply&quot;) {

  if (type == &quot;multiply&quot;) {
    out &lt;- x * y
  }
  else if (type == &quot;divide&quot;) {
    out &lt;- x / y
  }
  else {
    stop(&quot;&#39;type&#39; must be either &#39;multiply&#39; or &#39;divide&#39;&quot;)
  }

  return(out)

}
</code></pre>

<p>Call the function to multiply scalar values of <code>x</code> and <code>y</code>:</p>

<pre><code class="r">f(3, 5)
</code></pre>

<pre><code>[1] 15
</code></pre>

<p>Call it to divide two vectors:</p>

<pre><code class="r">f(1:3, 7:9, type = &quot;divide&quot;)
</code></pre>

<pre><code>[1] 0.1429 0.2500 0.3333
</code></pre>

</div>


<div class='tab-pane' id='activity-15-statistical-and-graphical-analyses'>
<h3>Activity 1.5: Statistical and graphical analyses</h3>

<h1></h1>

<h4>Activity 1.5.1: A simple linear regression model</h4>

<p>Let&#39;s now consider fitting a simple linear regression model
to some car data that compares stopping distance to speed
for 50 vehicles.</p>

<p>Because these data are available in base R, we don&#39;t have to
load the data or read it from a file.  We can simply access
it by typing &#39;cars&#39;.</p>

<p>Look at the structure of the cars data.</p>

<pre><code class="r">str(cars)
</code></pre>

<pre><code>&#39;data.frame&#39;:   50 obs. of  2 variables:
 $ speed: num  4 4 7 7 8 9 10 10 10 11 ...
 $ dist : num  2 10 4 22 16 10 18 26 34 17 ...
</code></pre>

<p>Now that we know what the column names are, let&#39;s plot the
data:</p>

<pre><code class="r">plot(cars[,&quot;speed&quot;], cars[,&quot;dist&quot;],
xlab = &quot;Speed&quot;, ylab = &quot;Distance&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-2.png" alt="plot of chunk unnamed-chunk-2"> </p>

<p>Now let&#39;s fit a simple linear regression model, to use
speed to predict the stopping distance.  We use the linear
model function, <code>lm()</code>.</p>

<pre><code class="r">slrModel &lt;- lm(dist ~ speed, data = cars)
</code></pre>

<p>If we call <code>str()</code> on <code>slrModel</code>, we see that it is a
complicated R object called a list.</p>

<pre><code class="r">str(slrModel)
</code></pre>

<pre><code>List of 12
 $ coefficients : Named num [1:2] -17.58 3.93
  ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;(Intercept)&quot; &quot;speed&quot;
 $ residuals    : Named num [1:50] 3.85 11.85 -5.95 12.05 2.12 ...
  ..- attr(*, &quot;names&quot;)= chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
 $ effects      : Named num [1:50] -303.914 145.552 -8.115 9.885 0.194 ...
  ..- attr(*, &quot;names&quot;)= chr [1:50] &quot;(Intercept)&quot; &quot;speed&quot; &quot;&quot; &quot;&quot; ...
 $ rank         : int 2
 $ fitted.values: Named num [1:50] -1.85 -1.85 9.95 9.95 13.88 ...
  ..- attr(*, &quot;names&quot;)= chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
 $ assign       : int [1:2] 0 1
 $ qr           :List of 5
  ..$ qr   : num [1:50, 1:2] -7.071 0.141 0.141 0.141 0.141 ...
  .. ..- attr(*, &quot;dimnames&quot;)=List of 2
  .. .. ..$ : chr [1:50] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
  .. .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;speed&quot;
  .. ..- attr(*, &quot;assign&quot;)= int [1:2] 0 1
  ..$ qraux: num [1:2] 1.14 1.27
  ..$ pivot: int [1:2] 1 2
  ..$ tol  : num 1e-07
  ..$ rank : int 2
  ..- attr(*, &quot;class&quot;)= chr &quot;qr&quot;
 $ df.residual  : int 48
 $ xlevels      : Named list()
 $ call         : language lm(formula = dist ~ speed, data = cars)
 $ terms        :Classes &#39;terms&#39;, &#39;formula&#39; length 3 dist ~ speed
  .. ..- attr(*, &quot;variables&quot;)= language list(dist, speed)
  .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1
  .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2
  .. .. .. ..$ : chr [1:2] &quot;dist&quot; &quot;speed&quot;
  .. .. .. ..$ : chr &quot;speed&quot;
  .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;speed&quot;
  .. ..- attr(*, &quot;order&quot;)= int 1
  .. ..- attr(*, &quot;intercept&quot;)= int 1
  .. ..- attr(*, &quot;response&quot;)= int 1
  .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x577a4e8&gt; 
  .. ..- attr(*, &quot;predvars&quot;)= language list(dist, speed)
  .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot;
  .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;dist&quot; &quot;speed&quot;
 $ model        :&#39;data.frame&#39;:  50 obs. of  2 variables:
  ..$ dist : num [1:50] 2 10 4 22 16 10 18 26 34 17 ...
  ..$ speed: num [1:50] 4 4 7 7 8 9 10 10 10 11 ...
  ..- attr(*, &quot;terms&quot;)=Classes &#39;terms&#39;, &#39;formula&#39; length 3 dist ~ speed
  .. .. ..- attr(*, &quot;variables&quot;)= language list(dist, speed)
  .. .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1
  .. .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2
  .. .. .. .. ..$ : chr [1:2] &quot;dist&quot; &quot;speed&quot;
  .. .. .. .. ..$ : chr &quot;speed&quot;
  .. .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;speed&quot;
  .. .. ..- attr(*, &quot;order&quot;)= int 1
  .. .. ..- attr(*, &quot;intercept&quot;)= int 1
  .. .. ..- attr(*, &quot;response&quot;)= int 1
  .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x577a4e8&gt; 
  .. .. ..- attr(*, &quot;predvars&quot;)= language list(dist, speed)
  .. .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot;
  .. .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;dist&quot; &quot;speed&quot;
 - attr(*, &quot;class&quot;)= chr &quot;lm&quot;
</code></pre>

<p>Fortunately, there are a variety of method functions we
can use to extract information from the <code>slrModel</code> object.
For example: a call to <code>summary()</code> on the <code>slmModel</code> object
gives the slope, intercept, R-squared, and other statistics
about the model.</p>

<pre><code class="r">summary(slrModel)
</code></pre>

<pre><code>
Call:
lm(formula = dist ~ speed, data = cars)

Residuals:
   Min     1Q Median     3Q    Max 
-29.07  -9.53  -2.27   9.21  43.20 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  -17.579      6.758   -2.60    0.012 *  
speed          3.932      0.416    9.46  1.5e-12 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 15.4 on 48 degrees of freedom
Multiple R-squared:  0.651, Adjusted R-squared:  0.644 
F-statistic: 89.6 on 1 and 48 DF,  p-value: 1.49e-12
</code></pre>

<p>We can also extract the coefficients of the model.</p>

<pre><code class="r">coef(slrModel)
</code></pre>

<pre><code>(Intercept)       speed 
    -17.579       3.932 
</code></pre>

<p>And we can superimpose the regression line on the plot
(remake the plot of these data first before executing this
command if you closed the plot).</p>

<pre><code class="r">slrModel &lt;- lm(cars[,&quot;dist&quot;]~ cars[,&quot;speed&quot;])
plot(cars[,&quot;speed&quot;], cars[,&quot;dist&quot;], xlab=&#39;Speed&#39;, ylab=&#39;Distance&#39;)
abline(a=-17.57, b= 3.93, col = &quot;Blue&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-7.png" alt="plot of chunk unnamed-chunk-7"> </p>

<p>We can also add a smoothed line that follow the data
using <code>lowess()</code>.</p>

<pre><code class="r">slrModel &lt;- lm(cars[,&quot;dist&quot;]~ cars[,&quot;speed&quot;])
plot(cars[,&quot;speed&quot;], cars[,&quot;dist&quot;], xlab=&#39;Speed&#39;, ylab=&#39;Distance&#39;)
abline(a=-17.57, b= 3.93, col = &quot;Blue&quot;)
lines(lowess(cars$speed, cars$dist), col = &quot;Red&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-8.png" alt="plot of chunk unnamed-chunk-8"> </p>

<p>You can close the current plot with:</p>

<pre><code class="r">dev.off()
</code></pre>

<pre><code>null device 
          1 
</code></pre>

<p>Alternatively, you can close all open plots with:</p>

<pre><code class="r">graphics.off()
</code></pre>

<h4>Exercise 1.5.1: A simple linear regression model</h4>

<p>1) Look at the Old Faithful geyser data in Yellowstone
National Park.  It&#39;s the <code>faithful</code> dataset available in
the base R distribution.  Use <code>help(faithful)</code> or <code>?faithful</code>
to see its documentation</p>

<p>2) Plot the waiting time to the next eruptions vs. the
duration of the eruption</p>

<p>3) Fit a simple linear regression model to predict waiting
time from the eruption duration</p>

<p>4) Overlay the fitted model on the plot with a red line</p>

<h4>Activity 1.5.2: Factors</h4>

<p>&quot;Factors&quot; is a technique R uses to efficiently encode
categorical variables.  Factors are primarily used in
statistical models. Consider that a categorical predictor
variable, with n distinct possible values, must be
represented by n-1 dummy (or indicator) variables in the
model matrix. The factor representation tells R to
automatically create the dummy variables that are used in,
e.g., Analyis of Variance (ANOVA) and Analysis of Covariance
(ANCOVA) models.  Factors are also used for plotting data
in groups.</p>

<p>Suppose we had a categorical variable with three possible
values: &quot;animal&quot;, &quot;plant&quot;, or &quot;non-living&quot;.  We&#39;ll use
sample() to randomly order the character vector.</p>

<pre><code class="r">var &lt;- sample(c(rep(&quot;animal&quot;, 3), rep(&quot;plant&quot;, 2),
                rep(&quot;non-living&quot;, 4)))
var
</code></pre>

<pre><code>[1] &quot;animal&quot;     &quot;non-living&quot; &quot;non-living&quot; &quot;plant&quot;      &quot;non-living&quot;
[6] &quot;non-living&quot; &quot;plant&quot;      &quot;animal&quot;     &quot;animal&quot;    
</code></pre>

<p>We could create a factor vector as follows:</p>

<pre><code class="r">  f1 &lt;- factor(var)
  f1
</code></pre>

<pre><code>  [1] animal     non-living non-living plant      non-living non-living
  [7] plant      animal     animal    
  Levels: animal non-living plant
</code></pre>

<p>Notice in the structure, we see levels and the numeric
encodings of the categorical values.</p>

<pre><code class="r">str(f1)
</code></pre>

<pre><code> Factor w/ 3 levels &quot;animal&quot;,&quot;non-living&quot;,..: 1 2 2 3 2 2 3 1 1
</code></pre>

<p>Factors have a nice <code>summary()</code> method that counts the number
of elements that occur in each level.</p>

<pre><code class="r">summary(f1)
</code></pre>

<pre><code>    animal non-living      plant 
         3          4          2 
</code></pre>

<p>We can extract the levels from the factor vector.  Note how
they appear in alphabetical order by default.</p>

<pre><code class="r">levels(f1)
</code></pre>

<pre><code>[1] &quot;animal&quot;     &quot;non-living&quot; &quot;plant&quot;     
</code></pre>

<p>In this case, this means that &quot;animal&quot; is assigned a value of
1, &quot;non-living&quot; a value of 2, and &quot;plant&quot; a value of 3.  We
can see the numerical encodings by using <code>as.numeric()</code>.</p>

<pre><code class="r">as.numeric(f1)
</code></pre>

<pre><code>[1] 1 2 2 3 2 2 3 1 1
</code></pre>

<p>And we can pair the codings side-by-side in a data frame
with the original character vector to see the mapping.</p>

<pre><code class="r">data.frame(original = var, numerical.coding = as.numeric(f1))
</code></pre>

<pre><code>    original numerical.coding
1     animal                1
2 non-living                2
3 non-living                2
4      plant                3
5 non-living                2
6 non-living                2
7      plant                3
8     animal                1
9     animal                1
</code></pre>

<p>Suppose we prefer a different mapping: plant = 1, animal = 2,
and non-living = 3. This will do the trick:</p>

<pre><code class="r">f2 &lt;- factor(var, levels = c(&quot;plant&quot;, &quot;animal&quot;, &quot;non-living&quot;))
</code></pre>

<p>And we can see the new mapping:</p>

<pre><code class="r">data.frame(original = var, numerical.coding = as.numeric(f2))
</code></pre>

<pre><code>    original numerical.coding
1     animal                2
2 non-living                3
3 non-living                3
4      plant                1
5 non-living                3
6 non-living                3
7      plant                1
8     animal                2
9     animal                2
</code></pre>

<p>We subset factors by referencing their level names, not their
numerical coding.  For example if we wanted to identify the
elements that were &quot;plants&quot;, we could do the following:</p>

<pre><code class="r">f2 == &quot;plant&quot;
</code></pre>

<pre><code>[1] FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE
</code></pre>

<p>Or, to get the index numbers:</p>

<pre><code class="r">which(f2 == &quot;plant&quot;)
</code></pre>

<pre><code>[1] 4 7
</code></pre>

<p>If the original data that were used to create a factor are
character, converting the factor back to a character vector
is straightforward using <code>as.character()</code>.</p>

<pre><code class="r">varRestored1 &lt;- as.character(f1)
identical(var, varRestored1)
</code></pre>

<pre><code>[1] TRUE
</code></pre>

<p>And this back-conversion works regardles of how the levels
were specified.</p>

<pre><code class="r">varRestored2 &lt;- as.character(f2)
identical(var, varRestored2)
</code></pre>

<pre><code>[1] TRUE
</code></pre>

<p>We can also create factors from numeric variables as well
(provided the variable has a limited number of distinct
 values).</p>

<pre><code class="r">numVar &lt;- rep(4:1, each = 2)
numVar
</code></pre>

<pre><code>[1] 4 4 3 3 2 2 1 1
</code></pre>

<pre><code class="r">f3 &lt;- factor(numVar)
f3
</code></pre>

<pre><code>[1] 4 4 3 3 2 2 1 1
Levels: 1 2 3 4
</code></pre>

<p>If the original data that were used to create a factor are
numeric, we have to take some special steps to properly
convert the factor back to its original integer (or numeric)
values.</p>

<pre><code class="r">numVarRestored &lt;- as.integer(levels(f3)[f3])
identical(numVarRestored, numVar)
</code></pre>

<pre><code>[1] TRUE
</code></pre>

<p>And we can even give levels new names, or labels.
Suppose we want 1 = &quot;good&quot;, 2 = &quot;bad&quot;, 3 = &quot;ugly&quot;, and
4 = &quot;obnoxious&quot;.</p>

<pre><code class="r">f4 &lt;- factor(numVar, levels = 1:4,
             labels = c(&quot;good&quot;, &quot;bad&quot;, &quot;ugly&quot;, &quot;obnoxious&quot;))
</code></pre>

<p>Let&#39;s check it out in a variety of ways:</p>

<pre><code class="r">f4
</code></pre>

<pre><code>[1] obnoxious obnoxious ugly      ugly      bad       bad       good     
[8] good     
Levels: good bad ugly obnoxious
</code></pre>

<pre><code class="r">str(f4)
</code></pre>

<pre><code> Factor w/ 4 levels &quot;good&quot;,&quot;bad&quot;,&quot;ugly&quot;,..: 4 4 3 3 2 2 1 1
</code></pre>

<pre><code class="r">data.frame(original = numVar, numerical.coding = as.numeric(f4),
labels = as.character(f4))
</code></pre>

<pre><code>  original numerical.coding    labels
1        4                4 obnoxious
2        4                4 obnoxious
3        3                3      ugly
4        3                3      ugly
5        2                2       bad
6        2                2       bad
7        1                1      good
8        1                1      good
</code></pre>

<p>We can also create a new mapping:  2 = &quot;good&quot;, 1 = &quot;bad&quot;,
4 = &quot;ugly&quot;, and 3 = &quot;obnoxious&quot;.</p>

<pre><code class="r">f5 &lt;- factor(numVar, levels = c(2, 1, 4, 3),
labels = c(&quot;good&quot;, &quot;bad&quot;, &quot;ugly&quot;, &quot;obnoxious&quot;))
f5
</code></pre>

<pre><code>[1] ugly      ugly      obnoxious obnoxious good      good      bad      
[8] bad      
Levels: good bad ugly obnoxious
</code></pre>

<pre><code class="r">data.frame(original = numVar, 
            numerical.coding = as.numeric(f5),
            labels = as.character(f5)
          )
</code></pre>

<pre><code>  original numerical.coding    labels
1        4                3      ugly
2        4                3      ugly
3        3                4 obnoxious
4        3                4 obnoxious
5        2                1      good
6        2                1      good
7        1                2       bad
8        1                2       bad
</code></pre>

<p>As before, if we want to reference elements of the factor, for
the purpose of subsetting, we have to use the level labels:</p>

<pre><code class="r">subsetLogical &lt;- f5 == &quot;good&quot;
subsetIndexes &lt;- which(f5 %in% c(&quot;good&quot;, &quot;ugly&quot;))
</code></pre>

<p>And we can then subset the factor accordingly:</p>

<pre><code class="r">f5[subsetLogical]
</code></pre>

<pre><code>[1] good good
Levels: good bad ugly obnoxious
</code></pre>

<pre><code class="r">f5[subsetIndexes]
</code></pre>

<pre><code>[1] ugly ugly good good
Levels: good bad ugly obnoxious
</code></pre>

<p>Let&#39;s see how levels work in practice with ANOVA. Let&#39;s
first cook up some fake data from the standard normal
distribution to go with our numerical factor.</p>

<pre><code class="r">x &lt;- rnorm(length(numVar))
</code></pre>

<p>And then we&#39;ll look at the coefficients of an ANOVA model and
how R labels them based on the factor levels.  First, we
fit the ANOVA model:</p>

<pre><code class="r">m1 &lt;- lm(x ~ f3)
</code></pre>

<p>Notice how the parameter (coefficient) names of the ANOVA
model are <code>f3</code> with the levels of <code>f3</code> appended to them
(except for the first level, which is captured in the
intercept).</p>

<pre><code class="r">coef(m1)
</code></pre>

<pre><code>(Intercept)         f32         f33         f34 
    -0.3063     -1.1085     -0.2692      1.4140 
</code></pre>

<pre><code class="r">levels(f3)
</code></pre>

<pre><code>[1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot;
</code></pre>

<p>And here we have <code>f4</code> with the levels of <code>f4</code> appended:</p>

<pre><code class="r">coef(lm(x ~ f4))
</code></pre>

<pre><code>(Intercept)       f4bad      f4ugly f4obnoxious 
    -0.3063     -1.1085     -0.2692      1.4140 
</code></pre>

<pre><code class="r">levels(f4)
</code></pre>

<pre><code>[1] &quot;good&quot;      &quot;bad&quot;       &quot;ugly&quot;      &quot;obnoxious&quot;
</code></pre>

<h4>Exercise 1.5.2: Factors</h4>

<p>1) Create a numeric vector with arbitrarily repeated
values of 1.2, 3, and 7.9 .</p>

<p>2) Create the numeric vector to a factor, where 3 will be
numerically encoded as a 1, 7.9 as a 2, and 1.2 as 3.
Display the numerical encoding</p>

<p>3) Display the levels of the factor</p>

<p>4) Convert the factor back to the original numerical vector</p>

<p>5) Create a subset of the factor when it equals 1.2 or 3</p>

<h4>Activity 1.5.3: Trellis plots</h4>

<p>This example introduces making trellis (or lattice) plots
using the <code>lattice</code> package and the <code>mtcars</code> dataset.</p>

<p>Load the lattice package (for making trellis plots).</p>

<pre><code class="r">library(lattice)
</code></pre>

<p>For convenience, attaching the data frame places it in the
search path so that we don&#39;t always have to reference <code>mtcars</code>
each time we want to extract a column from the data.</p>

<pre><code class="r">attach(mtcars)
</code></pre>

<pre><code>The following object is masked from package:ggplot2:

    mpg
</code></pre>

<p>Now that we&#39;ve attached it, notice how it appears in the
2nd position of R&#39;s search path?</p>

<pre><code class="r">search()
</code></pre>

<pre><code> [1] &quot;.GlobalEnv&quot;          &quot;mtcars&quot;              &quot;package:stl2&quot;       
 [4] &quot;package:yaImpute&quot;    &quot;package:buildDocs&quot;   &quot;package:devtools&quot;   
 [7] &quot;package:tools&quot;       &quot;package:whisker&quot;     &quot;package:scagnostics&quot;
[10] &quot;package:trelliscope&quot; &quot;package:fastICA&quot;     &quot;package:jsonlite&quot;   
[13] &quot;package:ggplot2&quot;     &quot;package:shiny&quot;       &quot;package:markdown&quot;   
[16] &quot;package:knitr&quot;       &quot;package:base64enc&quot;   &quot;package:cyberTools&quot; 
[19] &quot;package:lubridate&quot;   &quot;package:plyr&quot;        &quot;package:Rhipe&quot;      
[22] &quot;package:rJava&quot;       &quot;package:datadr&quot;      &quot;package:testthat&quot;   
[25] &quot;package:hexbin&quot;      &quot;package:lattice&quot;     &quot;package:grid&quot;       
[28] &quot;package:codetools&quot;   &quot;package:digest&quot;      &quot;package:data.table&quot; 
[31] &quot;package:parallel&quot;    &quot;tools:rstudio&quot;       &quot;package:stats&quot;      
[34] &quot;package:graphics&quot;    &quot;package:grDevices&quot;   &quot;package:utils&quot;      
[37] &quot;package:datasets&quot;    &quot;package:methods&quot;     &quot;Autoloads&quot;          
[40] &quot;package:base&quot;       
</code></pre>

<p>Since <code>search()</code> returns a character vector, we could use the
following to verify <code>mtcars</code> is in the search path:</p>

<pre><code class="r">&quot;mtcars&quot; %in% search()
</code></pre>

<pre><code>[1] TRUE
</code></pre>

<p>And thus, instead of using either of these:</p>

<pre><code class="r">head(mtcars$mpg)
</code></pre>

<pre><code>[1] 21.0 21.0 22.8 21.4 18.7 18.1
</code></pre>

<pre><code class="r">head(mtcars[,&quot;mpg&quot;])
</code></pre>

<pre><code>[1] 21.0 21.0 22.8 21.4 18.7 18.1
</code></pre>

<p>We can simply use <code>mpg</code></p>

<pre><code class="r">head(mpg)
</code></pre>

<pre><code>[1] 21.0 21.0 22.8 21.4 18.7 18.1
</code></pre>

<p>In preparation for the lattice plots, we create factors with
value labels that will aid in annotation and in dividing the
data into groups based on the number of gears and the
number of cylinders.</p>

<pre><code class="r">gear.f &lt;- factor(gear, levels = c(3, 4, 5),
labels = c(&quot;3gears&quot;, &quot;4gears&quot;, &quot;5gears&quot;))

cyl.f &lt;- factor(cyl, levels = c(4, 6, 8),
labels = c(&quot;4cyl&quot;, &quot;6cyl&quot;, &quot;8cyl&quot;))
</code></pre>

<p>Let&#39;s make a kernel density plot of mpg for all the vehicles.
A kernel density is a smoothed plot of the raw
data. Notice that <code>densityplot()</code> comes from the <code>lattice</code>
package.</p>

<pre><code class="r">densityplot(~mpg, main = &quot;Density Plot&quot;,
            xlab = &quot;Miles per Gallon&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-42.png" alt="plot of chunk unnamed-chunk-42"> </p>

<p>Kernel density plots for each cylinder type.  Notice
this is where we use the factor variable for cylinder.</p>

<pre><code class="r">densityplot(~mpg | cyl.f,
            main = &quot;Density Plot by Number of Cylinders&quot;,
            xlab = &quot;Miles per Gallon&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-43.png" alt="plot of chunk unnamed-chunk-43"> </p>

<p>Scatterplots of mpg vs. weight for each combination of
cylinder type and gear type.  <code>xyplot()</code> is another function
from the <code>lattice</code> package.</p>

<pre><code class="r">xyplot(mpg ~ wt | cyl.f * gear.f,
       main = &quot;Scatterplots by Cylinders and Gears&quot;,
       ylab = &quot;Miles per Gallon&quot;, xlab = &quot;Car Weight&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-44.png" alt="plot of chunk unnamed-chunk-44"> </p>

<p>Scatterplot matrix over a number of the columns:</p>

<pre><code class="r">splom(mtcars[,c(1, 3:6)], main = &quot;MTCARS Data&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-45.png" alt="plot of chunk unnamed-chunk-45"> </p>

<p>Now that we&#39;re through with <code>mtcars</code>, we detach it from the
search path.</p>

<pre><code class="r">detach(mtcars)
</code></pre>

<p>It&#39;s no longer there:</p>

<pre><code class="r">&quot;mtcars&quot; %in% search()
</code></pre>

<pre><code>[1] FALSE
</code></pre>

<p>Close the graphics window(s).</p>

<pre><code class="r">graphics.off()
</code></pre>

<h4>Exercise 1.5.3: Trellis plots</h4>

<p>1) Attach the quakes data that comes with R. Look at the
columns using <code>head()</code> or <code>str()</code></p>

<p>2) Use xyplot to plot lat vs. long for the location of the
earthquakes. Label the axes and the main graphs
using the following command to bin the depth variable into
9 bins:</p>

<p><code>depthbin &lt;- equal.count(quakes$depth, number = 9,
                          overlap = 0)</code></p>

<p>Make sure you have loaded the lattice package via:
  <code>library(lattice)</code></p>

<p>3) Now use xyplot() to plot lat,long for each depth bin of
the earthquake to create a set of graphs in a trellis
display.</p>

<h4>Activity 1.5.4: Time series analysis</h4>

<p>The data for this example contain daily counts of the number
(<code>Freq</code>) of domestic airline flights in the United States
from 1999 until the spring of 2008</p>

<p>Let&#39;s load the data, which we previously saved as an
Rdata object.  Wrapping <code>print()</code> around the call to <code>load()</code>
will list the name(s) of the R objects that were loaded from
the Rdata file</p>

<pre><code class="r">print(load(&quot;dailycount.Rdata&quot;))
</code></pre>

<pre><code>[1] &quot;dailycount&quot;
</code></pre>

<p>R has a built-in function for time series decompostion, where
seasonal, trend, and irregular components can be separated
from one another.  <code>stl()</code> is the function that does this.</p>

<p>Use R&#39;s built-in <code>stl()</code> function:</p>

<pre><code class="r">daily.stl &lt;- stl(ts(dailycount$Freq / 1000, frequency = 7),
                 s.window = 51, s.degree = 1, t.window = 19)
</code></pre>

<p>And a plot shows a visualization of the decomposition:</p>

<pre><code class="r">plot(daily.stl)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-51.png" alt="plot of chunk unnamed-chunk-51"> </p>

<p>To explore some additional capability for time series
decomposition that was developed by Ryan Hafen, we need to
download and install his package from github.  To do that,
we need a helper function, install_github(), which is
available in the devtools package that is available from CRAN.</p>

<p>Since the <code>devtools</code>  and <code>stl</code> packages are already
installed on the AWS cluster, we will skip these 3 steps
Otherwise, you would need to run these 3 commands:</p>

<pre><code class="r">install.packages(&quot;devtools&quot;)
library(devtools)
install_github(&quot;stl2&quot;, &quot;hafen&quot;)
</code></pre>

<p>Load the <code>stl2</code> package.</p>

<pre><code class="r">library(stl2)
</code></pre>

<p>Define a character vector of weekdays:</p>

<pre><code class="r">weekdays &lt;- c(&quot;Sun&quot;, &quot;Mon&quot;, &quot;Tue&quot;, &quot;Wed&quot;, &quot;Thu&quot;, &quot;Fri&quot;, &quot;Sat&quot;)
</code></pre>

<p>And now we calculate the time series decomposition.
(To learn more about this, begin with <code>?stl2</code>.)</p>

<pre><code class="r">daily.stl2 &lt;- stl2(dailycount$Freq / 1000, n.p = 7,
t = dailycount$date, s.window = 51,
s.degree = 1, t.window = 19,
sub.labels = weekdays, sub.start = 3)
</code></pre>

<p>Plot the results of the decomposition:</p>

<pre><code class="r">plot(daily.stl2, ylab = &quot;Daily Flights (thousands)&quot;,
xlab = &quot;Time&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-56.png" alt="plot of chunk unnamed-chunk-56"> </p>

<p>We have decomposed the time series into seasonal, trend,
and remainder components.  The trend component captures
the overall level over time, the seasonal component (here
day-of-week) captures changes across week over time,
and the remainder is the residual noise not explained by
the time series model.</p>

<p>When we fit models to data, we should look at those points
where the model does not fit well.  Hence we study
abnormal outliers in remainder:</p>

<pre><code class="r">plot.seasonal(daily.stl2, layout = c(7, 1))
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-57.png" alt="plot of chunk unnamed-chunk-57"> </p>

<p>We see that Wednesday is declining over the years, while
Monday and Tuesday are increasing.  No wonder flights
are cheaper on Wednesdays! This pattern would have been
difficult to see without the combination of the
time series model and the lattice plot visualization.</p>

<p>Now we turn to the trend portion of the decomposition:
We see a drop on 9/11/2001, then a huge jump back up in 2003.</p>

<pre><code class="r">plot.trend(daily.stl2)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-58.png" alt="plot of chunk unnamed-chunk-58"> </p>

<p>This plot gives us a sense of the magnitude of the
residuals (remainder), broken down by day of the week,
adjusting for the seasonal effect:</p>

<pre><code class="r">plot.cycle(daily.stl2)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-59.png" alt="plot of chunk unnamed-chunk-59"> </p>

<p>Same residual plot, for each day of the week.</p>

<pre><code class="r">plot.rembycycle(daily.stl2)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-60.png" alt="plot of chunk unnamed-chunk-60"> </p>

<p>This leads us to look for places where the residuals
are negative--indicating the model is underpredicting
the number of flights on those days.</p>

<p>What dates in remainder are large in magnitude?</p>

<pre><code class="r">ind &lt;- which(remainder(daily.stl2) &lt; -3)
dailycount[ind,]
</code></pre>

<pre><code>      juliandate  Freq       date       dow
-2228      -2228 11554 1999-11-25  Thursday
-2192      -2192 11520 1999-12-31    Friday
-1864      -1864 11957 2000-11-23  Thursday
-1863      -1863 12360 2000-11-24    Friday
-1129      -1129 10249 2002-11-28  Thursday
-1128      -1128 10783 2002-11-29    Friday
-1096      -1096 12414 2002-12-31   Tuesday
-911        -911 14500 2003-07-04    Friday
-765        -765 13646 2003-11-27  Thursday
-401        -401 15252 2004-11-25  Thursday
-37          -37 14634 2005-11-24  Thursday
327          327 15090 2006-11-23  Thursday
328          328 16600 2006-11-24    Friday
550          550 17742 2007-07-04 Wednesday
691          691 14859 2007-11-22  Thursday
692          692 16912 2007-11-23    Friday
723          723 17313 2007-12-24    Monday
</code></pre>

<p>Thanksgiving, New Years, 4th of July, Christmas...</p>

<p>And if we look for the largest remainder?</p>

<pre><code class="r">ind &lt;- which(remainder(daily.stl2) &lt; -4)
dailycount[ind,]
</code></pre>

<pre><code>     juliandate  Freq       date      dow
-401       -401 15252 2004-11-25 Thursday
-37         -37 14634 2005-11-24 Thursday
327         327 15090 2006-11-23 Thursday
691         691 14859 2007-11-22 Thursday
</code></pre>

<p>We see Thanksgiving is the worst.</p>

</div>


<div class='tab-pane' id='activity-15-solutions'>
<h3>Activity 1.5 Solutions</h3>

<p>Solutions to the exercises in Activity 1.5.</p>

<h4>Exercise 1.5.1: A simple linear regression model</h4>

<p>1) Look at the Old Faithful geyser data in Yellowstone
   National Park.  It&#39;s the <code>faithful</code> dataset available in
    the base R distribution.  Use <code>help(faithful)</code> or <code>?faithful</code>
    to see its documentation</p>

<p>2) Plot the waiting time to the next eruptions vs. the
    duration of the eruption</p>

<p>3) Fit a simple linear regression model to predict waiting
    time from the eruption duration</p>

<p>4) Overlay the fitted model on the plot with a red line</p>

<h5>Solution</h5>

<p>Look at the documentation:</p>

<pre><code class="r">?faithful
</code></pre>

<p>Plot the data:</p>

<pre><code class="r">with(faithful, plot(eruptions, waiting))
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-2.png" alt="plot of chunk unnamed-chunk-2"> </p>

<p>Fit the simple linear regression model:</p>

<pre><code class="r">slrModel &lt;- lm(waiting ~ eruptions, data = faithful)
</code></pre>

<p>Overlay a regression line, make it thick with the <code>lwd</code>
(line width) argument:</p>

<pre><code class="r">slrModel &lt;- lm(waiting ~ eruptions, data = faithful)
plot(faithful[,&#39;eruptions&#39;], faithful[,&#39;waiting&#39;])
abline(slrModel, col = &quot;Red&quot;, lwd = 5)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-4.png" alt="plot of chunk unnamed-chunk-4"> </p>

<p>Shut down the graph:</p>

<pre><code class="r">dev.off()
</code></pre>

<pre><code>null device 
          1 
</code></pre>

<h4>Exercise 1.5.2: Factors</h4>

<p>1) Create a numeric vector with arbitrarily repeated
    values of 1.2, 3, and 7.9 .</p>

<p>2) Create the numeric vector to a factor, where 3 will be
    numerically encoded as a 1, 7.9 as a 2, and 1.2 as 3.
    Display the numerical encoding</p>

<p>3) Display the levels of the factor</p>

<p>4) Convert the factor back to the original numerical vector</p>

<p>5) Create a subset of the factor when it equals 1.2 or 3</p>

<h5>Solution</h5>

<p>Create a numeric vector:</p>

<pre><code class="r">x &lt;- c(rep(1.2, 3), rep(3, 2), rep(7.9, 4))
</code></pre>

<p>Convert it to a factor with the encoding specified:</p>

<pre><code class="r">xf &lt;- factor(x, levels = c(3, 7.9, 1.2))
xf
</code></pre>

<pre><code>[1] 1.2 1.2 1.2 3   3   7.9 7.9 7.9 7.9
Levels: 3 7.9 1.2
</code></pre>

<p>Display the numerical encoding:</p>

<pre><code class="r">as.numeric(xf)
</code></pre>

<pre><code>[1] 3 3 3 1 1 2 2 2 2
</code></pre>

<p>Display the levels:</p>

<pre><code class="r">levels(xf)
</code></pre>

<pre><code>[1] &quot;3&quot;   &quot;7.9&quot; &quot;1.2&quot;
</code></pre>

<p>Convert the factor object back to numeric again and compare:</p>

<pre><code class="r">xCompare &lt;- as.numeric(levels(xf)[xf])
identical(xCompare, x)
</code></pre>

<pre><code>[1] TRUE
</code></pre>

<p>Create a subset when the factor is 1.2 or 3.  Both of these
produce identical results. In the second instance,
R converts the numeric values of 1.2 and 3 to character.</p>

<pre><code class="r">xf[xf %in% c(&quot;1.2&quot;, &quot;3&quot;)]
</code></pre>

<pre><code>[1] 1.2 1.2 1.2 3   3  
Levels: 3 7.9 1.2
</code></pre>

<pre><code class="r">xf[xf %in% c(1.2, 3)]
</code></pre>

<pre><code>[1] 1.2 1.2 1.2 3   3  
Levels: 3 7.9 1.2
</code></pre>

<h4>Exercise 1.5.3: Trellis plots</h4>

<p>1) Attach the quakes data that comes with R. Look at the
    columns using <code>head()</code> or <code>str()</code></p>

<p>2) Use <code>xyplot</code> to plot lat vs. long for the location of the
    earthquakes. Label the axes and the main graphs
    using the following command to bin the depth variable into
    9 bins:</p>

<pre><code>`depthbin &lt;- equal.count(quakes$depth, number = 9,
                        overlap = 0)`

Make sure you have loaded the lattice package via:
`library(lattice)`
</code></pre>

<p>3) Now use <code>xyplot()</code> to plot lat,long for each depth bin of
    the earthquake to create a set of graphs in a trellis
    display.</p>

<h5>Solution</h5>

<p>Attach quakes for convenience in accessing its columns:</p>

<pre><code class="r">attach(quakes)
</code></pre>

<p>Check out the data</p>

<pre><code class="r">head(quakes)
</code></pre>

<pre><code>     lat  long depth mag stations
1 -20.42 181.6   562 4.8       41
2 -20.62 181.0   650 4.2       15
3 -26.00 184.1    42 5.4       43
4 -17.97 181.7   626 4.1       19
5 -20.42 182.0   649 4.0       11
6 -19.68 184.3   195 4.0       12
</code></pre>

<pre><code class="r">str(quakes)
</code></pre>

<pre><code>&#39;data.frame&#39;:   1000 obs. of  5 variables:
 $ lat     : num  -20.4 -20.6 -26 -18 -20.4 ...
 $ long    : num  182 181 184 182 182 ...
 $ depth   : int  562 650 42 626 649 195 82 194 211 622 ...
 $ mag     : num  4.8 4.2 5.4 4.1 4 4 4.8 4.4 4.7 4.3 ...
 $ stations: int  41 15 43 19 11 12 43 15 35 19 ...
</code></pre>

<p>Create the depth binning variable:</p>

<pre><code class="r">library(lattice)
depth_bin &lt;- equal.count(quakes$depth, number = 9, overlap = 0)
</code></pre>

<p>Produce the plot:</p>

<pre><code class="r">xyplot(lat ~long | depth_bin,
       main = &quot;Earthquakes in the Pacific&quot;,
       xlab = &quot;longitude&quot;, ylab = &quot;latitude&quot;)
</code></pre>

<p><img src="figures/knitr/unnamed-chunk-15.png" alt="plot of chunk unnamed-chunk-15"> </p>

<p>Detach the quakes data frame:</p>

<pre><code class="r">detach(quakes)
</code></pre>

</div>


<div class='tab-pane' id='activity-21-datadr-and-trelliscope-example-with-census-data'>
<h3>Activity 2.1: DataDR and Trelliscope example with Census Data</h3>

<h4>Introduction to the Census Data and Distributed Data Frames</h4>

<p>This example uses a dataset from the 1994 U.S. census, available at 
<a href="http://archive.ics.uci.edu/ml/datasets/Adult">http://archive.ics.uci.edu/ml/datasets/Adult</a>. This is a relatively small
dataset, which can be loaded into memory; we use it to demonstrate DataDR
and Trelliscope because its size makes it easy to see the relationship
between the analysis steps and the visualizations. This dataset (<code>adult</code>) is
distributed with the <code>datadr</code> library, once the library is loaded, the
data frame is available.</p>

<p>We start by loading the datadr and trelliscope libraries, and looking at
the <code>adult</code> data frame. The data has a mix of categorical and numeric variables, including
age, race, gender, education level, income bin (&lt;=$50K, &gt;$50K), 
hours per week worked, and job class (e.g. private, government, 
self-employed, etc) among others.</p>

<pre><code class="r">library(datadr)
library(trelliscope)

# look at the dataset
str(adult)
</code></pre>

<pre><code>&#39;data.frame&#39;:   32561 obs. of  16 variables:
 $ age          : int  39 50 38 53 28 37 49 52 31 42 ...
 $ workclass    : Factor w/ 9 levels &quot;?&quot;,&quot;Federal-gov&quot;,..: 8 7 5 5 5 5 5 7 5 5 ...
 $ fnlwgt       : int  77516 83311 215646 234721 338409 284582 160187 209642 45781 159449 ...
 $ education    : Factor w/ 16 levels &quot;10th&quot;,&quot;11th&quot;,..: 10 10 12 2 10 13 7 12 13 10 ...
 $ educationnum : int  13 13 9 7 13 14 5 9 14 13 ...
 $ marital      : Factor w/ 7 levels &quot;Divorced&quot;,&quot;Married-AF-spouse&quot;,..: 5 3 1 3 3 3 4 3 5 3 ...
 $ occupation   : Factor w/ 15 levels &quot;?&quot;,&quot;Adm-clerical&quot;,..: 2 5 7 7 11 5 9 5 11 5 ...
 $ relationship : Factor w/ 6 levels &quot;Husband&quot;,&quot;Not-in-family&quot;,..: 2 1 2 1 6 6 2 1 2 1 ...
 $ race         : Factor w/ 5 levels &quot;Amer-Indian-Eskimo&quot;,..: 5 5 5 3 3 5 3 5 5 5 ...
 $ sex          : Factor w/ 2 levels &quot;Female&quot;,&quot;Male&quot;: 2 2 2 2 1 1 1 2 1 2 ...
 $ capgain      : int  2174 0 0 0 0 0 0 0 14084 5178 ...
 $ caploss      : int  0 0 0 0 0 0 0 0 0 0 ...
 $ hoursperweek : int  40 13 40 40 40 40 16 45 50 40 ...
 $ nativecountry: Factor w/ 42 levels &quot;?&quot;,&quot;Cambodia&quot;,..: 40 40 40 40 6 40 24 40 40 40 ...
 $ income       : Factor w/ 2 levels &quot;&lt;=50K&quot;,&quot;&gt;50K&quot;: 1 1 1 1 1 1 1 2 2 2 ...
 $ incomebin    : num  0 0 0 0 0 0 0 1 1 1 ...
</code></pre>

<p>The first step is to transform <code>adult</code> into a distributed data frame (DDF).
A DDF is one of the main data containing classes in <code>datadr</code>. A DDF can 
represent data in memory, on local disk, or on a Hadoop Distributed File
System (HDFS), so it can be used for data from the very small to the very large.
One advantage of using <code>datadr</code> is that the same analysis algorithms can 
be used on all types of DDFs without rewriting code. </p>

<pre><code class="r"># express data as a local &quot;distributed data frame&quot;
adultDdf &lt;- ddf(adult, update=TRUE)

adultDdf
</code></pre>

<pre><code>
Distributed data object of class &#39;kvMemory&#39; with attributes: 

&#39;ddo&#39; attribute | value
----------------+-----------------------------------------------------------
 keys           | keys are available through getKeys(dat)
 totStorageSize | 2.12 MB
 totObjectSize  | 2.12 MB
 nDiv           | 1
 splitSizeDistn | use splitSizeDistn(dat) to get distribution
 example        | use kvExample(dat) to get an example subset
 bsvInfo        | [empty] no BSVs have been specified

&#39;ddf&#39; attribute | value
----------------+-----------------------------------------------------------
 vars           | age(int), workclass(fac), fnlwgt(int), and 13 more
 transFn        | identity (original data is a data frame)
 nRow           | 32561
 splitRowDistn  | use splitRowDistn(dat) to get distribution
 summary        | use summary(dat) to see summaries

In-memory data connection
</code></pre>

<p>As we see, this dataset has size 2.12 MB and has  observations.
A good place to start in an exploratory analysis is to look at summary statistics. The <code>summary()</code> method provides a nice overview of the variables in our distributed data frame.  For categorical variables, it provides a frequency table, and for numeric variables, it provides summary statistics such as moments (mean, standard deviation, etc.), range, etc.</p>

<pre><code class="r"># look at data summary statistics
summary(adultDdf)
</code></pre>

<pre><code>        age                workclass                fnlwgt       
 -----------------  ------------------------  ------------------ 
  missing :      0          levels : 9         missing :       0 
      min :     17         missing : 0             min :   12285 
      max :     90     &gt; freqTable head &lt;          max : 1484705 
     mean :  38.58           Private : 22696      mean :  189778 
  std dev :  13.64  Self-emp-not-inc :  2541   std dev :  105550 
 skewness : 0.5587         Local-gov :  2093  skewness :   1.447 
 kurtosis :  2.834                 ? :  1836  kurtosis :   9.218 
 -----------------  ------------------------  ------------------ 
      education           educationnum              marital           
 --------------------  ------------------  -------------------------- 
         levels : 16    missing :       0          levels : 7         
        missing : 0         min :       1         missing : 0         
  &gt; freqTable head &lt;        max :      16      &gt; freqTable head &lt;     
      HS-grad : 10501      mean :   10.08  Married-civ-spouse : 14976 
 Some-college :  7291   std dev :   2.573       Never-married : 10683 
    Bachelors :  5355  skewness : -0.3117            Divorced :  4443 
      Masters :  1723  kurtosis :   3.623           Separated :  1025 
 --------------------  ------------------  -------------------------- 
       occupation            relationship      
 ----------------------  --------------------- 
         levels : 15             levels : 6    
        missing : 0             missing : 0    
   &gt; freqTable head &lt;     &gt; freqTable head &lt;   
  Prof-specialty : 4140        Husband : 13193 
    Craft-repair : 4099  Not-in-family :  8305 
 Exec-managerial : 4066      Own-child :  5068 
    Adm-clerical : 3770      Unmarried :  3446 
 ----------------------  --------------------- 
            race                    sex              capgain      
 --------------------------  ------------------  ---------------- 
         levels : 5                  levels : 2   missing :     0 
        missing : 0                 missing : 0       min :     0 
     &gt; freqTable head &lt;      &gt; freqTable head &lt;       max : 99999 
              White : 27816    Male : 21790          mean :  1078 
              Black :  3124  Female : 10771       std dev :  7385 
 Asian-Pac-Islander :  1039                      skewness : 11.95 
 Amer-Indian-Eskimo :   311                      kurtosis : 157.8 
 --------------------------  ------------------  ---------------- 
     caploss         hoursperweek         nativecountry     
 ----------------  -----------------  --------------------- 
  missing :     0   missing :      0          levels : 42   
      min :     0       min :      1         missing : 0    
      max :  4356       max :     99   &gt; freqTable head &lt;   
     mean :  87.3      mean :  40.44  United-States : 29170 
  std dev :   403   std dev :  12.35         Mexico :   643 
 skewness : 4.594  skewness : 0.2276              ? :   583 
 kurtosis : 23.37  kurtosis :  5.916    Philippines :   198 
 ----------------  -----------------  --------------------- 
       income            incomebin     
 ------------------  ----------------- 
         levels : 2   missing :      0 
        missing : 0       min :      0 
 &gt; freqTable head &lt;       max :      1 
 &lt;=50K : 24720           mean : 0.2408 
  &gt;50K :  7841        std dev : 0.4276 
                     skewness :  1.212 
                     kurtosis :   2.47 
 ------------------  ----------------- 
</code></pre>

<h4>Dividing and Recombining</h4>

<p>A typical analysis path is to divide data based on some variable in the dataset 
and apply some analysis to each subset of the data. We will divide based on
the <code>education</code> field. Use the <code>getKeys</code> method to see the keys associated
with a data. Then use one key to see the data rows associated with that value
of <code>education</code>.</p>

<pre><code class="r"># divide the ddf by the variable &quot;education&quot;
byEducation &lt;- divide(adultDdf, by = &quot;education&quot;, update=TRUE)

# look at division keys
getKeys(byEducation)
</code></pre>

<pre><code>[[1]]
[1] &quot;education=10th&quot;

[[2]]
[1] &quot;education=11th&quot;

[[3]]
[1] &quot;education=12th&quot;

[[4]]
[1] &quot;education=1st-4th&quot;

[[5]]
[1] &quot;education=5th-6th&quot;

[[6]]
[1] &quot;education=7th-8th&quot;

[[7]]
[1] &quot;education=9th&quot;

[[8]]
[1] &quot;education=Assoc-acdm&quot;

[[9]]
[1] &quot;education=Assoc-voc&quot;

[[10]]
[1] &quot;education=Bachelors&quot;

[[11]]
[1] &quot;education=Doctorate&quot;

[[12]]
[1] &quot;education=HS-grad&quot;

[[13]]
[1] &quot;education=Masters&quot;

[[14]]
[1] &quot;education=Preschool&quot;

[[15]]
[1] &quot;education=Prof-school&quot;

[[16]]
[1] &quot;education=Some-college&quot;
</code></pre>

<pre><code class="r">
# look at subsets of the ddf
head(byEducation[[&quot;education=Bachelors&quot;]][[2]])
</code></pre>

<pre><code>  age        workclass fnlwgt educationnum            marital
1  39        State-gov  77516           13      Never-married
2  50 Self-emp-not-inc  83311           13 Married-civ-spouse
3  28          Private 338409           13 Married-civ-spouse
4  42          Private 159449           13 Married-civ-spouse
5  30        State-gov 141297           13 Married-civ-spouse
6  23          Private 122272           13      Never-married
       occupation  relationship               race    sex capgain caploss
1    Adm-clerical Not-in-family              White   Male    2174       0
2 Exec-managerial       Husband              White   Male       0       0
3  Prof-specialty          Wife              Black Female       0       0
4 Exec-managerial       Husband              White   Male    5178       0
5  Prof-specialty       Husband Asian-Pac-Islander   Male       0       0
6    Adm-clerical     Own-child              White Female       0       0
  hoursperweek nativecountry income incomebin
1           40 United-States  &lt;=50K         0
2           13 United-States  &lt;=50K         0
3           40          Cuba  &lt;=50K         0
4           40 United-States   &gt;50K         1
5           40         India   &gt;50K         1
6           30 United-States  &lt;=50K         0
</code></pre>

<p>What if we wanted to compute summary statistics on each division of the data? For 
example, we could calculate the mean and standard deviation of the number of 
hours per week worked for each education level. The <code>recombine</code> method will apply
a function to each data division, then combine the function outputs into a single
data frame.</p>

<pre><code class="r"># compute mean and standard dev of hoursperweek for each subset and recombine into one table
edMeanAndVar &lt;- recombine(byEducation,
   apply = function(x) {
      list(
         mean=mean(x$age, na.rm=TRUE), 
         stdev=sqrt(var(x$age, na.rm=TRUE))
      )
   },
   combine = combRbind()
)

# look at results 
edMeanAndVar
</code></pre>

<pre><code>      education val.mean val.stdev
1          10th    37.43     16.72
2          11th    32.36     15.55
3          12th    32.00     14.33
4       1st-4th    46.14     15.62
5       5th-6th    42.89     15.56
6       7th-8th    48.45     16.09
7           9th    41.06     15.95
8    Assoc-acdm    37.38     11.10
9     Assoc-voc    38.55     11.63
10    Bachelors    38.90     11.91
11    Doctorate    47.70     11.78
12      HS-grad    38.97     13.54
13      Masters    44.05     11.07
14    Preschool    42.76     15.13
15  Prof-school    44.75     11.96
16 Some-college    35.76     13.47
</code></pre>

<h4>Trelliscope Displays</h4>

<p>For this activity, we will make a couple of simple Trelliscope displays. The
Trelliscope documentation at <a href="http://tesseradata.org/trelliscope/">http://tesseradata.org/trelliscope/</a> 
has many more details than what is discussed here.</p>

<p>Trelliscope provides a visual recombination approach to D&amp;R.  In Trelliscope, 
we specify a function to be applied to each subset that produces a plot. Each 
plot is called a &quot;panel&quot;.  The collection of panels for given dataset is 
called a &quot;display&quot;.  A collection of displays is called a &quot;visualization 
database&quot; (VDB).</p>

<p>Trelliscope provides an interactive viewer that allows the user to specify how 
to sort, filter, and arrange the panels in a display to view them in a 
meaningful way.</p>

<p>We start by creating a different division on the data, using the <code>workclass</code> variable.</p>

<pre><code class="r"># divide by work class
byWorkClass &lt;- divide(adultDdf, by=&quot;workclass&quot;)

getKeys(byWorkClass)
</code></pre>

<pre><code>[[1]]
[1] &quot;workclass=?&quot;

[[2]]
[1] &quot;workclass=Federal-gov&quot;

[[3]]
[1] &quot;workclass=Local-gov&quot;

[[4]]
[1] &quot;workclass=Never-worked&quot;

[[5]]
[1] &quot;workclass=Private&quot;

[[6]]
[1] &quot;workclass=Self-emp-inc&quot;

[[7]]
[1] &quot;workclass=Self-emp-not-inc&quot;

[[8]]
[1] &quot;workclass=State-gov&quot;

[[9]]
[1] &quot;workclass=Without-pay&quot;
</code></pre>

<p>We will create Trelliscope display to explore the data divided by <code>workclass</code>. 
First, we create a function that makes a plot out of one data division. It&#39;s good
to test this function on one division. </p>

<pre><code class="r"># panel function: education vs hours per week, conditioned on income category
pf1 &lt;- function(x)
   xyplot(hoursperweek ~ educationnum | income, 
      data = x,
      xlab=&quot;Years of Education&quot;,
      ylab=&quot;Hours per Week&quot;
   )
# test it on one data division
pf1(byWorkClass[[&quot;workclass=Federal-gov&quot;]][[2]])
</code></pre>

<p><img src="figures/knitr/Activity2_1_8.png" alt="plot of chunk Activity2.1.8"> </p>

<p>We will have a set of these plots, one corresponding to each value of <code>workclass</code>.
To help interact with all the possible panels we can specify metrics to computed 
for each subset, which are called â€˜cognosticsâ€™. Cognostics specify sorting and 
filtering of the plots based on the metrics chosen. For this data, our 
cognostics include summary statistics of the education level and hours per week
(mean, max, min).</p>

<pre><code class="r"># cognostics function
cf &lt;- function(x) {
   list(
      fracAbove50K = cog(mean(x$incomebin), desc = &quot;fraction above $50K income&quot;),
      minEducation = cog(min(x$educationnum), desc = &quot;min number of education years&quot;),
      meanEducation = cog(mean(x$educationnum), desc = &quot;mean number of education years&quot;),
      maxEducation = cog(max(x$educationnum), desc = &quot;max number of education years&quot;),
      minnHoursPerWeek = cog(min(x$hoursperweek), desc=&quot;min hours per week worked&quot;),
      meanHoursPerWeek = cog(mean(x$hoursperweek), desc=&quot;mean hours per week worked&quot;),
      maxHoursPerWeek = cog(max(x$hoursperweek), desc=&quot;max hours per week worked&quot;)
   )
}
</code></pre>

<p>As with the panel function, it&#39;s a good idea to test the cognostics function
on one data division.</p>

<pre><code class="r">cf(byWorkClass[[1]][[2]])
</code></pre>

<pre><code>$fracAbove50K
[1] 0.104

$minEducation
[1] 1

$meanEducation
[1] 9.26

$maxEducation
[1] 16

$minnHoursPerWeek
[1] 1

$meanHoursPerWeek
[1] 31.92

$maxHoursPerWeek
[1] 99
</code></pre>

<p>Now that we&#39;re satisfied with our panel and cognostics functions, we put 
them together to create a Trelliscope display. The <code>vdbConn</code> command creates 
a visualization database (VDB) directory where plots and metadata will be 
stored when they are created by the <code>makeDisplay</code> function.</p>

<pre><code class="r"># create visualization database
vdbConn(&quot;vdb_census&quot;, autoYes = TRUE)
</code></pre>

<pre><code>vdb connection object: name=.; path=/people/d3l348/bootcamp/analysis/vdb_census
</code></pre>

<pre><code class="r">
# create display with this panel and cognostics functions
makeDisplay(byWorkClass,
   name = &quot;hours_and_education_by_workclass&quot;,
   desc = &quot;hours and education by workclass&quot;,
   panelFn = pf1, cogFn = cf,
   width = 400, height = 400
)
</code></pre>

<p>The <code>view</code> command launches the Trelliscope viewer in a browser. </p>

<pre><code class="r"># view the display
view()
</code></pre>

<p>When the Trelliscope viewer appears, it displays a list of displays to 
choose from--at the moment it shows only one option which is the display 
we just created. </p>

<p><img src="figures/trelliscope_1_1.png" alt="Trelliscope Fig 1"></p>

<p>When you select the display, the first, randomly selected plot is shown. Notice
the left and right arrows at the top that allow you to page through the
plots. There is one plot panel for each data division--in this case,
for each work class.</p>

<p><img src="figures/trelliscope_1_2.png" alt="Trelliscope Fig 2"></p>

<p>We will use the Visible Cognostics screen to choose what information is displayed
below each plot. The variable used to define the division is chosen by
default (<code>workclass</code>); let&#39;s also select <code>fracAbove50K</code>.</p>

<p><img src="figures/trelliscope_1_3.png" alt="Trelliscope Fig 3"></p>

<p>Next use the Panel Layout screen to display multiple panels at a time.</p>

<p><img src="figures/trelliscope_1_4.png" alt="Trelliscope Fig 4"></p>

<p>Now all 9 panels (for the 9 work classes) are displayed at once.</p>

<p><img src="figures/trelliscope_1_5.png" alt="Trelliscope Fig 5"></p>

<p>In the Table Sort/Filter Screen, we can sort and filter the plots based
on the cognostics defined above. Click the small up arrow next to the
<code>fracAbove50K</code> column header; this sorts the rows into decreasing
order according to that statistic. </p>

<p><img src="figures/trelliscope_1_6.png" alt="Trelliscope Fig 6"></p>

<p>Hit Apply to return to the plots
and you will see that they have been re-ordered.</p>

<p><img src="figures/trelliscope_1_7.png" alt="Trelliscope Fig 7"></p>

<p>We will look at additional capabilities of the Trelliscope viewer in 
the next example. Close the Trelliscope viewer and return to the R 
command line. Type <code>Esc</code> or <code>Ctrl-C</code> to stop the Trelliscope viewer. </p>

<p>Next we will create a second type of panel function for a different 
type of plot. </p>

<pre><code class="r">pf2 &lt;- function(x)
   boxplot(educationnum ~ income, data = x,
      xlab=&quot;Income&quot;, ylab=&quot;Education&quot;)
pf2(byWorkClass[[1]][[2]])
</code></pre>

<p><img src="figures/knitr/Activity2_1_12a.png" alt="plot of chunk Activity2.1.12a"> </p>

<p>We pass this new panel function to the <code>makeDisplay</code> function
as before, and use the same cognostics function as previously.</p>

<pre><code class="r"># a second type of plot on the same data
makeDisplay(byWorkClass,
   name = &quot;education_boxplot_by_workclass&quot;,
   desc = &quot;education boxplot by workclass&quot;,
   panelFn = pf2, cogFn = cf,
   width = 400, height = 400
)
</code></pre>

<p>When the Trelliscope viewer is launched you will see that both the first set
of plots and the most recent set are available to view. This is because
the Trelliscope displays are persistent: they are stored in the vdbConn
specified above.  You can keep adding more types of plots and as long as they
are given unique names in the <code>makeDisplay</code> command they will all be
available to view.</p>

<p>You could also come back in future sessions of R and specify the same directory
in a <code>vdbConn</code> command and see the Trelliscope displays created today, as long
as you do not delete that directory.</p>

<pre><code class="r"># launch viewer
view(port=myport)
</code></pre>

<p><img src="figures/trelliscope_1_8.png" alt="Trelliscope Fig 8"></p>

<p>Select the new display (labeled education_boxplot_by_workclass) and you will
see a single boxplot panel.</p>

<p><img src="figures/trelliscope_1_9.png" alt="Trelliscope Fig 9"></p>

<p>In the visible cognostics screen, we will select <code>fracAbove50K</code> and 
<code>meanHoursPerWeek</code>. Click the Apply button.</p>

<p><img src="figures/trelliscope_1_10.png" alt="Trelliscope Fig 10"></p>

<p>In the Univariate Filter screen, we can view quantile plots of the
cognostic statistics, and select outliers to filter. If we select
<code>fracAbove50K</code> on the left, and draw a box to select the two points 
on the upper right of the plot, this will filter the panels so that
only the panels corresponding to those two values of <code>fracAbove50K</code> 
are displayed. Click the Apply button.</p>

<p><img src="figures/trelliscope_1_11.png" alt="Trelliscope Fig 11"></p>

<p>After using the Panel Layout screen to display two panels at a
time, we can see the two sets of boxplots corresponding to the two
work classes with the highest fraction of incomes above $50,000.</p>

<p><img src="figures/trelliscope_1_12.png" alt="Trelliscope Fig 12"></p>

<p>As previously noted, after finishing looking at the Trelliscope viewer,
type <code>Esc</code> or <code>Ctrl-C</code> at the R command line.</p>

</div>


<div class='tab-pane' id='activity-22-using-tessera-with-hadoop-to-analyze-large-data'>
<h3>Activity 2.2: Using Tessera with Hadoop to Analyze Large Data</h3>

<h4>Session Initialization</h4>

<pre><code class="r"># load required packages and initialize Rhipe
library(datadr)
library(Rhipe)
library(cyberTools)
rhinit()

# set time zone to &quot;UTC&quot; for use with dates in the data
Sys.setenv(TZ = &quot;UTC&quot;)

# set working directories on local machine 
setwd(&quot;~&quot;)

# set working directory in HDFS
hdfs.setwd(&quot;&quot;Sys.getenv(&quot;HDFS_USER_VAST&quot;)&quot;&quot;)
</code></pre>

<pre><code class="r"># make sure raw text data has been copied to HDFS
rhls(&quot;raw/nf&quot;)
</code></pre>

<pre><code>  permission  owner      group     size          modtime
1 drwxrwxrwx d3l348 supergroup        0 2014-07-01 21:07
2 -rw-r--r-- d3l348 supergroup 2.766 gb 2014-06-13 03:29
                                       file
1     /user/d3l348/bootcamp/raw/nf/_rh_meta
2 /user/d3l348/bootcamp/raw/nf/nf-week2.csv
</code></pre>

<h4>Read NetFlow csv Data to R Objects</h4>

<p>One of the more tedious parts of data analaysis can be getting the data 
into the proper format for analysis.  <code>datadr</code> stives to provide as much 
functionality to make this process as painless as possible, but there 
will always be special situations that require unique solutions.</p>

<p>For analysis in <code>datadr</code>, we want to take the raw data and store it as 
native R objects.  This provides a great degree of flexibility in what 
type of data structures we can use, such as non-tabular data or special 
classes of R objects like time series or spatial objects.</p>

<p>Here, all of our input data is text.  Text files are used quite often 
for storing and sharing big data.  For example, often 
<a href="https://hive.apache.org">Hive</a> tables are stored as text files. <code>datadr</code> 
provides some helpful functions that make it easy to deal 
with reading in text data and storing it as R objects..  </p>

<p>In this activity we will go through how to read the NetFlow data from 
text.  These examples read the data using a simple function 
<code>drRead.csv()</code> which has a similar interface to R&#39;s <code>read.csv()</code> function.</p>

<p>We saw from before that the NetFlow data is located on HDFS at 
<code>raw/nf/nf-week2.csv</code>.  If we were to look at a sample of the NetFlow 
data we would see that it has a few date/time related columns. R will 
read those in as character and/or numeric, and we will want to 
convert them to R date/time objects.
<img src="figures/NetFlow_data.png" alt="NetFlow Data"></p>

<p>We will make a date transformation function, which we will pass to the 
<code>drRead.csv()</code> function so that it will be applied to each row of data 
as it is read. </p>

<pre><code class="r"># make a date parsing function to use during data ingest
nfTransform &lt;- function(x) {
   x$date &lt;- as.POSIXct(as.numeric(as.character(x$TimeSeconds)), 
      origin = &quot;1970-01-01&quot;, tz = &quot;UTC&quot;)
   x[,setdiff(names(x), c(&quot;TimeSeconds&quot;, &quot;parsedDate&quot;))]
}
</code></pre>

<h4>HDFS connections</h4>

<p>We are reading text data from HDFS and will be storing the data we read 
to HDFS.  When working with HDFS in <code>datadr</code>, we create <em>HDFS connections</em>.  An 
HDFS connection is simply defined by the path where we would like the 
data to be stored on HDFS and the file type (such as &quot;text&quot;).  </p>

<p>For the input connection, we want to point to <code>raw/nf</code>, and make sure it 
is known that it is &quot;text&quot; data:</p>

<pre><code class="r"># initiate a connection to existing csv text file on HDFS
csvConn &lt;- hdfsConn(&quot;raw/nf&quot;, type = &quot;text&quot;)
</code></pre>

<pre><code>* &#39;loc&#39; is not an absolute path - prepending HDFS working directory
* Loading connection attributes
</code></pre>

<p>The output connection should be an empty directory, and can be a 
nonexistent directory.  Here, we would like to store our parsed NetFlow 
data in <code>nfRaw</code>.  We initialize this connection with a call to <code>hdfsConn()</code>:</p>

<pre><code class="r"># initiate a new connection where parsed NetFlow data will be stored
nfConn &lt;- hdfsConn(&quot;nfRaw&quot;, autoYes=TRUE) 
</code></pre>

<p>The <code>autoYes</code> parameter tells the function to respond &#39;Yes&#39; to any question 
about creating the directory if it does not exist.  <code>nfConn</code> is now simply 
an R object that points to a directory on HDFS.</p>

<p>We can now use these objects in our csv reader.</p>

<h4>Reading in the data</h4>

<p>There is a handy function in <code>datadr</code> that is the analog to <code>read.csv</code>, 
called <code>drRead.csv</code>, which reads the data in in blocks.  It has the same 
calling interface as R&#39;s <code>read.csv</code> with additional arguments to specify 
where to store the output, how many rows to put in each block, and an 
optional transformation function to apply to each block prior to storing 
it.</p>

<p>We will read in the NetFlow csv file using the default number of rows per 
block (<code>50000</code>), apply our <code>nfTransform</code> function that adds the <code>time</code> 
variable, and save the output to our <code>nfConn</code> local disk connection:</p>

<pre><code class="r"># read in NetFlow data
nfRaw &lt;- drRead.csv(csvConn, output = nfConn, postTransFn = nfTransform)
</code></pre>

<p>At this point you will see a series of status updates from Hadoop, while
the <code>drRead.csv</code> command is running. In particular, pay attention to the 
numbers of map and reduce jobs moving from the &#39;pending&#39; to the &#39;running&#39; 
to the &#39;complete&#39; columns. When this is complete, let&#39;s take a look at 
<code>nfRaw</code> to see what the object looks like:</p>

<pre><code class="r"># look at the nfRaw object
nfRaw
</code></pre>

<pre><code>
Distributed data object of class &#39;kvHDFS&#39; with attributes: 

&#39;ddo&#39; attribute | value
----------------+--------------------------------------------------------------------------
 keys           | [empty] call updateAttributes(dat) to get this value
 totStorageSize | 1.56 GB
 totObjectSize  | [empty] call updateAttributes(dat) to get this value
 nDiv           | 481
 splitSizeDistn | [empty] call updateAttributes(dat) to get this value
 example        | use kvExample(dat) to get an example subset
 bsvInfo        | [empty] no BSVs have been specified

&#39;ddf&#39; attribute | value
----------------+--------------------------------------------------------------------------
 vars           | dateTimeStr(num), ipLayerProtocol(int), and 16 more
 transFn        | identity (original data is a data frame)
 nRow           | [empty] call updateAttributes(dat) to get this value
 splitRowDistn  | [empty] call updateAttributes(dat) to get this value
 summary        | [empty] call updateAttributes(dat) to get this value

hdfsConn connection
  loc=/user/d3l348/bootcamp/nfRaw; type=sequence
</code></pre>

<p><code>nfRaw</code> is a <em>distributed data frame</em> (ddf), and we see several aspects 
about the data printed.  For example, we see that there are 481 subsets 
and that the size of the data on HDFS is <code>totStorageSize</code> = 
1.56 Mb.  The 
other attributes will be updated in a moment.</p>

<p>The <code>nfRaw</code> object itself is simply a special R object that contains 
metadata and pointers to the actual data stored on disk.  For more 
background on ddf and related objects, see 
<a href="http://hafen.github.io/datadr/index.html#distributed-data-objects">here</a> 
and <a href="http://hafen.github.io/datadr/index.html#distributed-data-frames">here</a>, 
and particularly for ddf objects on local disk, see 
<a href="http://hafen.github.io/datadr/index.html#medium-disk--multicore">here</a>.</p>

<p>Earlier we saw in the printout of <code>nfRaw</code> that it has many attibutes that 
have not yet been determined.  We can fix this by calling <code>updateAttributes()</code>:</p>

<pre><code class="r"># get missing attributes
nfRaw &lt;- updateAttributes(nfRaw)
</code></pre>

<p>In any subsequent R session, we can &quot;reload&quot; this data object, along with 
its metadata,
with the following command:</p>

<pre><code class="r"># reload &quot;nfRaw&quot; by loading the connection as a ddf
nfRaw &lt;- ddf(hdfsConn(&quot;nfRaw&quot;))
</code></pre>

<p>Now we can see more meaningful information about our data:</p>

<pre><code class="r"># look at the updated nfRaw object
nfRaw
</code></pre>

<pre><code>
Distributed data object of class &#39;kvHDFS&#39; with attributes: 

&#39;ddo&#39; attribute | value
----------------+--------------------------------------------------------------------------
 keys           | keys are available through getKeys(dat)
 totStorageSize | 1.56 GB
 totObjectSize  | 2 GB
 nDiv           | 481
 splitSizeDistn | use splitSizeDistn(dat) to get distribution
 example        | use kvExample(dat) to get an example subset
 bsvInfo        | [empty] no BSVs have been specified

&#39;ddf&#39; attribute | value
----------------+--------------------------------------------------------------------------
 vars           | dateTimeStr(num), ipLayerProtocol(int), and 16 more
 transFn        | identity (original data is a data frame)
 nRow           | 23258685
 splitRowDistn  | use splitRowDistn(dat) to get distribution
 summary        | use summary(dat) to see summaries

hdfsConn connection
  loc=/user/d3l348/bootcamp/nfRaw; type=sequence
</code></pre>

<p>We now see that there are about 23 million rows of data, and we are supplied, 
among other things, with summary statistics for the variables in the ddf.</p>

<h4>DDF attributes</h4>

<p>Since <code>nfRaw</code> is a distributed data frame, we can look at various aspects of 
the data frame through familiar R methods.</p>

<p>We can get number of rows:</p>

<pre><code class="r"># get total number of rows
nrow(nfRaw)
</code></pre>

<pre><code>[1] 23258685
</code></pre>

<p>We can see variable names:</p>

<pre><code class="r"># see what variables are available
names(nfRaw)
</code></pre>

<pre><code> [1] &quot;dateTimeStr&quot;               &quot;ipLayerProtocol&quot;           &quot;ipLayerProtocolCode&quot;      
 [4] &quot;firstSeenSrcIp&quot;            &quot;firstSeenDestIp&quot;           &quot;firstSeenSrcPort&quot;         
 [7] &quot;firstSeenDestPort&quot;         &quot;moreFragments&quot;             &quot;contFragments&quot;            
[10] &quot;durationSeconds&quot;           &quot;firstSeenSrcPayloadBytes&quot;  &quot;firstSeenDestPayloadBytes&quot;
[13] &quot;firstSeenSrcTotalBytes&quot;    &quot;firstSeenDestTotalBytes&quot;   &quot;firstSeenSrcPacketCount&quot;  
[16] &quot;firstSeenDestPacketCount&quot;  &quot;recordForceOut&quot;            &quot;date&quot;                     
</code></pre>

<p>We can grab the first subset and look at its structure:</p>

<pre><code class="r"># look at the structure of the first key-value pair
str(nfRaw[[1]])
</code></pre>

<pre><code>List of 2
 $ : chr &quot;attempt_201402250850_1322_m_000020_0&quot;
 $ :&#39;data.frame&#39;:   50000 obs. of  18 variables:
  ..$ dateTimeStr              : num [1:50000] 2.01e+13 2.01e+13 2.01e+13 2.01e+13 2.01e+13 ...
  ..$ ipLayerProtocol          : int [1:50000] 6 6 6 6 6 6 6 6 6 6 ...
  ..$ ipLayerProtocolCode      : chr [1:50000] &quot;TCP&quot; &quot;TCP&quot; &quot;TCP&quot; &quot;TCP&quot; ...
  ..$ firstSeenSrcIp           : chr [1:50000] &quot;172.10.0.4&quot; &quot;10.247.58.182&quot; &quot;10.247.58.182&quot; &quot;10.247.58.182&quot; ...
  ..$ firstSeenDestIp          : chr [1:50000] &quot;10.247.58.182&quot; &quot;172.10.0.4&quot; &quot;172.10.0.4&quot; &quot;172.10.0.4&quot; ...
  ..$ firstSeenSrcPort         : int [1:50000] 80 29589 27922 28874 27921 29349 80 9763 23973 23972 ...
  ..$ firstSeenDestPort        : int [1:50000] 27919 80 80 80 80 80 27920 80 80 80 ...
  ..$ moreFragments            : int [1:50000] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ contFragments            : int [1:50000] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ durationSeconds          : int [1:50000] 11 2 11 7 11 3 11 0 0 0 ...
  ..$ firstSeenSrcPayloadBytes : int [1:50000] 503 19 19 19 19 19 503 19 19 19 ...
  ..$ firstSeenDestPayloadBytes: int [1:50000] 19 503 503 503 503 503 19 503 503 503 ...
  ..$ firstSeenSrcTotalBytes   : int [1:50000] 619 297 297 297 297 297 619 243 243 243 ...
  ..$ firstSeenDestTotalBytes  : int [1:50000] 235 619 619 619 619 619 235 619 619 619 ...
  ..$ firstSeenSrcPacketCount  : int [1:50000] 2 5 5 5 5 5 2 4 4 4 ...
  ..$ firstSeenDestPacketCount : int [1:50000] 4 2 2 2 2 2 4 2 2 2 ...
  ..$ recordForceOut           : int [1:50000] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ date                     : POSIXct[1:50000], format: &quot;2013-04-14 15:00:10&quot; &quot;2013-04-14 15:00:10&quot; ...
</code></pre>

<p>We can view summaries of the variables in the distributed data frame:</p>

<pre><code class="r"># look at summaries (computed from updateAttributes)
summary(nfRaw)
</code></pre>

<pre><code>     dateTimeStr        ipLayerProtocol   ipLayerProtocolCode      firstSeenSrcIp      
 --------------------  -----------------  -------------------  ----------------------- 
  missing :         0   missing :      0          levels : 3           levels : 1390   
      min : 2.013e+13       min :      1         missing : 0          missing : 0      
      max : 2.013e+13       max :     17  &gt; freqTable head &lt;     &gt; freqTable head &lt;    
     mean : 2.013e+13      mean :   6.09    TCP : 23062987     10.138.214.18 : 1300759 
  std dev :    317466   std dev : 0.9961    UDP :   191395     10.170.32.181 : 1259035 
 skewness :     4.299  skewness :  10.79  OTHER :     4303     10.170.32.110 : 1257747 
 kurtosis :      35.2  kurtosis :  118.5                        10.10.11.102 : 1251990 
 --------------------  -----------------  -------------------  ----------------------- 
    firstSeenDestIp      firstSeenSrcPort   firstSeenDestPort     moreFragments    
 ---------------------  ------------------  -----------------  ------------------- 
         levels : 1277   missing :       0   missing :     0    missing :        0 
        missing : 0          min :       0       min :     0        min :        0 
  &gt; freqTable head &lt;         max :   65534       max : 65534        max :        1 
  172.30.0.4 : 8122427      mean :   30523      mean : 595.9       mean : 1.75e-05 
  172.10.0.4 : 4652570   std dev :   18235   std dev :  4261    std dev : 0.004183 
  172.20.0.4 : 4341038  skewness : 0.05421  skewness : 10.51   skewness :      239 
 172.20.0.15 : 4029911  kurtosis :   1.809  kurtosis : 121.3   kurtosis :    57145 
 ---------------------  ------------------  -----------------  ------------------- 
    contFragments      durationSeconds   firstSeenSrcPayloadBytes 
 --------------------  ----------------  ------------------------ 
  missing :         0   missing :     0      missing :       0    
      min :         0       min :     0          min :       0    
      max :         1       max :  1800          max : 3050256    
     mean : 1.741e-05      mean : 11.36         mean :   691.6    
  std dev :  0.004173   std dev : 37.15      std dev :   38955    
 skewness :     239.6  skewness : 10.48     skewness :   67.35    
 kurtosis :     57427  kurtosis :   221     kurtosis :    4739    
 --------------------  ----------------  ------------------------ 
 firstSeenDestPayloadBytes  firstSeenSrcTotalBytes  firstSeenDestTotalBytes 
 -------------------------  ----------------------  ----------------------- 
     missing :       0         missing :       0       missing :       0    
         min :       0             min :      43           min :       0    
         max : 3129878             max : 3326672           max : 3762470    
        mean :   22561            mean :    1497          mean :   23576    
     std dev :  245130         std dev :   41306       std dev :  254859    
    skewness :   11.84        skewness :    65.7      skewness :   11.84    
    kurtosis :     143        kurtosis :    4598      kurtosis :     143    
 -------------------------  ----------------------  ----------------------- 
 firstSeenSrcPacketCount  firstSeenDestPacketCount  recordForceOut 
 -----------------------  ------------------------  -------------- 
     missing :     0           missing :     0       missing :   0 
         min :     1               min :     0           min :   0 
         max : 13033               max : 13969           max :   0 
        mean : 14.51              mean : 18.64          mean :   0 
     std dev : 109.3           std dev : 182.4       std dev :   0 
    skewness : 14.66          skewness : 12.02      skewness : NaN 
    kurtosis : 334.4          kurtosis : 155.5      kurtosis : NaN 
 -----------------------  ------------------------  -------------- 
           date           
 ------------------------ 
 missing :              0 
     min : 13-04-10 06:50 
     max : 13-04-15 10:00 




 ------------------------ 
</code></pre>

<p>There are several insights we can get from the data by simply scanning 
the summary output printed above.  For example, the variable 
<code>ipLayerProtocolCode</code> tells us that the vast majority of the connections 
monitored are [TCP][TCP-wik] connections, while [UDP][UDP-wik] connections 
make up a little less than 1% of the traffic.  Also, all other protocols 
are rolled up into an &quot;other&quot; category.  There are 1390 <code>firstSeenSrcIp</code> 
values and 1277 <code>firstSeenDestIp</code> values. Also, the top destination IP 
had nearly twice as many sessions as the next most frequent. Recall that 
all variables are described <a href="docs/data/NetFlow_NetworkHealth.pdf">here</a>).</p>

<h4>Aggregate session counts per minute for each destination IP</h4>

<p>The <code>drAggregate</code> function counts frequencies of any combination of variables 
specified. This function can be used to get an idea of meaningful or interesting 
data divisions for further analysis. <code>drAggregate</code> is similar to the familiar 
<code>xtabs</code> function available in base R.</p>

<p>We would like to look at the time series of session counts per minute for each 
destination IP. We can apply the <code>drAggregate</code> function to <code>nfRaw</code> to 
accomplish this. Such tabulation is an example of a &quot;division-agnostic&quot; method </p>

<ul>
<li>a method we would like to run over the entire data set regardless of how 
it is divided.</li>
</ul>

<p>As with <code>xtabs()</code>, at a minimum, we provide <code>drAggregate()</code> a formula 
specifying the tabulation and the input data (must be a ddf or coercible 
to one).  We also subset the data to the four big IP addresses prior to 
performing the tabulation and create a variable that will help us bin by 
minute through the use of the <code>preTransFn</code> argument.</p>

<pre><code class="r"># count sessions per minute per destination IP
bigTimeAgg &lt;- drAggregate(~ timeMinute + firstSeenDestIp, 
                 data = nfRaw, 
                 preTransFn = function(x) {
                     x$timeMinute &lt;- as.POSIXct(trunc(x$date, 0, units = &quot;mins&quot;))
                     x
                 })
</code></pre>

<p>Now we sort the data in decreasing order of frequency and look at the first 
few rows:  </p>

<pre><code class="r"># sort by number of sessions
bigTimeAgg &lt;- bigTimeAgg[order(bigTimeAgg$Freq, decreasing=TRUE),]

# look at the first few rows
head(bigTimeAgg)       
</code></pre>

<pre><code>               timeMinute firstSeenDestIp   Freq
19821 2013-04-11 12:55:00      172.30.0.4 200790
19820 2013-04-11 12:54:00      172.30.0.4 193490
19819 2013-04-11 12:53:00      172.30.0.4 191602
19823 2013-04-11 12:57:00      172.30.0.4 189878
23883 2013-04-14 15:06:00      172.30.0.4 174662
19818 2013-04-11 12:52:00      172.30.0.4 174432
</code></pre>

<p>One obvious thing to do would be to plot time series by host IP. First we have
to convert the timeMinute column from character to a date/time object. We will 
plot four IPs that we know from information distributed with the data are
HTTP servers.</p>

<pre><code class="r"># convert timeMinute column to a time variable
bigTimeAgg$timeMinute &lt;- as.POSIXct(bigTimeAgg$timeMinute, tz = &quot;UTC&quot;)

# a few http servers
httpIPs &lt;- c(&quot;172.20.0.15&quot;, &quot;172.20.0.4&quot;, &quot;172.10.0.4&quot;, &quot;172.30.0.4&quot;)

# plot the time series of minute-counts by destination IP
xyplot(Freq ~ timeMinute | firstSeenDestIp, 
        data = bigTimeAgg[bigTimeAgg$firstSeenDestIp %in% httpIPs,], 
        layout = c(1, 4), as.table = TRUE, 
        strip = FALSE, strip.left = TRUE, 
        between = list(y = 0.25),
        type = c(&quot;p&quot;, &quot;g&quot;))
</code></pre>

<p><img src="figures/knitr/Activity2_2_13.png" alt="plot of chunk Activity2.2.13"> </p>

<p>It is clear that the majority of this traffic for each host occurs in two 
bursts, which occur at the same time for each host.  This looks like a denial of 
service attack.  We will look at this more in more detail in the next section.</p>

<h4>Calculate session duration quantiles</h4>

<p>Next we will explore the <code>drQuantile</code> function. <code>drQuantile</code> is another <code>datadr</code>
function that is division-agnostic, it is the analog of the <code>quantile</code> function
in R&#39;s base package. It is useful to look at data quantiles to identify 
outliers. </p>

<p>Let&#39;s use <code>drQuantile</code> to calculate the quantiles of the session duration,
by source IP type (e.g. HTTP, Workstation, etc). (We will use the convenience 
function <code>mergeHostList</code> in the <code>cyberTools</code> package. This function maps the
internal IP assignments of this dataset to their assigned categories.)</p>

<pre><code class="r"># compute the distribution of connection duration by source host type
dsqSrcType &lt;- drQuantile(
   nfRaw, var = &quot;durationSeconds&quot;, by = &quot;type&quot;,
   preTransFn = function(x) {
      suppressMessages(library(cyberTools))
      mergeHostList(x[,c(&quot;firstSeenSrcIp&quot;, 
         &quot;durationSeconds&quot;)], &quot;firstSeenSrcIp&quot;)
   }
)
</code></pre>

<p>Look at the result:</p>

<pre><code class="r"># look at the drQuantile output
head(dsqSrcType)
</code></pre>

<pre><code>       fval q         group
1 0.0000000 0 Administrator
2 0.0004036 0 Administrator
3 0.0008071 0 Administrator
4 0.0012107 0 Administrator
5 0.0016142 0 Administrator
6 0.0020178 0 Administrator
</code></pre>

<p>Now we will plot the data. We log-transform the y axis so that differences 
in the smaller values are not completely obscured.</p>

<pre><code class="r"># plot the distribution of connection duration by source host type
xyplot(log2(q + 1) ~ fval * 100 | group, 
   data = dsqSrcType, type = &quot;p&quot;,
   xlab = &quot;Percentile&quot;,
   ylab = &quot;log2(duration + 1)&quot;,
   panel = function(x, y, ...) {
      panel.abline(v = seq(0, 100, by = 10), col = &quot;#e6e6e6&quot;)
      panel.xyplot(x, y, ...)
      panel.abline(h = log2(1801), lty = 2)
   },
   layout = c(7, 1)
)
</code></pre>

<p><img src="figures/knitr/Activity2_2_16.png" alt="plot of chunk Activity2.2.16"> </p>

<p>We can see from this plot that while the durations of the sessions initiated 
by external IPs have a lot of variability, the sessions initiated by other 
types, like Domain Controllers for example, tend to be consistently short with
a few notable outliers. Consultation with a network traffic expert would be 
necessary at this point to determine if this behavior is potentially 
concerning, and if it were, tools like Trelliscope could be used to dig into
the data and identify the source of the outliers. In the next session we will
use Trelliscope to investigate the NetFlow data, however not the duration
field.</p>

</div>


<div class='tab-pane' id='activity-23-using-trelliscope-to-explore-large-complex-data'>
<h3>Activity 2.3: Using Trelliscope to Explore Large, Complex Data</h3>

<h4>Dividing NetFlow data based on inside host</h4>

<p>We have looked at many summaries and are now ready to look at some of the data 
in more detail.  </p>

<p>For many of our analyses, it makes sense to be investigating the behaviors of 
individual hosts inside the network.  The data we read in was arbitrarily 
split into 50K rows per subset, but for doing per-inside-host analyses, it 
makes sense to divide the data by inside host.  Another division that is worth 
looking into is looking at all hosts for small slices of time, which we will 
do later.</p>

<p>In the <code>preTransFn</code>, we filter out the DDoS attacks, we will get rid of the 4 
big HTTP hosts cooresponding to our previous analysis.  We want to filter out 
records with destination in <code>httpIPs</code> and source in <code>badIPs</code> during <code>bigTimes</code>:</p>

<pre><code class="r"># variables to filter on
bigTimes &lt;- sort(unique(bigTimeAgg$timeMinute[bigTimeAgg$Freq &gt; 1000]))
badIPs &lt;- c(&quot;10.138.214.18&quot;, &quot;10.17.15.10&quot;, &quot;10.12.15.152&quot;, &quot;10.170.32.110&quot;, &quot;10.170.32.181&quot;, &quot;10.10.11.102&quot;, &quot;10.247.106.27&quot;, &quot;10.247.58.182&quot;, &quot;10.78.100.150&quot;, &quot;10.38.217.48&quot;, &quot;10.6.6.7&quot;, &quot;10.12.14.15&quot;, &quot;10.15.7.85&quot;, &quot;10.156.165.120&quot;, &quot;10.0.0.42&quot;, &quot;10.200.20.2&quot;, &quot;10.70.68.127&quot;, &quot;10.138.235.111&quot;, &quot;10.13.77.49&quot;, &quot;10.250.178.101&quot;)
</code></pre>

<p>To create the <code>nfByHost</code> division, we define a new variable <code>hostIP</code> and split 
on that, knowing that we have taken care of inside-&gt;inside connections. <code>getHost()</code> 
takes the chunk of data being processed and adds the <code>hostIP</code> column, which is
then used to define the division.</p>

<pre><code class="r"># divide data by host IP
nfByHost &lt;- divide(nfRaw, by = &quot;hostIP&quot;,
                   preTransFn = function(x) {
                     suppressMessages(library(cyberTools))
                     x$timeMinute &lt;- as.POSIXct(trunc(x$date, 0, units = &quot;mins&quot;))
                     x &lt;- subset(x, !(timeMinute %in% bigTimes &amp; 
                                        firstSeenSrcIp %in% c(httpIPs, badIPs) &amp; 
                                        firstSeenDestIp %in% c(httpIPs, badIPs)))
                     if(nrow(x) &gt; 0) {
                       return(getHost(x))
                     } else {
                       return(NULL)
                     }
                   },
                   output = hdfsConn(&quot;nfByHost&quot;, autoYes=TRUE) 
)
nfByHost &lt;- updateAttributes(nfByHost)
</code></pre>

<p>Let&#39;s take a look at nfByHost:</p>

<pre><code class="r"># print nfbyHost
nfByHost
</code></pre>

<pre><code>
Distributed data object of class &#39;kvHDFS&#39; with attributes: 

&#39;ddo&#39; attribute | value
----------------+--------------------------------------------------------------------------
 keys           | keys are available through getKeys(dat)
 totStorageSize | 150.78 MB
 totObjectSize  | 197 MB
 nDiv           | 1223
 splitSizeDistn | use splitSizeDistn(dat) to get distribution
 example        | use kvExample(dat) to get an example subset
 bsvInfo        | [empty] no BSVs have been specified

&#39;ddf&#39; attribute | value
----------------+--------------------------------------------------------------------------
 vars           | dateTimeStr(num), ipLayerProtocol(int), and 18 more
 transFn        | identity (original data is a data frame)
 nRow           | 1913593
 splitRowDistn  | use splitRowDistn(dat) to get distribution
 summary        | use summary(dat) to see summaries

Division:
  Type: Conditioning variable division
    Conditioning variables: hostIP

hdfsConn connection
  loc=/user/d3l348/bootcamp/nfByHost; type=map
</code></pre>

<p>Much smaller - plenty small to handle in memory actually. We can also look at
the sizes of the data divisions. <code>splitRowDistn()</code> is a function in <code>datadr</code> which
returns the quantiles of the data subsets or divisions. The plot shows there
are a few outliers with much larger size than the others; that indicates a 
few hosts with quite a bit more traffic than the rest.</p>

<pre><code class="r"># look at the distribution of number of rows in nfByHost
plot(log10(splitRowDistn(nfByHost)))
</code></pre>

<p><img src="figures/knitr/Activity2_3_4.png" alt="plot of chunk Activity2.3.4"> </p>

<p>Let&#39;s tabulate number of connections by hour.  We can do this by calling 
<code>recombine()</code>, which will <code>apply</code> a function to each subset and <code>combine</code> 
the results using <code>combDdo()</code>, which outputs a distributed data object.</p>

<pre><code class="r"># roll data up to counts by hour for each host
hostTimeAgg &lt;- recombine(nfByHost, 
   apply = function(x) {
      timeHour &lt;- as.POSIXct(trunc(x$date, 0, units = &quot;hours&quot;))
      res &lt;- data.frame(xtabs(~ timeHour))
      res$timeHour &lt;- as.POSIXct(res$timeHour)
      res
   }, 
   combine = combDdo()
)
</code></pre>

<h4>Creating Trelliscope displays of host activity over time</h4>

<p>For this activity, we will make a couple of simple Trelliscope displays. The
Trelliscope documentation at <a href="http://tesseradata.org/trelliscope/">http://tesseradata.org/trelliscope/</a> 
has many more details than what is discussed here.</p>

<p>We start by loading the trelliscope library, and defining a visualization
database (VDB) connection. All subsequent displays will be saved in the
directory specified here. </p>

<pre><code class="r"># load trelliscope library
library(trelliscope)
# initiate a visualization database (VDB) connection
vdbConn(&quot;vdb_vast&quot;, autoYes=TRUE)
</code></pre>

<p>A simple visualization for our <code>hostTimeAgg</code> data is to look at the aggregated 
hourly counts vs. time for each inside host.  We can specify a panel function 
that, given one subset of our data, <code>x</code>, plots the square root of frequency vs 
timeHour. Then we test the panel on a single data division.</p>

<pre><code class="r"># panel function for simple time series plot
timePanel &lt;- function(x) {
   xyplot(sqrt(Freq) ~ timeHour, data = x, type = c(&quot;p&quot;, &quot;g&quot;))
}

# test on subset
timePanel(hostTimeAgg[[1]][[2]])
</code></pre>

<p><img src="figures/knitr/Activity2_3_6b.png" alt="plot of chunk Activity2.3.6b"> </p>

<p>To help us interact with the panels in a more meaningful way, we can specify 
metrics to be computed for each subset, called &quot;cognostics&quot;.  Using cognostics, 
in the viewer we can specify sorting and filters based on these metrics to 
help focus on panels of interest in the data.</p>

<p>Here is a simple cognostics function which computes for a given host metrics 
such as the number of total connections, median and standard deviation of 
number of hourly counts, etc.</p>

<pre><code class="r"># cognostics function for simple time series plot
timeCog &lt;- function(x) {
   IP &lt;- attr(x, &quot;split&quot;)$hostIP
   curHost &lt;- hostList[hostList$IP == IP,]

   list(
      hostName = cog(curHost$hostName, desc = &quot;host name&quot;),
      type = cog(curHost$type, desc = &quot;host type&quot;),
      nobs = cog(sum(x$Freq), &quot;log 10 total number of connections&quot;),
      timeCover = cog(nrow(x), desc = &quot;number of hours containing connections&quot;),
      medHourCt = cog(median(sqrt(x$Freq)), 
      desc = &quot;median square root number of connections&quot;),
      madHourCt = cog(mad(sqrt(x$Freq)), 
      desc = &quot;median absolute deviation square root number of connections&quot;),
      max = cog(max(x$Freq), desc = &quot;maximum number of connections in an hour&quot;)
   )
}
</code></pre>

<p>Once again, we test the function on a single data subset.</p>

<pre><code class="r"># test on subset
timeCog(hostTimeAgg[[1]][[2]])
</code></pre>

<pre><code>$hostName
[1] &quot;wss2-259.bigmkt2.com&quot;

$type
[1] &quot;Workstation&quot;

$nobs
[1] 795

$timeCover
[1] 16

$medHourCt
[1] 6.671

$madHourCt
[1] 3.057

$max
[1] 195
</code></pre>

<p>We can now make a display by providing our panel and cognostics functions, as 
well as additional information such as the name of the display and a 
description.</p>

<pre><code class="r"># create the trelliscope display
makeDisplay(hostTimeAgg,
   name = &quot;hourly_count&quot;,
   group = &quot;inside_hosts&quot;,
   desc = &quot;time series plot of hourly counts of connections for each inside host&quot;,
   panelFn = timePanel,
   cogFn = timeCog,
   width = 800, height = 400,
   lims = list(x = &quot;same&quot;, y = &quot;same&quot;)
)

# a unique port number
myport &lt;- as.numeric(Sys.getenv(&quot;TR_PORT&quot;))
view(port=myport)
</code></pre>

<p>When the Trelliscope viewer appears, you can choose from a list of displays 
available in the VDB specified above. (For this example, the only available
display is inside_hosts/hourly_count, but one could create and save many 
displays in the same directory at different times and they would still
be available until explicitly removed.)</p>

<p><img src="figures/trelliscope_2_1.png" alt="Trelliscope Fig 1"></p>

<p>When a display is chosen, the first (randomly selected) panel is displayed. </p>

<p><img src="figures/trelliscope_2_2.png" alt="Trelliscope Fig 2"></p>

<p>First we will use the Visible Cognostics screen to augment the information shown 
with each plot. The dividing variable (<code>hostIP</code>) is selected by default, we 
will also choose <code>hostName</code> and <code>type</code>. Hit Apply to close the screen.</p>

<p><img src="figures/trelliscope_2_3.png" alt="Trelliscope Fig 3"></p>

<p>Next we will filter the plots shown using the Table Sort/Filter screen. We select
only HTTP from the type column. Hit Apply to close the screen.</p>

<p><img src="figures/trelliscope_2_4.png" alt="Trelliscope Fig 4"></p>

<p>Next we use the Univariate Filter screen, to choose only plots containing
outliers in the max cognostic. (The max value here is the max of frequency/hour,
so we are choosing the plots with only the largest number of connections per 
hour.) Hit Apply to close the screen.</p>

<p><img src="figures/trelliscope_2_5.png" alt="Trelliscope Fig 5"></p>

<p>Finally, we will use the Panel Layout screen to allow us to view multiple plots
at a time. </p>

<p><img src="figures/trelliscope_2_6.png" alt="Trelliscope Fig 6"></p>

<p>Hit Apply to close the screen and we see 12 plots of HTTP host traffic 
displayed. The left and right arrows at the top may be used to view subsequent
plots.</p>

<p><img src="figures/trelliscope_2_7.png" alt="Trelliscope Fig 7"></p>

<p>By viewing these plots together, we can easily see that there are a couple of 
different patterns of activity. A few have very low traffic, and a couple (the 
first and third) have rather cyclic patterns. Then there are four (2, 6, 7, 
and 9) that have sudden jumps between consistently low and consistently high 
traffic, and those jumps appear to happen at the same times across all four.</p>

<p>When finished looking at the Trelliscope view, close the browser tab or window,
and at the R prompt, type <code>Esc</code> or <code>Ctrl-C</code> to stop the server.</p>

<h4>Creating Trelliscope displays that distinguish between incoming and outgoing connections</h4>

<p>Now let&#39;s distinguish between incoming and outgoing connections. If the host 
is the first seen source, classify the connection as &quot;outgoing&quot; 
(this will not be 100% correct), otherwise the session will be &quot;incoming&quot;. 
Once again, aggregate by hour.</p>

<pre><code class="r"># aggregate hourly counts by &quot;incoming&quot;, &quot;outgoing&quot;
hostTimeDirAgg &lt;- recombine(nfByHost, 
   apply = function(x) {
      x$timeHour &lt;- as.POSIXct(trunc(x$date, 0, units = &quot;hours&quot;))
      res &lt;- data.frame(xtabs(~ timeHour + srcIsHost, data = x))
      res$timeHour &lt;- as.POSIXct(res$timeHour)
      res$direction &lt;- &quot;incoming&quot;
      res$direction[as.logical(as.character(res$srcIsHost))] &lt;- &quot;outgoing&quot;
      subset(res, Freq &gt; 0)
   }, 
   combine = combDdo()
)
</code></pre>

<p>Now we will make a similar display, showing incoming and outgoing connections.</p>

<pre><code class="r"># new slightly different time panel
timePanelDir &lt;- function(x) {
   xyplot(
      sqrt(Freq) ~ timeHour, groups = direction, 
      data = x, type = c(&quot;p&quot;, &quot;g&quot;), auto.key = TRUE
   )
}
</code></pre>

<p>We will also create a new cognostics function, which calculates the same
metrics as the previous one, but for incoming and outgoing connections 
separately.</p>

<pre><code class="r"># new cognostics function that calculates metrics for incoming and outgoing separately
timeCog2 &lt;- function(x) {
  IP &lt;- attr(x, &quot;split&quot;)$hostIP
  curHost &lt;- hostList[hostList$IP == IP,]
  ind.incoming &lt;- x$direction == &quot;incoming&quot;

  cog.values &lt;- list(
      hostName = cog(curHost$hostName, desc = &quot;host name&quot;),
      type = cog(curHost$type, desc = &quot;host type&quot;),
      incomingNobs = cog(sum(x$Freq[ind.incoming]), 
         desc=&quot;log 10 total number of incoming connections&quot;),
      outgoingNobs = cog(sum(x$Freq[!ind.incoming]), 
         desc=&quot;log 10 total number of outgoing connections&quot;),
      incomingTimeCover = cog(sum(ind.incoming), 
         desc = &quot;number of hours containing incoming connections&quot;),
      outgoingTimeCover = cog(sum(!ind.incoming), 
         desc = &quot;number of hours containing outgoing connections&quot;),
      incomingMedHourCt = cog(median(sqrt(x$Freq[ind.incoming]), na.rm=TRUE), 
         desc = &quot;median square root number of incoming connections&quot;),
      outgoingMedHourCt = cog(median(sqrt(x$Freq[!ind.incoming]), na.rm=TRUE), 
         desc = &quot;median square root number of outgoing connections&quot;),
      incomingMadHourCt = cog(mad(sqrt(x$Freq[ind.incoming])), 
         desc = &quot;median absolute deviation square root number of incoming connections&quot;),
      outgoingMadHourCt = cog(mad(sqrt(x$Freq[!ind.incoming])), 
         desc = &quot;median absolute deviation square root number of outgoing connections&quot;),
      incomingMax = cog(max(c(0, x$Freq[ind.incoming])), 
         desc = &quot;maximum number of incoming connections in an hour&quot;),
      outgoingMax = cog(max(c(0, x$Freq[!ind.incoming])), 
         desc = &quot;maximum number of outgoing connections in an hour&quot;)
  )
  cog.values[unlist(lapply(cog.values, is.na))] &lt;- -1
  cog.values
}
</code></pre>

<p>Now, we create the display and launch the Trelliscope viewer.</p>

<pre><code class="r"># create the display
makeDisplay(hostTimeDirAgg,
          name = &quot;hourly_count_src_dest&quot;,
          group = &quot;inside_hosts&quot;,
          desc = &quot;time series plot of hourly counts of connections for each inside host by source / destination&quot;,
          panelFn = timePanelDir,
          width = 800, height = 400,
          cogFn = timeCog2,
          lims = list(x = &quot;same&quot;, y = &quot;same&quot;))

# view display
view(port=myport)
</code></pre>

<p>When Trelliscope appears, you will see that the previous display 
(inside_hosts/hourly_count) has been joined by a new display: 
inside_hosts/hourly_count_src_dest. Choose the new one.</p>

<p><img src="figures/trelliscope_3_1.png" alt="Trelliscope Fig 7"></p>

<p>There is a set of workstations that were infected with malware and now 
form a <a href="http://en.wikipedia.org/wiki/Botnet">botnet</a>. This botnet has 
started a recurring Denial of Service attack against an external IP. 
Can you find the machines in question?</p>

<p>We will start by using the Table Sort/Filter screen to filter down
to only Workstations.</p>

<p><img src="figures/trelliscope_3_2.png" alt="Trelliscope Fig 8"></p>

<p>Next we will use the Univariate Filter to select the largest values
for outgoingMax.</p>

<p><img src="figures/trelliscope_3_3.png" alt="Trelliscope Fig 9"></p>

<p>After using Panel Layout to adjust the number of panels visible at once,
we can see 8 plots of workstations with a distinct pattern of outgoing
traffic that is suspiciously similar. Of course this visual analysis
is not conclusive, further statistical analysis would be needed to prove 
that these workstations have a distinct pattern from the others and are 
also substatially similar. But the visual exploration facilitated by
Trelliscope was a quick and intuitive way to find relevant machines.</p>

<p><img src="figures/trelliscope_3_4.png" alt="Trelliscope Fig 10"></p>

</div>


<div class='tab-pane' id='r-code'>
<h3>R Code</h3>

<p>If you would like to run through all of the code examples in this documentation without having to pick out each line of code from the text, below are files with the R code for each section.</p>

<ul>
<li><a href="scripts/Activity_1.2.R">Activity 1.2</a></li>
<li><a href="scripts/Activity_1.3.R">Activity 1.3</a></li>
<li><a href="scripts/Activity_1.3_solutions.R">Activity 1.3 Solutions</a></li>
<li><a href="scripts/Activity_1.4.R">Activity 1.4</a></li>
<li><a href="scripts/Activity_1.4_solutions.R">Activity 1.4 Solutions</a></li>
<li><a href="scripts/Activity_1.5.R">Activity 1.5</a></li>
<li><a href="scripts/Activity_1.5_solutions.R">Activity 1.5 Solutions</a></li>
<li><a href="scripts/Activity_2.1.R">Activity 2.1</a></li>
<li><a href="scripts/Activity_2.2.R">Activity 2.2</a></li>
<li><a href="scripts/Activity_2.3.R">Activity 2.3</a></li>
</ul>

</div>

   
   <ul class="pager">
      <li><a href="#" id="previous">&larr; Previous</a></li> 
      <li><a href="#" id="next">Next &rarr;</a></li> 
   </ul>
</div>


</div>
</div>

<hr>

<div class="footer">
   <p></p>
</div>
</div> <!-- /container -->

<script src="assets/jquery/jquery.js"></script>
<script type='text/javascript' src='assets/custom/custom.js'></script>
<script src="assets/bootstrap/js/bootstrap.js"></script>
<script src="assets/custom/jquery.ba-hashchange.min.js"></script>
<script src="assets/custom/nav.js"></script>

</body>
</html>